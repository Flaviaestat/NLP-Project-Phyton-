{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06 - Classificador_1.ipynb","provenance":[{"file_id":"1cEwX--YrYnjU9zckD_rxk48BJvnL97dF","timestamp":1584916566014}],"authorship_tag":"ABX9TyPQpBeWwezWLR6fEheZpWNH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"lxtkGL66F8iO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593461449020,"user_tz":180,"elapsed":848,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"9136ce8d-c33e-4364-9a13-257b94d529a3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":109,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y9YrEPUWF9rB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593461455536,"user_tz":180,"elapsed":860,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["import os\n","import pandas as pd\n","from gensim.models import Doc2Vec\n","workdir_path = '/content/drive/My Drive/' + '00 PUC BI MASTER/00 - PROJ (TCC)/PREDIÇÃO ATIVIDADES/event2mind'  # Inserir o local da pasta onde estão os arquivos de entrada (treino e teste)\n","os.chdir(workdir_path)"],"execution_count":110,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTRe9OKeJtTj","colab_type":"text"},"source":["MODEL LOAD - INPUT"]},{"cell_type":"code","metadata":{"id":"o4V8fF8ETZnC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1593461462616,"user_tz":180,"elapsed":4151,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"9fac8f3a-023a-44aa-94f1-74882ee06921"},"source":["#Parametros de Input\n","model = Doc2Vec.load(\"Event2Mind_Events.model\")\n","input_description = pd.read_csv('embeddingsEvents.csv', sep = ';')\n","\n","campo_input = \"Event\""],"execution_count":111,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"AoiCGPrsSCxR","colab_type":"text"},"source":["OUTPUT - CLUSTER\n"]},{"cell_type":"code","metadata":{"id":"_PkVcINsPUA2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593467576050,"user_tz":180,"elapsed":1308,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["#Parametros Output\n","cluster_output = pd.read_csv('clusterIntencoes.csv', sep = ',')\n","cluster_output.rename(columns={\"Xintent\": \"Xintent_2\"}, inplace = True)\n","cluster_output.rename(columns={\"cluster_intents\": \"cluster_output\"}, inplace = True)\n","\n","campo_output = \"Xintent_2\""],"execution_count":172,"outputs":[]},{"cell_type":"code","metadata":{"id":"RK0_FYFXtJCE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467578797,"user_tz":180,"elapsed":923,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"5d39259e-5919-4d85-fd41-fce6545ff40a"},"source":["print(cluster_output['cluster_output'].unique().tolist())"],"execution_count":173,"outputs":[{"output_type":"stream","text":["[5, 3, 6, 1, 0, 2, 4]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3vKimsR4V_8C","colab_type":"text"},"source":["TRATAMENTOS BASE"]},{"cell_type":"code","metadata":{"id":"pM1a3cnHJEL9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593461620263,"user_tz":180,"elapsed":1020,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["input_description['input_index'] = list(range(len(input_description.index)))\n","input_description['input_index'] = input_description['input_index'] + 1\n","embeddings_input = model.docvecs.vectors_docs\n","\n","def removeCaracteres(nomeColuna, dataSet):\n","  dataSet[nomeColuna]= dataSet[nomeColuna].astype(str)\n","  dataSet[nomeColuna] = dataSet[nomeColuna].str.replace(\"`` ve\", \"\")\n","  dataSet[nomeColuna] = dataSet[nomeColuna].str.replace(\"`` s\", \"\")\n","  dataSet[nomeColuna] = dataSet[nomeColuna].str.replace(\"'\", \"\")\n","  dataSet[nomeColuna] = dataSet[nomeColuna].str.replace(\"&\", \" \")\n","  dataSet[nomeColuna] = dataSet[nomeColuna].str.replace(\",\", \" \")\n","  dataSet[nomeColuna] = dataSet[nomeColuna].str.replace(\"  \", \" \")\n"],"execution_count":117,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dlDMtjnHR1ym","colab_type":"text"},"source":["CRUZANDO CLUSTER DE INTEÇÕES COM EVENTOS PARA DEIXA-LOS NA MESMA DIMENSÃO"]},{"cell_type":"code","metadata":{"id":"INPOKevZQXAS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467598697,"user_tz":180,"elapsed":2170,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"be9450d7-37fb-48d5-a149-f2e295cb0cf3"},"source":["#BASE COM TODAS AS INTENÇÕES E EMOÇÕES\n","dtPrincipal = pd.read_csv('event2MindClean.csv', sep = ',')\n","dtPrincipal = dtPrincipal[dtPrincipal[campo_output] != \"none\"]\n","dtPrincipal = dtPrincipal[dtPrincipal[campo_output] != \"'none'\"]\n","removeCaracteres(campo_output, dtPrincipal)\n","\n","#set_index = input variable\n","dtPrincipal = dtPrincipal.join(input_description.set_index(campo_input), on = campo_input, how = 'inner')\n","\n","#set_index = output variable\n","dtPrincipal = cluster_output.join(dtPrincipal.set_index(campo_output), on = campo_output, how = 'inner')  \n","\n","#criando novo index\n","dtPrincipal['new_index'] = list(range(len(dtPrincipal.index)))\n","dtPrincipal['new_index'] = dtPrincipal['new_index'] + 1\n","dtPrincipal.set_index(['new_index'], inplace = True)\n","\n","len(dtPrincipal)"],"execution_count":174,"outputs":[{"output_type":"execute_result","data":{"text/plain":["92405"]},"metadata":{"tags":[]},"execution_count":174}]},{"cell_type":"code","metadata":{"id":"V4lpVqaqgszs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"status":"ok","timestamp":1593467602966,"user_tz":180,"elapsed":850,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"6f6dc71d-79a8-43a9-eb6e-4a04df6bb4db"},"source":["dtPrincipal.head(5)"],"execution_count":175,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cluster_output</th>\n","      <th>Xintent_2</th>\n","      <th>Indice</th>\n","      <th>Xintent</th>\n","      <th>Xemotion</th>\n","      <th>Event</th>\n","      <th>Xsent</th>\n","      <th>Osent</th>\n","      <th>Event_2</th>\n","      <th>Xemotion_2</th>\n","      <th>vetor_doc_str</th>\n","      <th>cluster_events</th>\n","      <th>input_index</th>\n","    </tr>\n","    <tr>\n","      <th>new_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>advantage</td>\n","      <td>773</td>\n","      <td>to have an advantage</td>\n","      <td>pleased</td>\n","      <td>PersonX uses PersonX's ___ to obtain</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>'personx, ', ',', 'us, ', ',', 'personx, ', ',...</td>\n","      <td>'pleased '</td>\n","      <td>[-0.47499427  0.0606029   0.01173875  0.530232...</td>\n","      <td>17</td>\n","      <td>329</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>advantage</td>\n","      <td>773</td>\n","      <td>to have an advantage</td>\n","      <td>smug</td>\n","      <td>PersonX uses PersonX's ___ to obtain</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>'personx, ', ',', 'us, ', ',', 'personx, ', ',...</td>\n","      <td>'smug '</td>\n","      <td>[-0.47499427  0.0606029   0.01173875  0.530232...</td>\n","      <td>17</td>\n","      <td>329</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>advantage</td>\n","      <td>773</td>\n","      <td>to have an advantage</td>\n","      <td>excited</td>\n","      <td>PersonX uses PersonX's ___ to obtain</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>'personx, ', ',', 'us, ', ',', 'personx, ', ',...</td>\n","      <td>'excited '</td>\n","      <td>[-0.47499427  0.0606029   0.01173875  0.530232...</td>\n","      <td>17</td>\n","      <td>329</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>advantage</td>\n","      <td>8698</td>\n","      <td>advantage</td>\n","      <td>good</td>\n","      <td>PersonX takes ___ of opportunities</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>'personx, ', ',', 'tak, ', ',', ', ', ',', 'op...</td>\n","      <td>'good '</td>\n","      <td>[-3.53230327e-01  1.98501185e-01 -6.00352824e-...</td>\n","      <td>1</td>\n","      <td>4208</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>advantage</td>\n","      <td>16524</td>\n","      <td>to have an advantage</td>\n","      <td>in control</td>\n","      <td>PersonX throws off balance</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>'personx, ', ',', 'throw, ', ',', 'balanc, '</td>\n","      <td>'control '</td>\n","      <td>[ 0.26132074  0.02934684  0.38985577 -0.279397...</td>\n","      <td>16</td>\n","      <td>7719</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           cluster_output   Xintent_2  ...  cluster_events input_index\n","new_index                              ...                            \n","1                       5  advantage   ...              17         329\n","2                       5  advantage   ...              17         329\n","3                       5  advantage   ...              17         329\n","4                       5  advantage   ...               1        4208\n","5                       5  advantage   ...              16        7719\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":175}]},{"cell_type":"markdown","metadata":{"id":"DBT6-ZYn6GXw","colab_type":"text"},"source":["CRIANDO NUMPY ARRAYS COM OS INPUTS E OUTPUTS"]},{"cell_type":"code","metadata":{"id":"VB8sdlQ_ZuYT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467612705,"user_tz":180,"elapsed":4120,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"cd9a2552-18cb-4015-b86b-527b026f4ab4"},"source":["#criar um embeddings final que segue a ordem do input no dtPrincipal\n","embeddingDupl = []\n","cluster = []\n","\n","for i in range(1, len(dtPrincipal)):\n","\n","  linhaEmbedding = (dtPrincipal['input_index'][i]) - 1\n","  embeddingDupl.append(embeddings_input[linhaEmbedding])\n","  cluster.append(dtPrincipal['cluster_output'][i])\n","\n","len(embeddingDupl)"],"execution_count":176,"outputs":[{"output_type":"execute_result","data":{"text/plain":["92404"]},"metadata":{"tags":[]},"execution_count":176}]},{"cell_type":"markdown","metadata":{"id":"mtk8PHZhhyBA","colab_type":"text"},"source":["RODAR ABAIXO CASO QUEIRA CRIAR UMA CLASSE COM BASE NAS PALAVRAS"]},{"cell_type":"code","metadata":{"id":"xTPKQ-gjhthL","colab_type":"code","colab":{}},"source":["'''\n","listPalavras = ['happy', 'glad', 'excited', 'relieved', 'show', 'know', 'go', 'give', 'take', 'keep', 'fell', 'enjoy', 'work', 'wants', 'find', 'look', 'avoid']\n","listOutput = dtPrincipal[campo_output].toList()\n","\n","import math\n","\n","classes = []\n","\n","for i in range(0, len(listOutput):\n","  texto = listOutput[i]\n","  classeTemp = []\n","  for z in range(0, len(listPalavras)):\n","       if (texto.find(listPalavras[z]) != -1):\n","        flag = z\n","        classeTemp.append(flag)\n","         \n","    \n","  classeFinal = pd.Series(classeTemp).min()\n","  classes.append(classeFinal)\n","\n","maximo = pd.Series(classes).max()    \n","classes = [ maximo + 1 if math.isnan(x) else x for x in classes] \n","\n","cluster_output = cluster_output.assign(classes=classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fjdSg9Ox4iH","colab_type":"text"},"source":["SEPARANDO INPUT (X) E OUTPUT (Y) COMO NUMPY ARRAY"]},{"cell_type":"code","metadata":{"id":"IdTAaq3VufbX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467615535,"user_tz":180,"elapsed":927,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"620548af-32f7-435e-d79a-ebed461bef36"},"source":["import numpy as np\n","\n","X = np.array(embeddingDupl)\n","Y = np.array(cluster)\n","X.shape"],"execution_count":177,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(92404, 400)"]},"metadata":{"tags":[]},"execution_count":177}]},{"cell_type":"markdown","metadata":{"id":"nDqSQZ4Yi27-","colab_type":"text"},"source":["IMPORTS"]},{"cell_type":"code","metadata":{"id":"UCCkUOnYY_2-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593467617177,"user_tz":180,"elapsed":836,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["from sklearn import metrics\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import KNeighborsClassifier\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","from sklearn.model_selection import train_test_split"],"execution_count":178,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAAzmmza6i6w","colab_type":"text"},"source":["SPLIT DA BASE EM TREINO E TESTE"]},{"cell_type":"code","metadata":{"id":"pPtSCH0wnGqb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593467620477,"user_tz":180,"elapsed":816,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"],"execution_count":179,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1jSAdyGZX3_V","colab_type":"text"},"source":["NORMALIZAÇÃO E SCALER"]},{"cell_type":"code","metadata":{"id":"EN35yFijX1MH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593467626633,"user_tz":180,"elapsed":5224,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["scaler = StandardScaler()\n","scaler_model = scaler.fit(x_train)\n","\n","x_train_scaled = scaler_model.transform(x_train)\n","x_test_scaled = scaler_model.transform(x_test)\n","\n","pcaComp = PCA(n_components = 0.99)\n","pcaModel = pcaComp.fit(x_train_scaled)\n","x_train_prepared = pcaModel.transform(x_train_scaled)\n","x_test_prepared = pcaModel.transform(x_test_scaled)\n","\n","#caso não opte por testar com normalização e Scaler\n","#x_train_prepared = x_train\n","#x_test_prepared = x_test\n"],"execution_count":180,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBG3060sk0Ey","colab_type":"text"},"source":["OBTENDO AS DIMENSÕES"]},{"cell_type":"code","metadata":{"id":"MDiO9_K9kzPd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467628046,"user_tz":180,"elapsed":815,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"72abe885-3454-4159-ac70-9b7c8c658228"},"source":["dimensao_x = x_train_prepared.shape[1]\n","camadas_saida  = len(dtPrincipal['cluster_output'].unique())\n","\n","print(\"dimensao x: %(dx)s e dimensao y: %(dy)s\"% {'dx': dimensao_x, 'dy': camadas_saida} )"],"execution_count":181,"outputs":[{"output_type":"stream","text":["dimensao x: 84 e dimensao y: 7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oEdgOpNgX8pK","colab_type":"text"},"source":["PARAMETROS MODELOS"]},{"cell_type":"code","metadata":{"id":"tYuujxJ3pskS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593467636616,"user_tz":180,"elapsed":817,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["epocas = 500\n","\n","#nomes dos modelos\n","modelo1 = 'MLP 1 Camada'\n","modelo2 = 'MLP 2 Camadas'\n","modelo3 = 'KNN 2'\n","modelo4 = 'LSTM 1 Camada'\n","modelo5 = 'LSTM 2 Camadas'\n","modelo6 = 'LSTM 3 Camadas'"],"execution_count":182,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-4rPcTHKqhen","colab_type":"text"},"source":["DEFININDO CAMADAS DOS MODELOS"]},{"cell_type":"code","metadata":{"id":"mJn-Ihp7kO1p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467637716,"user_tz":180,"elapsed":516,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"084aa756-c05b-4b51-9508-0da9ffe2476b"},"source":["for k in range(3, 10):\n","  potencia = 2 ** k\n","  if potencia < dimensao_x:\n","    primeiro_neuronio_lstm = potencia\n","\n","for k in range(3, 10):\n","  potencia = 2 ** k\n","  if potencia < primeiro_neuronio_lstm:\n","    segundo_neuronio_lstm = potencia\n","\n","for k in range(3, 10):\n","  potencia = 2 ** k\n","  if potencia < segundo_neuronio_lstm:\n","    terceiro_neuronio_lstm = potencia\n","\n","print(\"O primeiro neuronio do modelo de LSTM tera %(n1)s camadas. O segundo neuronio terá %(n2)s camadas. O terceiro neuronio terá %(n3)s camadas.\" % {'n1': primeiro_neuronio_lstm, 'n2': segundo_neuronio_lstm, 'n3': terceiro_neuronio_lstm})"],"execution_count":183,"outputs":[{"output_type":"stream","text":["O primeiro neuronio do modelo de LSTM tera 64 camadas. O segundo neuronio terá 32 camadas. O terceiro neuronio terá 16 camadas.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e0gU6KfLX74B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467646533,"user_tz":180,"elapsed":847,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"45cba6d2-81dd-419c-8b00-8640e2f9d28c"},"source":["primeira_hl_mlp = round((dimensao_x + camadas_saida) / 2)\n","segunda_hl_mlp = round(primeira_hl_mlp /2)\n","\n","print(\"O primeiro neuronio do modelo de MLP tera %(n1)s camadas. O segundo neuronio terá %(n2)s camadas\" % {'n1': primeira_hl_mlp, 'n2': segunda_hl_mlp})"],"execution_count":184,"outputs":[{"output_type":"stream","text":["O primeiro neuronio do modelo de MLP tera 46 camadas. O segundo neuronio terá 23 camadas\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TsxZi07_6tsu","colab_type":"text"},"source":["\n","\n","MULTILAYER PERCEPTRON 1 CAMADA\n"]},{"cell_type":"code","metadata":{"id":"DseCgiy_4e5F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467889667,"user_tz":180,"elapsed":234485,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"640376e0-4078-4883-8938-def07f12f473"},"source":["clf_mlp1 = MLPClassifier(solver='sgd'\n","                     , hidden_layer_sizes=(primeira_hl_mlp)\n","                     , max_iter = (epocas * 2)\n","                     , random_state=1)\n","\n","clf_mlp1.out_activation_ = 'softmax'\n","\n","clf_mlp1.fit(x_train_prepared, y_train)\n","y_predicted_mlp1 = clf_mlp1.predict(x_test_prepared)\n","\n","accuracy_modelo1 = metrics.accuracy_score(y_test, y_predicted_mlp1).round(3)\n","print(accuracy_modelo1)"],"execution_count":185,"outputs":[{"output_type":"stream","text":["0.237\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1uXJDmjE11_F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593467890682,"user_tz":180,"elapsed":998,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"4ed6bc5c-6beb-43f7-8ee2-3d130e80e9e5"},"source":["y_predicted_mlp1.max()"],"execution_count":186,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{"tags":[]},"execution_count":186}]},{"cell_type":"code","metadata":{"id":"YS0UHYZhvoRx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593467890684,"user_tz":180,"elapsed":967,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["mlp1_results = pd.DataFrame(list(zip(y_predicted_mlp1, y_test)), columns =['predito', 'real'])\n","df_confusion = pd.crosstab(mlp1_results.real, mlp1_results.predito)\n","\n","export_path = workdir_path + '/matrizConfusaoMLP1.csv'\n","df_confusion.to_csv (export_path, index = True, header=True)"],"execution_count":187,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7I8tiSZ17Z3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"status":"ok","timestamp":1593467890687,"user_tz":180,"elapsed":955,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"fc2b2bfd-f426-4836-b642-a3ac30428360"},"source":["df_confusion.head(20)"],"execution_count":188,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>predito</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","    <tr>\n","      <th>real</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>891</td>\n","      <td>54</td>\n","      <td>979</td>\n","      <td>23</td>\n","      <td>762</td>\n","      <td>179</td>\n","      <td>152</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>384</td>\n","      <td>77</td>\n","      <td>694</td>\n","      <td>12</td>\n","      <td>449</td>\n","      <td>112</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>673</td>\n","      <td>66</td>\n","      <td>1814</td>\n","      <td>21</td>\n","      <td>781</td>\n","      <td>158</td>\n","      <td>156</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>335</td>\n","      <td>26</td>\n","      <td>636</td>\n","      <td>28</td>\n","      <td>397</td>\n","      <td>74</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>728</td>\n","      <td>58</td>\n","      <td>1183</td>\n","      <td>22</td>\n","      <td>1149</td>\n","      <td>215</td>\n","      <td>184</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>543</td>\n","      <td>34</td>\n","      <td>898</td>\n","      <td>22</td>\n","      <td>690</td>\n","      <td>245</td>\n","      <td>131</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>476</td>\n","      <td>26</td>\n","      <td>918</td>\n","      <td>15</td>\n","      <td>539</td>\n","      <td>130</td>\n","      <td>177</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["predito    0   1     2   3     4    5    6\n","real                                      \n","0        891  54   979  23   762  179  152\n","1        384  77   694  12   449  112   86\n","2        673  66  1814  21   781  158  156\n","3        335  26   636  28   397   74   79\n","4        728  58  1183  22  1149  215  184\n","5        543  34   898  22   690  245  131\n","6        476  26   918  15   539  130  177"]},"metadata":{"tags":[]},"execution_count":188}]},{"cell_type":"markdown","metadata":{"id":"0WcQeXtuRxAv","colab_type":"text"},"source":["MULTILAYER PERCEPTRON 2 CAMADAS"]},{"cell_type":"code","metadata":{"id":"NnxsGGErqvpU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593468355433,"user_tz":180,"elapsed":397366,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"56eb91ed-eeeb-4347-d16f-f8a6851debd0"},"source":["clf_mlp2 = MLPClassifier(solver='sgd'\n","                     , hidden_layer_sizes=(primeira_hl_mlp, segunda_hl_mlp)\n","                     , max_iter = (epocas * 2)\n","                     , random_state=1)\n","\n","clf_mlp2.out_activation_ = 'softmax'\n","\n","clf_mlp2.fit(x_train_prepared, y_train)\n","y_predicted_mlp2 = clf_mlp2.predict(x_test_prepared)\n","\n","accuracy_modelo2 = metrics.accuracy_score(y_test, y_predicted_mlp2).round(3)\n","print(accuracy_modelo2)"],"execution_count":189,"outputs":[{"output_type":"stream","text":["0.237\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DCAsYbL6Pbul","colab_type":"text"},"source":["NEAREST NEIGHBOR\n"]},{"cell_type":"code","metadata":{"id":"NbDURukLzmQP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593468380242,"user_tz":180,"elapsed":24765,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"20c109c4-0d71-496b-ae98-d29fb7336656"},"source":["neigh = KNeighborsClassifier(n_neighbors=2)\n","neigh.fit(x_train_prepared, y_train)\n","y_predicted_neigh = neigh.predict(x_test_prepared)\n","\n","accuracy_modelo3 = metrics.accuracy_score(y_test, y_predicted_neigh).round(3)\n","print(accuracy_modelo3)"],"execution_count":190,"outputs":[{"output_type":"stream","text":["0.313\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NZzE3MTc8Sb5","colab_type":"text"},"source":["RESHAPING PARA USO DOS MODELOS DOS KERAS"]},{"cell_type":"code","metadata":{"id":"x_dhZ8KWxfWM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593468380247,"user_tz":180,"elapsed":24730,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["#Reshaping\n","X_train = np.reshape(x_train_prepared, (x_train_prepared.shape[0], 1, x_train_prepared.shape[1]))\n","X_test = np.reshape(x_test_prepared, (x_test_prepared.shape[0], 1, x_test_prepared.shape[1]))"],"execution_count":191,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AEbPgwLyrsHB","colab_type":"text"},"source":["MODELO DE REDE NEURAL LSTM - 1 CAMADA ESCONDIDA"]},{"cell_type":"code","metadata":{"id":"_6K_XW2Protr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1593468380250,"user_tz":180,"elapsed":24686,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"a100c735-c721-4d2d-d37a-bfe003ed2c86"},"source":["#Initicializar a RNN\n","regressor = Sequential()\n"," \n","# Adicionar a primeira camada LSTM e Dropout \n","regressor.add(LSTM(units = primeiro_neuronio_lstm, input_shape=(1, x_train_prepared.shape[1])))\n","regressor.add(Dropout(0.2))\n"," \n","# camada de saída\n","regressor.add(Dense(units = camadas_saida, activation='softmax')) #para classificação dar como entrada as classes com função de ativação softmax\n","\n","# Compilar a rede\n","regressor.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Visualizar a rede\n","regressor.summary()"],"execution_count":192,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_9 (LSTM)                (None, 64)                38144     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 7)                 455       \n","=================================================================\n","Total params: 38,599\n","Trainable params: 38,599\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"izdwUQsmr8pr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593470930286,"user_tz":180,"elapsed":2574700,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"242cf961-d0f1-4e48-f567-96426317355e"},"source":["regressor.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = epocas, batch_size = 32)"],"execution_count":193,"outputs":[{"output_type":"stream","text":["Train on 73923 samples, validate on 18481 samples\n","Epoch 1/500\n","73923/73923 [==============================] - 5s 74us/step - loss: 1.8998 - accuracy: 0.2119 - val_loss: 1.8828 - val_accuracy: 0.2253\n","Epoch 2/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.8646 - accuracy: 0.2393 - val_loss: 1.8718 - val_accuracy: 0.2371\n","Epoch 3/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.8410 - accuracy: 0.2562 - val_loss: 1.8625 - val_accuracy: 0.2427\n","Epoch 4/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.8190 - accuracy: 0.2715 - val_loss: 1.8546 - val_accuracy: 0.2489\n","Epoch 5/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.8015 - accuracy: 0.2824 - val_loss: 1.8514 - val_accuracy: 0.2525\n","Epoch 6/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.7867 - accuracy: 0.2898 - val_loss: 1.8494 - val_accuracy: 0.2566\n","Epoch 7/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.7718 - accuracy: 0.2970 - val_loss: 1.8461 - val_accuracy: 0.2585\n","Epoch 8/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.7607 - accuracy: 0.3049 - val_loss: 1.8440 - val_accuracy: 0.2608\n","Epoch 9/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.7498 - accuracy: 0.3125 - val_loss: 1.8420 - val_accuracy: 0.2626\n","Epoch 10/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.7435 - accuracy: 0.3164 - val_loss: 1.8398 - val_accuracy: 0.2664\n","Epoch 11/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.7342 - accuracy: 0.3197 - val_loss: 1.8388 - val_accuracy: 0.2643\n","Epoch 12/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.7283 - accuracy: 0.3219 - val_loss: 1.8391 - val_accuracy: 0.2655\n","Epoch 13/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.7207 - accuracy: 0.3249 - val_loss: 1.8350 - val_accuracy: 0.2678\n","Epoch 14/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.7120 - accuracy: 0.3303 - val_loss: 1.8366 - val_accuracy: 0.2701\n","Epoch 15/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.7077 - accuracy: 0.3323 - val_loss: 1.8375 - val_accuracy: 0.2695\n","Epoch 16/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.7041 - accuracy: 0.3346 - val_loss: 1.8356 - val_accuracy: 0.2708\n","Epoch 17/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.6990 - accuracy: 0.3363 - val_loss: 1.8367 - val_accuracy: 0.2726\n","Epoch 18/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6932 - accuracy: 0.3385 - val_loss: 1.8352 - val_accuracy: 0.2743\n","Epoch 19/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6885 - accuracy: 0.3430 - val_loss: 1.8348 - val_accuracy: 0.2755\n","Epoch 20/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6849 - accuracy: 0.3441 - val_loss: 1.8342 - val_accuracy: 0.2705\n","Epoch 21/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6804 - accuracy: 0.3441 - val_loss: 1.8336 - val_accuracy: 0.2781\n","Epoch 22/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6765 - accuracy: 0.3471 - val_loss: 1.8328 - val_accuracy: 0.2736\n","Epoch 23/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6743 - accuracy: 0.3467 - val_loss: 1.8322 - val_accuracy: 0.2740\n","Epoch 24/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6719 - accuracy: 0.3479 - val_loss: 1.8338 - val_accuracy: 0.2757\n","Epoch 25/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6670 - accuracy: 0.3496 - val_loss: 1.8342 - val_accuracy: 0.2764\n","Epoch 26/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6654 - accuracy: 0.3515 - val_loss: 1.8337 - val_accuracy: 0.2764\n","Epoch 27/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6630 - accuracy: 0.3543 - val_loss: 1.8333 - val_accuracy: 0.2771\n","Epoch 28/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6601 - accuracy: 0.3535 - val_loss: 1.8337 - val_accuracy: 0.2771\n","Epoch 29/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6562 - accuracy: 0.3579 - val_loss: 1.8311 - val_accuracy: 0.2768\n","Epoch 30/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6550 - accuracy: 0.3552 - val_loss: 1.8312 - val_accuracy: 0.2771\n","Epoch 31/500\n","73923/73923 [==============================] - 5s 73us/step - loss: 1.6529 - accuracy: 0.3578 - val_loss: 1.8300 - val_accuracy: 0.2783\n","Epoch 32/500\n","73923/73923 [==============================] - 5s 73us/step - loss: 1.6497 - accuracy: 0.3565 - val_loss: 1.8312 - val_accuracy: 0.2751\n","Epoch 33/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6491 - accuracy: 0.3581 - val_loss: 1.8321 - val_accuracy: 0.2786\n","Epoch 34/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6475 - accuracy: 0.3607 - val_loss: 1.8312 - val_accuracy: 0.2793\n","Epoch 35/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6460 - accuracy: 0.3609 - val_loss: 1.8312 - val_accuracy: 0.2755\n","Epoch 36/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6409 - accuracy: 0.3619 - val_loss: 1.8315 - val_accuracy: 0.2822\n","Epoch 37/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6413 - accuracy: 0.3622 - val_loss: 1.8303 - val_accuracy: 0.2776\n","Epoch 38/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6401 - accuracy: 0.3631 - val_loss: 1.8321 - val_accuracy: 0.2783\n","Epoch 39/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.6373 - accuracy: 0.3650 - val_loss: 1.8309 - val_accuracy: 0.2793\n","Epoch 40/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6353 - accuracy: 0.3654 - val_loss: 1.8309 - val_accuracy: 0.2836\n","Epoch 41/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6340 - accuracy: 0.3674 - val_loss: 1.8322 - val_accuracy: 0.2796\n","Epoch 42/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6289 - accuracy: 0.3686 - val_loss: 1.8326 - val_accuracy: 0.2821\n","Epoch 43/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6317 - accuracy: 0.3676 - val_loss: 1.8332 - val_accuracy: 0.2820\n","Epoch 44/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6279 - accuracy: 0.3673 - val_loss: 1.8315 - val_accuracy: 0.2810\n","Epoch 45/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.6280 - accuracy: 0.3674 - val_loss: 1.8306 - val_accuracy: 0.2837\n","Epoch 46/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.6248 - accuracy: 0.3693 - val_loss: 1.8328 - val_accuracy: 0.2771\n","Epoch 47/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6243 - accuracy: 0.3697 - val_loss: 1.8312 - val_accuracy: 0.2799\n","Epoch 48/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6225 - accuracy: 0.3703 - val_loss: 1.8312 - val_accuracy: 0.2800\n","Epoch 49/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6181 - accuracy: 0.3730 - val_loss: 1.8305 - val_accuracy: 0.2814\n","Epoch 50/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6198 - accuracy: 0.3701 - val_loss: 1.8314 - val_accuracy: 0.2823\n","Epoch 51/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6196 - accuracy: 0.3715 - val_loss: 1.8302 - val_accuracy: 0.2820\n","Epoch 52/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6176 - accuracy: 0.3713 - val_loss: 1.8302 - val_accuracy: 0.2842\n","Epoch 53/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.6155 - accuracy: 0.3737 - val_loss: 1.8284 - val_accuracy: 0.2835\n","Epoch 54/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6155 - accuracy: 0.3729 - val_loss: 1.8320 - val_accuracy: 0.2828\n","Epoch 55/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.6132 - accuracy: 0.3736 - val_loss: 1.8302 - val_accuracy: 0.2842\n","Epoch 56/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6121 - accuracy: 0.3756 - val_loss: 1.8320 - val_accuracy: 0.2846\n","Epoch 57/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.6096 - accuracy: 0.3749 - val_loss: 1.8319 - val_accuracy: 0.2849\n","Epoch 58/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.6086 - accuracy: 0.3743 - val_loss: 1.8303 - val_accuracy: 0.2845\n","Epoch 59/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6065 - accuracy: 0.3768 - val_loss: 1.8297 - val_accuracy: 0.2861\n","Epoch 60/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.6051 - accuracy: 0.3782 - val_loss: 1.8290 - val_accuracy: 0.2854\n","Epoch 61/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6043 - accuracy: 0.3788 - val_loss: 1.8299 - val_accuracy: 0.2859\n","Epoch 62/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.6035 - accuracy: 0.3788 - val_loss: 1.8310 - val_accuracy: 0.2875\n","Epoch 63/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6032 - accuracy: 0.3786 - val_loss: 1.8288 - val_accuracy: 0.2852\n","Epoch 64/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6048 - accuracy: 0.3772 - val_loss: 1.8299 - val_accuracy: 0.2850\n","Epoch 65/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5995 - accuracy: 0.3800 - val_loss: 1.8281 - val_accuracy: 0.2860\n","Epoch 66/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6005 - accuracy: 0.3783 - val_loss: 1.8302 - val_accuracy: 0.2838\n","Epoch 67/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.6015 - accuracy: 0.3789 - val_loss: 1.8295 - val_accuracy: 0.2876\n","Epoch 68/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5962 - accuracy: 0.3810 - val_loss: 1.8294 - val_accuracy: 0.2865\n","Epoch 69/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5964 - accuracy: 0.3817 - val_loss: 1.8294 - val_accuracy: 0.2834\n","Epoch 70/500\n","73923/73923 [==============================] - 5s 73us/step - loss: 1.5955 - accuracy: 0.3819 - val_loss: 1.8291 - val_accuracy: 0.2889\n","Epoch 71/500\n","73923/73923 [==============================] - 5s 74us/step - loss: 1.5943 - accuracy: 0.3824 - val_loss: 1.8295 - val_accuracy: 0.2872\n","Epoch 72/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5962 - accuracy: 0.3810 - val_loss: 1.8293 - val_accuracy: 0.2884\n","Epoch 73/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5904 - accuracy: 0.3823 - val_loss: 1.8308 - val_accuracy: 0.2882\n","Epoch 74/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5920 - accuracy: 0.3831 - val_loss: 1.8301 - val_accuracy: 0.2865\n","Epoch 75/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5927 - accuracy: 0.3805 - val_loss: 1.8304 - val_accuracy: 0.2869\n","Epoch 76/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5928 - accuracy: 0.3808 - val_loss: 1.8300 - val_accuracy: 0.2866\n","Epoch 77/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5907 - accuracy: 0.3817 - val_loss: 1.8306 - val_accuracy: 0.2889\n","Epoch 78/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5903 - accuracy: 0.3821 - val_loss: 1.8310 - val_accuracy: 0.2870\n","Epoch 79/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5876 - accuracy: 0.3849 - val_loss: 1.8327 - val_accuracy: 0.2861\n","Epoch 80/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5865 - accuracy: 0.3837 - val_loss: 1.8320 - val_accuracy: 0.2873\n","Epoch 81/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5860 - accuracy: 0.3881 - val_loss: 1.8314 - val_accuracy: 0.2847\n","Epoch 82/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5869 - accuracy: 0.3838 - val_loss: 1.8317 - val_accuracy: 0.2886\n","Epoch 83/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5841 - accuracy: 0.3839 - val_loss: 1.8318 - val_accuracy: 0.2892\n","Epoch 84/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5849 - accuracy: 0.3853 - val_loss: 1.8303 - val_accuracy: 0.2886\n","Epoch 85/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5827 - accuracy: 0.3863 - val_loss: 1.8306 - val_accuracy: 0.2865\n","Epoch 86/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5823 - accuracy: 0.3858 - val_loss: 1.8305 - val_accuracy: 0.2898\n","Epoch 87/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5826 - accuracy: 0.3881 - val_loss: 1.8301 - val_accuracy: 0.2893\n","Epoch 88/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5829 - accuracy: 0.3868 - val_loss: 1.8309 - val_accuracy: 0.2858\n","Epoch 89/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5798 - accuracy: 0.3884 - val_loss: 1.8283 - val_accuracy: 0.2874\n","Epoch 90/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5790 - accuracy: 0.3888 - val_loss: 1.8305 - val_accuracy: 0.2893\n","Epoch 91/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5795 - accuracy: 0.3869 - val_loss: 1.8305 - val_accuracy: 0.2856\n","Epoch 92/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5782 - accuracy: 0.3866 - val_loss: 1.8289 - val_accuracy: 0.2884\n","Epoch 93/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5784 - accuracy: 0.3892 - val_loss: 1.8287 - val_accuracy: 0.2904\n","Epoch 94/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5779 - accuracy: 0.3876 - val_loss: 1.8294 - val_accuracy: 0.2894\n","Epoch 95/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5796 - accuracy: 0.3870 - val_loss: 1.8300 - val_accuracy: 0.2899\n","Epoch 96/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5737 - accuracy: 0.3900 - val_loss: 1.8293 - val_accuracy: 0.2881\n","Epoch 97/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5751 - accuracy: 0.3897 - val_loss: 1.8285 - val_accuracy: 0.2915\n","Epoch 98/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5763 - accuracy: 0.3884 - val_loss: 1.8308 - val_accuracy: 0.2898\n","Epoch 99/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5733 - accuracy: 0.3922 - val_loss: 1.8295 - val_accuracy: 0.2913\n","Epoch 100/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5739 - accuracy: 0.3891 - val_loss: 1.8292 - val_accuracy: 0.2917\n","Epoch 101/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5719 - accuracy: 0.3912 - val_loss: 1.8295 - val_accuracy: 0.2917\n","Epoch 102/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5734 - accuracy: 0.3901 - val_loss: 1.8303 - val_accuracy: 0.2933\n","Epoch 103/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5703 - accuracy: 0.3906 - val_loss: 1.8315 - val_accuracy: 0.2888\n","Epoch 104/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5714 - accuracy: 0.3920 - val_loss: 1.8292 - val_accuracy: 0.2919\n","Epoch 105/500\n","73923/73923 [==============================] - 7s 89us/step - loss: 1.5694 - accuracy: 0.3917 - val_loss: 1.8310 - val_accuracy: 0.2917\n","Epoch 106/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5700 - accuracy: 0.3912 - val_loss: 1.8320 - val_accuracy: 0.2914\n","Epoch 107/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5699 - accuracy: 0.3921 - val_loss: 1.8290 - val_accuracy: 0.2891\n","Epoch 108/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5677 - accuracy: 0.3924 - val_loss: 1.8290 - val_accuracy: 0.2914\n","Epoch 109/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5661 - accuracy: 0.3927 - val_loss: 1.8329 - val_accuracy: 0.2908\n","Epoch 110/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5684 - accuracy: 0.3914 - val_loss: 1.8309 - val_accuracy: 0.2918\n","Epoch 111/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5648 - accuracy: 0.3932 - val_loss: 1.8302 - val_accuracy: 0.2902\n","Epoch 112/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5667 - accuracy: 0.3934 - val_loss: 1.8301 - val_accuracy: 0.2900\n","Epoch 113/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5656 - accuracy: 0.3917 - val_loss: 1.8300 - val_accuracy: 0.2902\n","Epoch 114/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5661 - accuracy: 0.3920 - val_loss: 1.8297 - val_accuracy: 0.2901\n","Epoch 115/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5658 - accuracy: 0.3940 - val_loss: 1.8291 - val_accuracy: 0.2913\n","Epoch 116/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5625 - accuracy: 0.3946 - val_loss: 1.8295 - val_accuracy: 0.2882\n","Epoch 117/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5650 - accuracy: 0.3936 - val_loss: 1.8299 - val_accuracy: 0.2905\n","Epoch 118/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5610 - accuracy: 0.3955 - val_loss: 1.8290 - val_accuracy: 0.2915\n","Epoch 119/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5631 - accuracy: 0.3943 - val_loss: 1.8318 - val_accuracy: 0.2933\n","Epoch 120/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5625 - accuracy: 0.3927 - val_loss: 1.8304 - val_accuracy: 0.2906\n","Epoch 121/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5610 - accuracy: 0.3946 - val_loss: 1.8315 - val_accuracy: 0.2917\n","Epoch 122/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5620 - accuracy: 0.3945 - val_loss: 1.8306 - val_accuracy: 0.2914\n","Epoch 123/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5584 - accuracy: 0.3969 - val_loss: 1.8299 - val_accuracy: 0.2921\n","Epoch 124/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5612 - accuracy: 0.3924 - val_loss: 1.8301 - val_accuracy: 0.2941\n","Epoch 125/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5563 - accuracy: 0.3973 - val_loss: 1.8322 - val_accuracy: 0.2920\n","Epoch 126/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5581 - accuracy: 0.3962 - val_loss: 1.8322 - val_accuracy: 0.2915\n","Epoch 127/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5572 - accuracy: 0.3972 - val_loss: 1.8303 - val_accuracy: 0.2940\n","Epoch 128/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5569 - accuracy: 0.3961 - val_loss: 1.8293 - val_accuracy: 0.2946\n","Epoch 129/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5571 - accuracy: 0.3978 - val_loss: 1.8296 - val_accuracy: 0.2934\n","Epoch 130/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5583 - accuracy: 0.3952 - val_loss: 1.8294 - val_accuracy: 0.2926\n","Epoch 131/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5583 - accuracy: 0.3974 - val_loss: 1.8308 - val_accuracy: 0.2937\n","Epoch 132/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5574 - accuracy: 0.3949 - val_loss: 1.8309 - val_accuracy: 0.2916\n","Epoch 133/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5545 - accuracy: 0.3978 - val_loss: 1.8308 - val_accuracy: 0.2934\n","Epoch 134/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5529 - accuracy: 0.3982 - val_loss: 1.8320 - val_accuracy: 0.2939\n","Epoch 135/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5578 - accuracy: 0.3950 - val_loss: 1.8300 - val_accuracy: 0.2957\n","Epoch 136/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5562 - accuracy: 0.3963 - val_loss: 1.8301 - val_accuracy: 0.2922\n","Epoch 137/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5527 - accuracy: 0.3988 - val_loss: 1.8326 - val_accuracy: 0.2912\n","Epoch 138/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5533 - accuracy: 0.3991 - val_loss: 1.8328 - val_accuracy: 0.2916\n","Epoch 139/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5537 - accuracy: 0.3999 - val_loss: 1.8315 - val_accuracy: 0.2946\n","Epoch 140/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5526 - accuracy: 0.3978 - val_loss: 1.8311 - val_accuracy: 0.2929\n","Epoch 141/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5520 - accuracy: 0.3998 - val_loss: 1.8305 - val_accuracy: 0.2965\n","Epoch 142/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5516 - accuracy: 0.3996 - val_loss: 1.8313 - val_accuracy: 0.2971\n","Epoch 143/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5516 - accuracy: 0.3992 - val_loss: 1.8326 - val_accuracy: 0.2941\n","Epoch 144/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5500 - accuracy: 0.3997 - val_loss: 1.8318 - val_accuracy: 0.2954\n","Epoch 145/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5499 - accuracy: 0.4011 - val_loss: 1.8306 - val_accuracy: 0.2944\n","Epoch 146/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5489 - accuracy: 0.4000 - val_loss: 1.8299 - val_accuracy: 0.2935\n","Epoch 147/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5503 - accuracy: 0.3990 - val_loss: 1.8324 - val_accuracy: 0.2950\n","Epoch 148/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5509 - accuracy: 0.3992 - val_loss: 1.8306 - val_accuracy: 0.2940\n","Epoch 149/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5505 - accuracy: 0.3986 - val_loss: 1.8306 - val_accuracy: 0.2935\n","Epoch 150/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5502 - accuracy: 0.4010 - val_loss: 1.8285 - val_accuracy: 0.2961\n","Epoch 151/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5465 - accuracy: 0.4015 - val_loss: 1.8316 - val_accuracy: 0.2963\n","Epoch 152/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5497 - accuracy: 0.4008 - val_loss: 1.8314 - val_accuracy: 0.2955\n","Epoch 153/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5486 - accuracy: 0.4000 - val_loss: 1.8308 - val_accuracy: 0.2951\n","Epoch 154/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5470 - accuracy: 0.3991 - val_loss: 1.8323 - val_accuracy: 0.2946\n","Epoch 155/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5502 - accuracy: 0.3997 - val_loss: 1.8306 - val_accuracy: 0.2955\n","Epoch 156/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5477 - accuracy: 0.4000 - val_loss: 1.8300 - val_accuracy: 0.2964\n","Epoch 157/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5451 - accuracy: 0.4020 - val_loss: 1.8302 - val_accuracy: 0.2961\n","Epoch 158/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5471 - accuracy: 0.4005 - val_loss: 1.8290 - val_accuracy: 0.2969\n","Epoch 159/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5452 - accuracy: 0.4021 - val_loss: 1.8294 - val_accuracy: 0.2954\n","Epoch 160/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5443 - accuracy: 0.4009 - val_loss: 1.8310 - val_accuracy: 0.2942\n","Epoch 161/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5460 - accuracy: 0.4004 - val_loss: 1.8304 - val_accuracy: 0.2972\n","Epoch 162/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5465 - accuracy: 0.4011 - val_loss: 1.8298 - val_accuracy: 0.2944\n","Epoch 163/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5449 - accuracy: 0.4021 - val_loss: 1.8307 - val_accuracy: 0.2951\n","Epoch 164/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5416 - accuracy: 0.4040 - val_loss: 1.8325 - val_accuracy: 0.2937\n","Epoch 165/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5436 - accuracy: 0.4038 - val_loss: 1.8324 - val_accuracy: 0.2948\n","Epoch 166/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5424 - accuracy: 0.4029 - val_loss: 1.8321 - val_accuracy: 0.2962\n","Epoch 167/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5438 - accuracy: 0.4015 - val_loss: 1.8317 - val_accuracy: 0.2943\n","Epoch 168/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5410 - accuracy: 0.4021 - val_loss: 1.8312 - val_accuracy: 0.2966\n","Epoch 169/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5450 - accuracy: 0.4012 - val_loss: 1.8296 - val_accuracy: 0.2971\n","Epoch 170/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5414 - accuracy: 0.4035 - val_loss: 1.8309 - val_accuracy: 0.2965\n","Epoch 171/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5442 - accuracy: 0.4011 - val_loss: 1.8301 - val_accuracy: 0.2963\n","Epoch 172/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5436 - accuracy: 0.4030 - val_loss: 1.8307 - val_accuracy: 0.2950\n","Epoch 173/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5423 - accuracy: 0.4005 - val_loss: 1.8297 - val_accuracy: 0.2964\n","Epoch 174/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5402 - accuracy: 0.4024 - val_loss: 1.8311 - val_accuracy: 0.2968\n","Epoch 175/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5391 - accuracy: 0.4045 - val_loss: 1.8316 - val_accuracy: 0.2956\n","Epoch 176/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5386 - accuracy: 0.4042 - val_loss: 1.8331 - val_accuracy: 0.2961\n","Epoch 177/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5418 - accuracy: 0.4027 - val_loss: 1.8298 - val_accuracy: 0.2945\n","Epoch 178/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5406 - accuracy: 0.4026 - val_loss: 1.8299 - val_accuracy: 0.2938\n","Epoch 179/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5395 - accuracy: 0.4045 - val_loss: 1.8296 - val_accuracy: 0.2950\n","Epoch 180/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5403 - accuracy: 0.4029 - val_loss: 1.8304 - val_accuracy: 0.2953\n","Epoch 181/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5367 - accuracy: 0.4065 - val_loss: 1.8303 - val_accuracy: 0.2960\n","Epoch 182/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5374 - accuracy: 0.4043 - val_loss: 1.8315 - val_accuracy: 0.2952\n","Epoch 183/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5400 - accuracy: 0.4042 - val_loss: 1.8311 - val_accuracy: 0.2950\n","Epoch 184/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5398 - accuracy: 0.4043 - val_loss: 1.8309 - val_accuracy: 0.2965\n","Epoch 185/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5398 - accuracy: 0.4039 - val_loss: 1.8311 - val_accuracy: 0.2970\n","Epoch 186/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5373 - accuracy: 0.4054 - val_loss: 1.8306 - val_accuracy: 0.2970\n","Epoch 187/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5379 - accuracy: 0.4070 - val_loss: 1.8304 - val_accuracy: 0.2951\n","Epoch 188/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5372 - accuracy: 0.4032 - val_loss: 1.8306 - val_accuracy: 0.2967\n","Epoch 189/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5344 - accuracy: 0.4061 - val_loss: 1.8313 - val_accuracy: 0.2964\n","Epoch 190/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5358 - accuracy: 0.4052 - val_loss: 1.8324 - val_accuracy: 0.2957\n","Epoch 191/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5379 - accuracy: 0.4036 - val_loss: 1.8297 - val_accuracy: 0.2974\n","Epoch 192/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5352 - accuracy: 0.4088 - val_loss: 1.8314 - val_accuracy: 0.2972\n","Epoch 193/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5364 - accuracy: 0.4046 - val_loss: 1.8286 - val_accuracy: 0.2973\n","Epoch 194/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5357 - accuracy: 0.4030 - val_loss: 1.8321 - val_accuracy: 0.2966\n","Epoch 195/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5357 - accuracy: 0.4062 - val_loss: 1.8321 - val_accuracy: 0.2966\n","Epoch 196/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5350 - accuracy: 0.4051 - val_loss: 1.8307 - val_accuracy: 0.2966\n","Epoch 197/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5343 - accuracy: 0.4047 - val_loss: 1.8321 - val_accuracy: 0.2977\n","Epoch 198/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5355 - accuracy: 0.4058 - val_loss: 1.8308 - val_accuracy: 0.2979\n","Epoch 199/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5328 - accuracy: 0.4087 - val_loss: 1.8290 - val_accuracy: 0.2962\n","Epoch 200/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5332 - accuracy: 0.4060 - val_loss: 1.8319 - val_accuracy: 0.2948\n","Epoch 201/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5334 - accuracy: 0.4056 - val_loss: 1.8320 - val_accuracy: 0.2961\n","Epoch 202/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5367 - accuracy: 0.4031 - val_loss: 1.8321 - val_accuracy: 0.2967\n","Epoch 203/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5305 - accuracy: 0.4076 - val_loss: 1.8342 - val_accuracy: 0.2937\n","Epoch 204/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5331 - accuracy: 0.4071 - val_loss: 1.8337 - val_accuracy: 0.2955\n","Epoch 205/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5305 - accuracy: 0.4100 - val_loss: 1.8330 - val_accuracy: 0.2984\n","Epoch 206/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5318 - accuracy: 0.4060 - val_loss: 1.8311 - val_accuracy: 0.2985\n","Epoch 207/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5330 - accuracy: 0.4080 - val_loss: 1.8316 - val_accuracy: 0.2945\n","Epoch 208/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5315 - accuracy: 0.4075 - val_loss: 1.8299 - val_accuracy: 0.2957\n","Epoch 209/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5328 - accuracy: 0.4078 - val_loss: 1.8303 - val_accuracy: 0.2975\n","Epoch 210/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5322 - accuracy: 0.4074 - val_loss: 1.8294 - val_accuracy: 0.2975\n","Epoch 211/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5301 - accuracy: 0.4094 - val_loss: 1.8311 - val_accuracy: 0.2993\n","Epoch 212/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5316 - accuracy: 0.4048 - val_loss: 1.8289 - val_accuracy: 0.2968\n","Epoch 213/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5329 - accuracy: 0.4064 - val_loss: 1.8289 - val_accuracy: 0.2984\n","Epoch 214/500\n","73923/73923 [==============================] - 5s 74us/step - loss: 1.5299 - accuracy: 0.4062 - val_loss: 1.8296 - val_accuracy: 0.2963\n","Epoch 215/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5310 - accuracy: 0.4062 - val_loss: 1.8290 - val_accuracy: 0.2968\n","Epoch 216/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5303 - accuracy: 0.4076 - val_loss: 1.8284 - val_accuracy: 0.2979\n","Epoch 217/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5319 - accuracy: 0.4059 - val_loss: 1.8297 - val_accuracy: 0.2956\n","Epoch 218/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5275 - accuracy: 0.4085 - val_loss: 1.8295 - val_accuracy: 0.2954\n","Epoch 219/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5323 - accuracy: 0.4054 - val_loss: 1.8283 - val_accuracy: 0.2966\n","Epoch 220/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5275 - accuracy: 0.4082 - val_loss: 1.8318 - val_accuracy: 0.2978\n","Epoch 221/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5302 - accuracy: 0.4059 - val_loss: 1.8305 - val_accuracy: 0.2976\n","Epoch 222/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5287 - accuracy: 0.4075 - val_loss: 1.8329 - val_accuracy: 0.2957\n","Epoch 223/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5258 - accuracy: 0.4109 - val_loss: 1.8328 - val_accuracy: 0.2975\n","Epoch 224/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5294 - accuracy: 0.4070 - val_loss: 1.8311 - val_accuracy: 0.2960\n","Epoch 225/500\n","73923/73923 [==============================] - 6s 87us/step - loss: 1.5302 - accuracy: 0.4070 - val_loss: 1.8312 - val_accuracy: 0.2973\n","Epoch 226/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5280 - accuracy: 0.4078 - val_loss: 1.8314 - val_accuracy: 0.2980\n","Epoch 227/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5264 - accuracy: 0.4072 - val_loss: 1.8310 - val_accuracy: 0.2979\n","Epoch 228/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5243 - accuracy: 0.4092 - val_loss: 1.8319 - val_accuracy: 0.2986\n","Epoch 229/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5262 - accuracy: 0.4105 - val_loss: 1.8308 - val_accuracy: 0.2960\n","Epoch 230/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5280 - accuracy: 0.4096 - val_loss: 1.8314 - val_accuracy: 0.2963\n","Epoch 231/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5245 - accuracy: 0.4097 - val_loss: 1.8310 - val_accuracy: 0.2961\n","Epoch 232/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5260 - accuracy: 0.4077 - val_loss: 1.8316 - val_accuracy: 0.2958\n","Epoch 233/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5249 - accuracy: 0.4076 - val_loss: 1.8296 - val_accuracy: 0.2961\n","Epoch 234/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5259 - accuracy: 0.4096 - val_loss: 1.8307 - val_accuracy: 0.2971\n","Epoch 235/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5274 - accuracy: 0.4081 - val_loss: 1.8307 - val_accuracy: 0.2967\n","Epoch 236/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5243 - accuracy: 0.4114 - val_loss: 1.8323 - val_accuracy: 0.2951\n","Epoch 237/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5264 - accuracy: 0.4090 - val_loss: 1.8311 - val_accuracy: 0.2976\n","Epoch 238/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5255 - accuracy: 0.4087 - val_loss: 1.8308 - val_accuracy: 0.2978\n","Epoch 239/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5228 - accuracy: 0.4110 - val_loss: 1.8324 - val_accuracy: 0.2956\n","Epoch 240/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5251 - accuracy: 0.4097 - val_loss: 1.8319 - val_accuracy: 0.2957\n","Epoch 241/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5227 - accuracy: 0.4114 - val_loss: 1.8327 - val_accuracy: 0.2967\n","Epoch 242/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5247 - accuracy: 0.4101 - val_loss: 1.8320 - val_accuracy: 0.2970\n","Epoch 243/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5216 - accuracy: 0.4118 - val_loss: 1.8325 - val_accuracy: 0.2990\n","Epoch 244/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5238 - accuracy: 0.4098 - val_loss: 1.8310 - val_accuracy: 0.2954\n","Epoch 245/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5235 - accuracy: 0.4111 - val_loss: 1.8310 - val_accuracy: 0.2968\n","Epoch 246/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5224 - accuracy: 0.4093 - val_loss: 1.8319 - val_accuracy: 0.2958\n","Epoch 247/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5226 - accuracy: 0.4105 - val_loss: 1.8314 - val_accuracy: 0.2933\n","Epoch 248/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5223 - accuracy: 0.4103 - val_loss: 1.8315 - val_accuracy: 0.2984\n","Epoch 249/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5227 - accuracy: 0.4112 - val_loss: 1.8316 - val_accuracy: 0.2964\n","Epoch 250/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5217 - accuracy: 0.4098 - val_loss: 1.8308 - val_accuracy: 0.2973\n","Epoch 251/500\n","73923/73923 [==============================] - 5s 74us/step - loss: 1.5204 - accuracy: 0.4108 - val_loss: 1.8324 - val_accuracy: 0.2966\n","Epoch 252/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5228 - accuracy: 0.4115 - val_loss: 1.8315 - val_accuracy: 0.2955\n","Epoch 253/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5240 - accuracy: 0.4092 - val_loss: 1.8307 - val_accuracy: 0.2958\n","Epoch 254/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5238 - accuracy: 0.4097 - val_loss: 1.8306 - val_accuracy: 0.2956\n","Epoch 255/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5214 - accuracy: 0.4116 - val_loss: 1.8315 - val_accuracy: 0.2970\n","Epoch 256/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5225 - accuracy: 0.4092 - val_loss: 1.8303 - val_accuracy: 0.2942\n","Epoch 257/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5204 - accuracy: 0.4137 - val_loss: 1.8314 - val_accuracy: 0.2963\n","Epoch 258/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5223 - accuracy: 0.4100 - val_loss: 1.8304 - val_accuracy: 0.2975\n","Epoch 259/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5202 - accuracy: 0.4120 - val_loss: 1.8315 - val_accuracy: 0.2971\n","Epoch 260/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5196 - accuracy: 0.4139 - val_loss: 1.8323 - val_accuracy: 0.2969\n","Epoch 261/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5218 - accuracy: 0.4108 - val_loss: 1.8308 - val_accuracy: 0.2978\n","Epoch 262/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5228 - accuracy: 0.4089 - val_loss: 1.8312 - val_accuracy: 0.2971\n","Epoch 263/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5214 - accuracy: 0.4104 - val_loss: 1.8313 - val_accuracy: 0.2966\n","Epoch 264/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5216 - accuracy: 0.4105 - val_loss: 1.8319 - val_accuracy: 0.2989\n","Epoch 265/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5211 - accuracy: 0.4109 - val_loss: 1.8308 - val_accuracy: 0.2965\n","Epoch 266/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5196 - accuracy: 0.4103 - val_loss: 1.8311 - val_accuracy: 0.2954\n","Epoch 267/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5172 - accuracy: 0.4123 - val_loss: 1.8329 - val_accuracy: 0.2981\n","Epoch 268/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5209 - accuracy: 0.4102 - val_loss: 1.8315 - val_accuracy: 0.2949\n","Epoch 269/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5193 - accuracy: 0.4107 - val_loss: 1.8319 - val_accuracy: 0.2981\n","Epoch 270/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5185 - accuracy: 0.4102 - val_loss: 1.8326 - val_accuracy: 0.2993\n","Epoch 271/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5197 - accuracy: 0.4120 - val_loss: 1.8321 - val_accuracy: 0.2991\n","Epoch 272/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5155 - accuracy: 0.4133 - val_loss: 1.8338 - val_accuracy: 0.2975\n","Epoch 273/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5203 - accuracy: 0.4087 - val_loss: 1.8332 - val_accuracy: 0.2979\n","Epoch 274/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5210 - accuracy: 0.4113 - val_loss: 1.8307 - val_accuracy: 0.2965\n","Epoch 275/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5186 - accuracy: 0.4099 - val_loss: 1.8310 - val_accuracy: 0.2965\n","Epoch 276/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5173 - accuracy: 0.4129 - val_loss: 1.8321 - val_accuracy: 0.2971\n","Epoch 277/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5168 - accuracy: 0.4123 - val_loss: 1.8333 - val_accuracy: 0.2961\n","Epoch 278/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5175 - accuracy: 0.4105 - val_loss: 1.8327 - val_accuracy: 0.2976\n","Epoch 279/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5170 - accuracy: 0.4126 - val_loss: 1.8329 - val_accuracy: 0.2960\n","Epoch 280/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5176 - accuracy: 0.4123 - val_loss: 1.8320 - val_accuracy: 0.2986\n","Epoch 281/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5188 - accuracy: 0.4118 - val_loss: 1.8314 - val_accuracy: 0.2982\n","Epoch 282/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5160 - accuracy: 0.4134 - val_loss: 1.8316 - val_accuracy: 0.2969\n","Epoch 283/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5179 - accuracy: 0.4108 - val_loss: 1.8309 - val_accuracy: 0.2982\n","Epoch 284/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5151 - accuracy: 0.4133 - val_loss: 1.8307 - val_accuracy: 0.2979\n","Epoch 285/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5187 - accuracy: 0.4117 - val_loss: 1.8314 - val_accuracy: 0.2971\n","Epoch 286/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5136 - accuracy: 0.4132 - val_loss: 1.8321 - val_accuracy: 0.2979\n","Epoch 287/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5146 - accuracy: 0.4152 - val_loss: 1.8309 - val_accuracy: 0.2969\n","Epoch 288/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5181 - accuracy: 0.4107 - val_loss: 1.8314 - val_accuracy: 0.3006\n","Epoch 289/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5128 - accuracy: 0.4150 - val_loss: 1.8332 - val_accuracy: 0.2989\n","Epoch 290/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5139 - accuracy: 0.4132 - val_loss: 1.8326 - val_accuracy: 0.2963\n","Epoch 291/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5163 - accuracy: 0.4125 - val_loss: 1.8324 - val_accuracy: 0.2992\n","Epoch 292/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5170 - accuracy: 0.4111 - val_loss: 1.8334 - val_accuracy: 0.2965\n","Epoch 293/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5168 - accuracy: 0.4124 - val_loss: 1.8295 - val_accuracy: 0.2961\n","Epoch 294/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5141 - accuracy: 0.4127 - val_loss: 1.8318 - val_accuracy: 0.2951\n","Epoch 295/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5141 - accuracy: 0.4150 - val_loss: 1.8324 - val_accuracy: 0.2978\n","Epoch 296/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5154 - accuracy: 0.4122 - val_loss: 1.8328 - val_accuracy: 0.2964\n","Epoch 297/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5152 - accuracy: 0.4135 - val_loss: 1.8323 - val_accuracy: 0.2957\n","Epoch 298/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5146 - accuracy: 0.4132 - val_loss: 1.8315 - val_accuracy: 0.2984\n","Epoch 299/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5130 - accuracy: 0.4138 - val_loss: 1.8332 - val_accuracy: 0.2975\n","Epoch 300/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5128 - accuracy: 0.4146 - val_loss: 1.8326 - val_accuracy: 0.2965\n","Epoch 301/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5164 - accuracy: 0.4121 - val_loss: 1.8317 - val_accuracy: 0.2972\n","Epoch 302/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5125 - accuracy: 0.4133 - val_loss: 1.8328 - val_accuracy: 0.2973\n","Epoch 303/500\n","73923/73923 [==============================] - 5s 73us/step - loss: 1.5133 - accuracy: 0.4138 - val_loss: 1.8305 - val_accuracy: 0.2969\n","Epoch 304/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5127 - accuracy: 0.4147 - val_loss: 1.8322 - val_accuracy: 0.2977\n","Epoch 305/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5149 - accuracy: 0.4139 - val_loss: 1.8327 - val_accuracy: 0.2963\n","Epoch 306/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5117 - accuracy: 0.4140 - val_loss: 1.8315 - val_accuracy: 0.2979\n","Epoch 307/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5140 - accuracy: 0.4132 - val_loss: 1.8314 - val_accuracy: 0.2987\n","Epoch 308/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5131 - accuracy: 0.4122 - val_loss: 1.8308 - val_accuracy: 0.2978\n","Epoch 309/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5120 - accuracy: 0.4142 - val_loss: 1.8308 - val_accuracy: 0.2983\n","Epoch 310/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5130 - accuracy: 0.4133 - val_loss: 1.8312 - val_accuracy: 0.2975\n","Epoch 311/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5107 - accuracy: 0.4146 - val_loss: 1.8330 - val_accuracy: 0.2959\n","Epoch 312/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5119 - accuracy: 0.4151 - val_loss: 1.8321 - val_accuracy: 0.2966\n","Epoch 313/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5119 - accuracy: 0.4143 - val_loss: 1.8317 - val_accuracy: 0.2995\n","Epoch 314/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5102 - accuracy: 0.4155 - val_loss: 1.8306 - val_accuracy: 0.2976\n","Epoch 315/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5122 - accuracy: 0.4146 - val_loss: 1.8313 - val_accuracy: 0.2955\n","Epoch 316/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5110 - accuracy: 0.4138 - val_loss: 1.8310 - val_accuracy: 0.2983\n","Epoch 317/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5096 - accuracy: 0.4155 - val_loss: 1.8319 - val_accuracy: 0.2982\n","Epoch 318/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5105 - accuracy: 0.4150 - val_loss: 1.8326 - val_accuracy: 0.2980\n","Epoch 319/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5107 - accuracy: 0.4141 - val_loss: 1.8314 - val_accuracy: 0.3007\n","Epoch 320/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5122 - accuracy: 0.4137 - val_loss: 1.8342 - val_accuracy: 0.2985\n","Epoch 321/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5112 - accuracy: 0.4138 - val_loss: 1.8335 - val_accuracy: 0.2990\n","Epoch 322/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5085 - accuracy: 0.4159 - val_loss: 1.8341 - val_accuracy: 0.2968\n","Epoch 323/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5116 - accuracy: 0.4149 - val_loss: 1.8320 - val_accuracy: 0.2964\n","Epoch 324/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5101 - accuracy: 0.4139 - val_loss: 1.8328 - val_accuracy: 0.2965\n","Epoch 325/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5109 - accuracy: 0.4155 - val_loss: 1.8347 - val_accuracy: 0.2965\n","Epoch 326/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5095 - accuracy: 0.4157 - val_loss: 1.8319 - val_accuracy: 0.2958\n","Epoch 327/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5082 - accuracy: 0.4177 - val_loss: 1.8340 - val_accuracy: 0.2977\n","Epoch 328/500\n","73923/73923 [==============================] - 5s 73us/step - loss: 1.5099 - accuracy: 0.4144 - val_loss: 1.8355 - val_accuracy: 0.2971\n","Epoch 329/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5110 - accuracy: 0.4144 - val_loss: 1.8331 - val_accuracy: 0.2972\n","Epoch 330/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5096 - accuracy: 0.4155 - val_loss: 1.8332 - val_accuracy: 0.2981\n","Epoch 331/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5102 - accuracy: 0.4148 - val_loss: 1.8346 - val_accuracy: 0.2957\n","Epoch 332/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5097 - accuracy: 0.4165 - val_loss: 1.8313 - val_accuracy: 0.2968\n","Epoch 333/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5083 - accuracy: 0.4167 - val_loss: 1.8327 - val_accuracy: 0.2970\n","Epoch 334/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5072 - accuracy: 0.4161 - val_loss: 1.8334 - val_accuracy: 0.2991\n","Epoch 335/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5092 - accuracy: 0.4157 - val_loss: 1.8326 - val_accuracy: 0.2970\n","Epoch 336/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5089 - accuracy: 0.4147 - val_loss: 1.8334 - val_accuracy: 0.2972\n","Epoch 337/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5119 - accuracy: 0.4115 - val_loss: 1.8327 - val_accuracy: 0.2974\n","Epoch 338/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5091 - accuracy: 0.4162 - val_loss: 1.8334 - val_accuracy: 0.2983\n","Epoch 339/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.5098 - accuracy: 0.4150 - val_loss: 1.8319 - val_accuracy: 0.2990\n","Epoch 340/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5101 - accuracy: 0.4157 - val_loss: 1.8315 - val_accuracy: 0.2987\n","Epoch 341/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5101 - accuracy: 0.4164 - val_loss: 1.8321 - val_accuracy: 0.2999\n","Epoch 342/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5085 - accuracy: 0.4176 - val_loss: 1.8322 - val_accuracy: 0.2981\n","Epoch 343/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5090 - accuracy: 0.4135 - val_loss: 1.8334 - val_accuracy: 0.2974\n","Epoch 344/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5063 - accuracy: 0.4165 - val_loss: 1.8329 - val_accuracy: 0.2967\n","Epoch 345/500\n","73923/73923 [==============================] - 6s 83us/step - loss: 1.5083 - accuracy: 0.4166 - val_loss: 1.8327 - val_accuracy: 0.2989\n","Epoch 346/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5073 - accuracy: 0.4152 - val_loss: 1.8336 - val_accuracy: 0.2980\n","Epoch 347/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5093 - accuracy: 0.4160 - val_loss: 1.8331 - val_accuracy: 0.2979\n","Epoch 348/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5070 - accuracy: 0.4169 - val_loss: 1.8338 - val_accuracy: 0.2987\n","Epoch 349/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5047 - accuracy: 0.4171 - val_loss: 1.8353 - val_accuracy: 0.2965\n","Epoch 350/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5053 - accuracy: 0.4192 - val_loss: 1.8350 - val_accuracy: 0.2979\n","Epoch 351/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5062 - accuracy: 0.4163 - val_loss: 1.8336 - val_accuracy: 0.2974\n","Epoch 352/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5060 - accuracy: 0.4196 - val_loss: 1.8334 - val_accuracy: 0.2985\n","Epoch 353/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5054 - accuracy: 0.4161 - val_loss: 1.8361 - val_accuracy: 0.2967\n","Epoch 354/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5082 - accuracy: 0.4148 - val_loss: 1.8340 - val_accuracy: 0.2974\n","Epoch 355/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5068 - accuracy: 0.4165 - val_loss: 1.8344 - val_accuracy: 0.2947\n","Epoch 356/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5058 - accuracy: 0.4162 - val_loss: 1.8326 - val_accuracy: 0.2966\n","Epoch 357/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5056 - accuracy: 0.4157 - val_loss: 1.8337 - val_accuracy: 0.2984\n","Epoch 358/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5060 - accuracy: 0.4169 - val_loss: 1.8334 - val_accuracy: 0.2972\n","Epoch 359/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5076 - accuracy: 0.4140 - val_loss: 1.8337 - val_accuracy: 0.2992\n","Epoch 360/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5052 - accuracy: 0.4172 - val_loss: 1.8336 - val_accuracy: 0.3013\n","Epoch 361/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5062 - accuracy: 0.4160 - val_loss: 1.8324 - val_accuracy: 0.3007\n","Epoch 362/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5074 - accuracy: 0.4170 - val_loss: 1.8315 - val_accuracy: 0.2984\n","Epoch 363/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5071 - accuracy: 0.4151 - val_loss: 1.8323 - val_accuracy: 0.2992\n","Epoch 364/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5035 - accuracy: 0.4167 - val_loss: 1.8339 - val_accuracy: 0.2981\n","Epoch 365/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5059 - accuracy: 0.4164 - val_loss: 1.8334 - val_accuracy: 0.2984\n","Epoch 366/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5029 - accuracy: 0.4172 - val_loss: 1.8339 - val_accuracy: 0.2976\n","Epoch 367/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5061 - accuracy: 0.4152 - val_loss: 1.8349 - val_accuracy: 0.2986\n","Epoch 368/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5036 - accuracy: 0.4176 - val_loss: 1.8339 - val_accuracy: 0.3001\n","Epoch 369/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5047 - accuracy: 0.4170 - val_loss: 1.8336 - val_accuracy: 0.2985\n","Epoch 370/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5020 - accuracy: 0.4190 - val_loss: 1.8345 - val_accuracy: 0.2975\n","Epoch 371/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5027 - accuracy: 0.4174 - val_loss: 1.8348 - val_accuracy: 0.3003\n","Epoch 372/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5029 - accuracy: 0.4173 - val_loss: 1.8348 - val_accuracy: 0.2990\n","Epoch 373/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5053 - accuracy: 0.4171 - val_loss: 1.8338 - val_accuracy: 0.2992\n","Epoch 374/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5014 - accuracy: 0.4176 - val_loss: 1.8329 - val_accuracy: 0.2983\n","Epoch 375/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5045 - accuracy: 0.4172 - val_loss: 1.8336 - val_accuracy: 0.2988\n","Epoch 376/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5030 - accuracy: 0.4170 - val_loss: 1.8342 - val_accuracy: 0.3011\n","Epoch 377/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5055 - accuracy: 0.4159 - val_loss: 1.8344 - val_accuracy: 0.2977\n","Epoch 378/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5048 - accuracy: 0.4157 - val_loss: 1.8343 - val_accuracy: 0.2986\n","Epoch 379/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5048 - accuracy: 0.4157 - val_loss: 1.8327 - val_accuracy: 0.2970\n","Epoch 380/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5013 - accuracy: 0.4189 - val_loss: 1.8343 - val_accuracy: 0.2984\n","Epoch 381/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5040 - accuracy: 0.4183 - val_loss: 1.8349 - val_accuracy: 0.2988\n","Epoch 382/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5031 - accuracy: 0.4175 - val_loss: 1.8355 - val_accuracy: 0.2980\n","Epoch 383/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5047 - accuracy: 0.4155 - val_loss: 1.8341 - val_accuracy: 0.2993\n","Epoch 384/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5054 - accuracy: 0.4171 - val_loss: 1.8333 - val_accuracy: 0.3004\n","Epoch 385/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5034 - accuracy: 0.4192 - val_loss: 1.8321 - val_accuracy: 0.2992\n","Epoch 386/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5007 - accuracy: 0.4191 - val_loss: 1.8346 - val_accuracy: 0.3014\n","Epoch 387/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5027 - accuracy: 0.4169 - val_loss: 1.8337 - val_accuracy: 0.2988\n","Epoch 388/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5043 - accuracy: 0.4184 - val_loss: 1.8318 - val_accuracy: 0.2995\n","Epoch 389/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5032 - accuracy: 0.4181 - val_loss: 1.8336 - val_accuracy: 0.2975\n","Epoch 390/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5018 - accuracy: 0.4175 - val_loss: 1.8340 - val_accuracy: 0.2990\n","Epoch 391/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5048 - accuracy: 0.4176 - val_loss: 1.8334 - val_accuracy: 0.2996\n","Epoch 392/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5023 - accuracy: 0.4168 - val_loss: 1.8346 - val_accuracy: 0.3006\n","Epoch 393/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.5010 - accuracy: 0.4181 - val_loss: 1.8335 - val_accuracy: 0.2986\n","Epoch 394/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5045 - accuracy: 0.4166 - val_loss: 1.8319 - val_accuracy: 0.2989\n","Epoch 395/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5027 - accuracy: 0.4175 - val_loss: 1.8336 - val_accuracy: 0.2997\n","Epoch 396/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5026 - accuracy: 0.4171 - val_loss: 1.8343 - val_accuracy: 0.2977\n","Epoch 397/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5016 - accuracy: 0.4200 - val_loss: 1.8330 - val_accuracy: 0.2986\n","Epoch 398/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5033 - accuracy: 0.4175 - val_loss: 1.8341 - val_accuracy: 0.2977\n","Epoch 399/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5026 - accuracy: 0.4162 - val_loss: 1.8340 - val_accuracy: 0.2997\n","Epoch 400/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5020 - accuracy: 0.4164 - val_loss: 1.8339 - val_accuracy: 0.2998\n","Epoch 401/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5036 - accuracy: 0.4163 - val_loss: 1.8326 - val_accuracy: 0.2992\n","Epoch 402/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5046 - accuracy: 0.4155 - val_loss: 1.8324 - val_accuracy: 0.2991\n","Epoch 403/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5017 - accuracy: 0.4167 - val_loss: 1.8349 - val_accuracy: 0.2983\n","Epoch 404/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5000 - accuracy: 0.4171 - val_loss: 1.8340 - val_accuracy: 0.2994\n","Epoch 405/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5010 - accuracy: 0.4191 - val_loss: 1.8337 - val_accuracy: 0.2995\n","Epoch 406/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.4994 - accuracy: 0.4186 - val_loss: 1.8345 - val_accuracy: 0.3002\n","Epoch 407/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5025 - accuracy: 0.4180 - val_loss: 1.8342 - val_accuracy: 0.2976\n","Epoch 408/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5030 - accuracy: 0.4155 - val_loss: 1.8347 - val_accuracy: 0.2997\n","Epoch 409/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5004 - accuracy: 0.4194 - val_loss: 1.8362 - val_accuracy: 0.2987\n","Epoch 410/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4991 - accuracy: 0.4198 - val_loss: 1.8355 - val_accuracy: 0.2979\n","Epoch 411/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.4994 - accuracy: 0.4192 - val_loss: 1.8360 - val_accuracy: 0.3011\n","Epoch 412/500\n","73923/73923 [==============================] - 5s 66us/step - loss: 1.4999 - accuracy: 0.4177 - val_loss: 1.8347 - val_accuracy: 0.2990\n","Epoch 413/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.4992 - accuracy: 0.4199 - val_loss: 1.8349 - val_accuracy: 0.2970\n","Epoch 414/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5032 - accuracy: 0.4179 - val_loss: 1.8344 - val_accuracy: 0.2989\n","Epoch 415/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4986 - accuracy: 0.4210 - val_loss: 1.8338 - val_accuracy: 0.2984\n","Epoch 416/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5025 - accuracy: 0.4166 - val_loss: 1.8346 - val_accuracy: 0.2987\n","Epoch 417/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5005 - accuracy: 0.4193 - val_loss: 1.8349 - val_accuracy: 0.2978\n","Epoch 418/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5014 - accuracy: 0.4194 - val_loss: 1.8339 - val_accuracy: 0.2979\n","Epoch 419/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5023 - accuracy: 0.4174 - val_loss: 1.8334 - val_accuracy: 0.2975\n","Epoch 420/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4985 - accuracy: 0.4198 - val_loss: 1.8351 - val_accuracy: 0.2985\n","Epoch 421/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.4992 - accuracy: 0.4202 - val_loss: 1.8336 - val_accuracy: 0.2984\n","Epoch 422/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5011 - accuracy: 0.4181 - val_loss: 1.8345 - val_accuracy: 0.2988\n","Epoch 423/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4987 - accuracy: 0.4199 - val_loss: 1.8361 - val_accuracy: 0.2980\n","Epoch 424/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4996 - accuracy: 0.4192 - val_loss: 1.8335 - val_accuracy: 0.2991\n","Epoch 425/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.5004 - accuracy: 0.4196 - val_loss: 1.8351 - val_accuracy: 0.2981\n","Epoch 426/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.5009 - accuracy: 0.4193 - val_loss: 1.8331 - val_accuracy: 0.2975\n","Epoch 427/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4994 - accuracy: 0.4180 - val_loss: 1.8319 - val_accuracy: 0.3005\n","Epoch 428/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4974 - accuracy: 0.4204 - val_loss: 1.8346 - val_accuracy: 0.2977\n","Epoch 429/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4961 - accuracy: 0.4202 - val_loss: 1.8365 - val_accuracy: 0.2993\n","Epoch 430/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4988 - accuracy: 0.4195 - val_loss: 1.8354 - val_accuracy: 0.2971\n","Epoch 431/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.5014 - accuracy: 0.4174 - val_loss: 1.8347 - val_accuracy: 0.2987\n","Epoch 432/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.4974 - accuracy: 0.4195 - val_loss: 1.8353 - val_accuracy: 0.2985\n","Epoch 433/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4981 - accuracy: 0.4206 - val_loss: 1.8336 - val_accuracy: 0.2971\n","Epoch 434/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.4975 - accuracy: 0.4192 - val_loss: 1.8341 - val_accuracy: 0.2991\n","Epoch 435/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.5015 - accuracy: 0.4173 - val_loss: 1.8330 - val_accuracy: 0.2966\n","Epoch 436/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4986 - accuracy: 0.4179 - val_loss: 1.8331 - val_accuracy: 0.2974\n","Epoch 437/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.5000 - accuracy: 0.4191 - val_loss: 1.8324 - val_accuracy: 0.2977\n","Epoch 438/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4975 - accuracy: 0.4184 - val_loss: 1.8338 - val_accuracy: 0.2987\n","Epoch 439/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4983 - accuracy: 0.4190 - val_loss: 1.8331 - val_accuracy: 0.2987\n","Epoch 440/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4989 - accuracy: 0.4190 - val_loss: 1.8342 - val_accuracy: 0.2984\n","Epoch 441/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4976 - accuracy: 0.4172 - val_loss: 1.8334 - val_accuracy: 0.2997\n","Epoch 442/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4974 - accuracy: 0.4162 - val_loss: 1.8351 - val_accuracy: 0.2995\n","Epoch 443/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4970 - accuracy: 0.4178 - val_loss: 1.8337 - val_accuracy: 0.2981\n","Epoch 444/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4969 - accuracy: 0.4200 - val_loss: 1.8352 - val_accuracy: 0.2978\n","Epoch 445/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4973 - accuracy: 0.4194 - val_loss: 1.8353 - val_accuracy: 0.2974\n","Epoch 446/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4969 - accuracy: 0.4209 - val_loss: 1.8345 - val_accuracy: 0.2986\n","Epoch 447/500\n","73923/73923 [==============================] - 5s 74us/step - loss: 1.4979 - accuracy: 0.4176 - val_loss: 1.8338 - val_accuracy: 0.3010\n","Epoch 448/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4971 - accuracy: 0.4195 - val_loss: 1.8370 - val_accuracy: 0.2962\n","Epoch 449/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4985 - accuracy: 0.4189 - val_loss: 1.8353 - val_accuracy: 0.2948\n","Epoch 450/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4990 - accuracy: 0.4183 - val_loss: 1.8335 - val_accuracy: 0.2969\n","Epoch 451/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.4957 - accuracy: 0.4199 - val_loss: 1.8345 - val_accuracy: 0.2961\n","Epoch 452/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4973 - accuracy: 0.4175 - val_loss: 1.8347 - val_accuracy: 0.2983\n","Epoch 453/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4953 - accuracy: 0.4214 - val_loss: 1.8336 - val_accuracy: 0.2980\n","Epoch 454/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4953 - accuracy: 0.4211 - val_loss: 1.8333 - val_accuracy: 0.2963\n","Epoch 455/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4956 - accuracy: 0.4186 - val_loss: 1.8340 - val_accuracy: 0.2988\n","Epoch 456/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4947 - accuracy: 0.4197 - val_loss: 1.8350 - val_accuracy: 0.2975\n","Epoch 457/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4942 - accuracy: 0.4201 - val_loss: 1.8369 - val_accuracy: 0.2980\n","Epoch 458/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4968 - accuracy: 0.4189 - val_loss: 1.8349 - val_accuracy: 0.2970\n","Epoch 459/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.4962 - accuracy: 0.4201 - val_loss: 1.8330 - val_accuracy: 0.2953\n","Epoch 460/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4965 - accuracy: 0.4184 - val_loss: 1.8348 - val_accuracy: 0.2982\n","Epoch 461/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4929 - accuracy: 0.4225 - val_loss: 1.8347 - val_accuracy: 0.2967\n","Epoch 462/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4960 - accuracy: 0.4206 - val_loss: 1.8348 - val_accuracy: 0.2986\n","Epoch 463/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4939 - accuracy: 0.4207 - val_loss: 1.8345 - val_accuracy: 0.2979\n","Epoch 464/500\n","73923/73923 [==============================] - 6s 81us/step - loss: 1.4976 - accuracy: 0.4187 - val_loss: 1.8340 - val_accuracy: 0.2987\n","Epoch 465/500\n","73923/73923 [==============================] - 6s 76us/step - loss: 1.4948 - accuracy: 0.4196 - val_loss: 1.8316 - val_accuracy: 0.2972\n","Epoch 466/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4947 - accuracy: 0.4210 - val_loss: 1.8336 - val_accuracy: 0.2972\n","Epoch 467/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4979 - accuracy: 0.4183 - val_loss: 1.8330 - val_accuracy: 0.2978\n","Epoch 468/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4968 - accuracy: 0.4201 - val_loss: 1.8328 - val_accuracy: 0.2988\n","Epoch 469/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4933 - accuracy: 0.4205 - val_loss: 1.8341 - val_accuracy: 0.2983\n","Epoch 470/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.4936 - accuracy: 0.4208 - val_loss: 1.8329 - val_accuracy: 0.2992\n","Epoch 471/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4958 - accuracy: 0.4200 - val_loss: 1.8339 - val_accuracy: 0.2979\n","Epoch 472/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4950 - accuracy: 0.4205 - val_loss: 1.8347 - val_accuracy: 0.2968\n","Epoch 473/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4938 - accuracy: 0.4223 - val_loss: 1.8346 - val_accuracy: 0.2979\n","Epoch 474/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4953 - accuracy: 0.4177 - val_loss: 1.8340 - val_accuracy: 0.2975\n","Epoch 475/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4964 - accuracy: 0.4203 - val_loss: 1.8345 - val_accuracy: 0.2994\n","Epoch 476/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4934 - accuracy: 0.4192 - val_loss: 1.8343 - val_accuracy: 0.2996\n","Epoch 477/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4930 - accuracy: 0.4226 - val_loss: 1.8354 - val_accuracy: 0.2994\n","Epoch 478/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.4949 - accuracy: 0.4216 - val_loss: 1.8337 - val_accuracy: 0.2985\n","Epoch 479/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4963 - accuracy: 0.4209 - val_loss: 1.8332 - val_accuracy: 0.2961\n","Epoch 480/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4950 - accuracy: 0.4199 - val_loss: 1.8320 - val_accuracy: 0.3023\n","Epoch 481/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4961 - accuracy: 0.4168 - val_loss: 1.8335 - val_accuracy: 0.2977\n","Epoch 482/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4932 - accuracy: 0.4207 - val_loss: 1.8365 - val_accuracy: 0.2979\n","Epoch 483/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4936 - accuracy: 0.4233 - val_loss: 1.8344 - val_accuracy: 0.2996\n","Epoch 484/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4945 - accuracy: 0.4202 - val_loss: 1.8359 - val_accuracy: 0.2993\n","Epoch 485/500\n","73923/73923 [==============================] - 5s 67us/step - loss: 1.4942 - accuracy: 0.4212 - val_loss: 1.8332 - val_accuracy: 0.2998\n","Epoch 486/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4931 - accuracy: 0.4200 - val_loss: 1.8342 - val_accuracy: 0.2972\n","Epoch 487/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4962 - accuracy: 0.4206 - val_loss: 1.8340 - val_accuracy: 0.2993\n","Epoch 488/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4936 - accuracy: 0.4221 - val_loss: 1.8329 - val_accuracy: 0.2983\n","Epoch 489/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4936 - accuracy: 0.4221 - val_loss: 1.8346 - val_accuracy: 0.2999\n","Epoch 490/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4925 - accuracy: 0.4198 - val_loss: 1.8351 - val_accuracy: 0.2990\n","Epoch 491/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4926 - accuracy: 0.4195 - val_loss: 1.8350 - val_accuracy: 0.2988\n","Epoch 492/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.4938 - accuracy: 0.4202 - val_loss: 1.8345 - val_accuracy: 0.2992\n","Epoch 493/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4930 - accuracy: 0.4205 - val_loss: 1.8334 - val_accuracy: 0.2975\n","Epoch 494/500\n","73923/73923 [==============================] - 5s 72us/step - loss: 1.4918 - accuracy: 0.4230 - val_loss: 1.8357 - val_accuracy: 0.2985\n","Epoch 495/500\n","73923/73923 [==============================] - 5s 69us/step - loss: 1.4951 - accuracy: 0.4212 - val_loss: 1.8349 - val_accuracy: 0.2983\n","Epoch 496/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4929 - accuracy: 0.4219 - val_loss: 1.8341 - val_accuracy: 0.2965\n","Epoch 497/500\n","73923/73923 [==============================] - 5s 70us/step - loss: 1.4922 - accuracy: 0.4220 - val_loss: 1.8367 - val_accuracy: 0.2978\n","Epoch 498/500\n","73923/73923 [==============================] - 5s 71us/step - loss: 1.4921 - accuracy: 0.4200 - val_loss: 1.8357 - val_accuracy: 0.2978\n","Epoch 499/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4943 - accuracy: 0.4188 - val_loss: 1.8333 - val_accuracy: 0.2988\n","Epoch 500/500\n","73923/73923 [==============================] - 5s 68us/step - loss: 1.4940 - accuracy: 0.4203 - val_loss: 1.8338 - val_accuracy: 0.2996\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f37fb8de208>"]},"metadata":{"tags":[]},"execution_count":193}]},{"cell_type":"code","metadata":{"id":"wt9mm9L1tfKg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593470931033,"user_tz":180,"elapsed":2575424,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"7849ff93-4d8f-4114-ce50-d86d932daa8d"},"source":["acur_test = regressor.evaluate(X_test, y_test, verbose=0)\n","accuracy_modelo4 = acur_test[1]\n","print(accuracy_modelo4)"],"execution_count":194,"outputs":[{"output_type":"stream","text":["0.29960501194000244\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"geuzRrMmuA1r","colab_type":"text"},"source":["MATRIZ DE CONFUSÃO"]},{"cell_type":"code","metadata":{"id":"fIo4zHqYt_nI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593470931512,"user_tz":180,"elapsed":2575898,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["y_predicted_lstm = regressor.predict_classes(X_test)\n","lstm_results = pd.DataFrame(list(zip(y_predicted_lstm, y_test)), columns =['predito', 'real'])\n","df_confusion = pd.crosstab(lstm_results.real, lstm_results.predito)\n","\n","export_path = workdir_path + '/matrizConfusaoLSTM1.csv'\n","df_confusion.to_csv (export_path, index = True, header=True)"],"execution_count":195,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nDRLNkbaqCrr","colab_type":"text"},"source":["MODELO DE REDES NEURAL LSTM - 2 CAMADAS ESCONDIDAS"]},{"cell_type":"code","metadata":{"id":"dbCZ0f81oPmm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1593470931990,"user_tz":180,"elapsed":2576352,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"0e4e547c-b198-4641-dd24-a6b3018ad591"},"source":["# Initicializar a RNN\n","regressor = Sequential()\n"," \n","# Adicionar a primeira camada LSTM e Dropout \n","regressor.add(LSTM(units = primeiro_neuronio_lstm, return_sequences = True, input_shape=(1, x_train_prepared.shape[1])))\n","regressor.add(Dropout(0.2))\n"," \n","# Adicionar a terceira camada LSTM e Dropout\n","regressor.add(LSTM(units = segundo_neuronio_lstm))\n","regressor.add(Dropout(0.2))\n"," \n","# camada de saída\n","regressor.add(Dense(units = camadas_saida, activation='softmax')) #para classificação dar como entrada as classes com função de ativação softmax\n","\n","# Compilar a rede\n","regressor.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Visualizar a rede\n","regressor.summary()"],"execution_count":196,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_10 (LSTM)               (None, 1, 64)             38144     \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 1, 64)             0         \n","_________________________________________________________________\n","lstm_11 (LSTM)               (None, 32)                12416     \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 7)                 231       \n","=================================================================\n","Total params: 50,791\n","Trainable params: 50,791\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HI-L6suIoqJx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593474495494,"user_tz":180,"elapsed":6139829,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"41c99192-e118-4b11-d953-5e5e3f360e54"},"source":["#fitting\n","regressor.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = epocas, batch_size = 32 )"],"execution_count":197,"outputs":[{"output_type":"stream","text":["Train on 73923 samples, validate on 18481 samples\n","Epoch 1/500\n","73923/73923 [==============================] - 8s 105us/step - loss: 1.8965 - accuracy: 0.2101 - val_loss: 1.8884 - val_accuracy: 0.2224\n","Epoch 2/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.8714 - accuracy: 0.2330 - val_loss: 1.8744 - val_accuracy: 0.2299\n","Epoch 3/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.8466 - accuracy: 0.2519 - val_loss: 1.8620 - val_accuracy: 0.2415\n","Epoch 4/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.8245 - accuracy: 0.2655 - val_loss: 1.8552 - val_accuracy: 0.2464\n","Epoch 5/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.8062 - accuracy: 0.2793 - val_loss: 1.8485 - val_accuracy: 0.2517\n","Epoch 6/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.7921 - accuracy: 0.2851 - val_loss: 1.8440 - val_accuracy: 0.2562\n","Epoch 7/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.7803 - accuracy: 0.2918 - val_loss: 1.8423 - val_accuracy: 0.2606\n","Epoch 8/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.7687 - accuracy: 0.3009 - val_loss: 1.8408 - val_accuracy: 0.2635\n","Epoch 9/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.7595 - accuracy: 0.3069 - val_loss: 1.8360 - val_accuracy: 0.2650\n","Epoch 10/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.7510 - accuracy: 0.3093 - val_loss: 1.8335 - val_accuracy: 0.2680\n","Epoch 11/500\n","73923/73923 [==============================] - 8s 108us/step - loss: 1.7415 - accuracy: 0.3146 - val_loss: 1.8309 - val_accuracy: 0.2685\n","Epoch 12/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.7368 - accuracy: 0.3175 - val_loss: 1.8321 - val_accuracy: 0.2685\n","Epoch 13/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.7277 - accuracy: 0.3224 - val_loss: 1.8302 - val_accuracy: 0.2750\n","Epoch 14/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.7206 - accuracy: 0.3249 - val_loss: 1.8273 - val_accuracy: 0.2715\n","Epoch 15/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.7169 - accuracy: 0.3266 - val_loss: 1.8242 - val_accuracy: 0.2753\n","Epoch 16/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.7102 - accuracy: 0.3304 - val_loss: 1.8257 - val_accuracy: 0.2761\n","Epoch 17/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.7060 - accuracy: 0.3353 - val_loss: 1.8229 - val_accuracy: 0.2770\n","Epoch 18/500\n","73923/73923 [==============================] - 8s 102us/step - loss: 1.7014 - accuracy: 0.3326 - val_loss: 1.8249 - val_accuracy: 0.2784\n","Epoch 19/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.6965 - accuracy: 0.3378 - val_loss: 1.8237 - val_accuracy: 0.2767\n","Epoch 20/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.6912 - accuracy: 0.3413 - val_loss: 1.8240 - val_accuracy: 0.2770\n","Epoch 21/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6908 - accuracy: 0.3386 - val_loss: 1.8209 - val_accuracy: 0.2794\n","Epoch 22/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6863 - accuracy: 0.3427 - val_loss: 1.8225 - val_accuracy: 0.2814\n","Epoch 23/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6839 - accuracy: 0.3438 - val_loss: 1.8185 - val_accuracy: 0.2794\n","Epoch 24/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6799 - accuracy: 0.3458 - val_loss: 1.8200 - val_accuracy: 0.2826\n","Epoch 25/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6770 - accuracy: 0.3487 - val_loss: 1.8220 - val_accuracy: 0.2775\n","Epoch 26/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6738 - accuracy: 0.3484 - val_loss: 1.8186 - val_accuracy: 0.2777\n","Epoch 27/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.6697 - accuracy: 0.3495 - val_loss: 1.8193 - val_accuracy: 0.2802\n","Epoch 28/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6638 - accuracy: 0.3534 - val_loss: 1.8216 - val_accuracy: 0.2777\n","Epoch 29/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6662 - accuracy: 0.3520 - val_loss: 1.8182 - val_accuracy: 0.2763\n","Epoch 30/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6635 - accuracy: 0.3552 - val_loss: 1.8172 - val_accuracy: 0.2792\n","Epoch 31/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.6594 - accuracy: 0.3534 - val_loss: 1.8221 - val_accuracy: 0.2797\n","Epoch 32/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.6598 - accuracy: 0.3525 - val_loss: 1.8153 - val_accuracy: 0.2816\n","Epoch 33/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.6560 - accuracy: 0.3562 - val_loss: 1.8171 - val_accuracy: 0.2827\n","Epoch 34/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6508 - accuracy: 0.3582 - val_loss: 1.8205 - val_accuracy: 0.2809\n","Epoch 35/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.6513 - accuracy: 0.3570 - val_loss: 1.8161 - val_accuracy: 0.2855\n","Epoch 36/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6470 - accuracy: 0.3604 - val_loss: 1.8185 - val_accuracy: 0.2854\n","Epoch 37/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.6443 - accuracy: 0.3620 - val_loss: 1.8174 - val_accuracy: 0.2823\n","Epoch 38/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6459 - accuracy: 0.3616 - val_loss: 1.8167 - val_accuracy: 0.2836\n","Epoch 39/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.6438 - accuracy: 0.3623 - val_loss: 1.8164 - val_accuracy: 0.2873\n","Epoch 40/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6386 - accuracy: 0.3637 - val_loss: 1.8163 - val_accuracy: 0.2854\n","Epoch 41/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6388 - accuracy: 0.3629 - val_loss: 1.8169 - val_accuracy: 0.2868\n","Epoch 42/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.6374 - accuracy: 0.3641 - val_loss: 1.8153 - val_accuracy: 0.2849\n","Epoch 43/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6337 - accuracy: 0.3658 - val_loss: 1.8166 - val_accuracy: 0.2852\n","Epoch 44/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6323 - accuracy: 0.3647 - val_loss: 1.8156 - val_accuracy: 0.2865\n","Epoch 45/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6324 - accuracy: 0.3687 - val_loss: 1.8168 - val_accuracy: 0.2865\n","Epoch 46/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6315 - accuracy: 0.3678 - val_loss: 1.8154 - val_accuracy: 0.2869\n","Epoch 47/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6307 - accuracy: 0.3669 - val_loss: 1.8147 - val_accuracy: 0.2881\n","Epoch 48/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.6270 - accuracy: 0.3662 - val_loss: 1.8138 - val_accuracy: 0.2896\n","Epoch 49/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6238 - accuracy: 0.3701 - val_loss: 1.8148 - val_accuracy: 0.2868\n","Epoch 50/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6231 - accuracy: 0.3693 - val_loss: 1.8135 - val_accuracy: 0.2893\n","Epoch 51/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6234 - accuracy: 0.3705 - val_loss: 1.8142 - val_accuracy: 0.2871\n","Epoch 52/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6206 - accuracy: 0.3698 - val_loss: 1.8123 - val_accuracy: 0.2902\n","Epoch 53/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6207 - accuracy: 0.3699 - val_loss: 1.8158 - val_accuracy: 0.2893\n","Epoch 54/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6190 - accuracy: 0.3709 - val_loss: 1.8134 - val_accuracy: 0.2898\n","Epoch 55/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.6155 - accuracy: 0.3737 - val_loss: 1.8153 - val_accuracy: 0.2874\n","Epoch 56/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6136 - accuracy: 0.3754 - val_loss: 1.8169 - val_accuracy: 0.2907\n","Epoch 57/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.6146 - accuracy: 0.3733 - val_loss: 1.8114 - val_accuracy: 0.2908\n","Epoch 58/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.6123 - accuracy: 0.3748 - val_loss: 1.8124 - val_accuracy: 0.2902\n","Epoch 59/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.6121 - accuracy: 0.3748 - val_loss: 1.8142 - val_accuracy: 0.2911\n","Epoch 60/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6114 - accuracy: 0.3757 - val_loss: 1.8123 - val_accuracy: 0.2909\n","Epoch 61/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.6130 - accuracy: 0.3737 - val_loss: 1.8117 - val_accuracy: 0.2871\n","Epoch 62/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6092 - accuracy: 0.3776 - val_loss: 1.8119 - val_accuracy: 0.2931\n","Epoch 63/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.6085 - accuracy: 0.3763 - val_loss: 1.8118 - val_accuracy: 0.2898\n","Epoch 64/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6091 - accuracy: 0.3762 - val_loss: 1.8121 - val_accuracy: 0.2889\n","Epoch 65/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.6055 - accuracy: 0.3792 - val_loss: 1.8131 - val_accuracy: 0.2913\n","Epoch 66/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6048 - accuracy: 0.3799 - val_loss: 1.8129 - val_accuracy: 0.2933\n","Epoch 67/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.6066 - accuracy: 0.3793 - val_loss: 1.8099 - val_accuracy: 0.2897\n","Epoch 68/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.6021 - accuracy: 0.3795 - val_loss: 1.8104 - val_accuracy: 0.2891\n","Epoch 69/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.6041 - accuracy: 0.3797 - val_loss: 1.8103 - val_accuracy: 0.2918\n","Epoch 70/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.6014 - accuracy: 0.3805 - val_loss: 1.8130 - val_accuracy: 0.2916\n","Epoch 71/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.6026 - accuracy: 0.3816 - val_loss: 1.8086 - val_accuracy: 0.2932\n","Epoch 72/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5984 - accuracy: 0.3802 - val_loss: 1.8075 - val_accuracy: 0.2927\n","Epoch 73/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5982 - accuracy: 0.3794 - val_loss: 1.8114 - val_accuracy: 0.2933\n","Epoch 74/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5954 - accuracy: 0.3799 - val_loss: 1.8112 - val_accuracy: 0.2921\n","Epoch 75/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5956 - accuracy: 0.3809 - val_loss: 1.8114 - val_accuracy: 0.2919\n","Epoch 76/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5971 - accuracy: 0.3811 - val_loss: 1.8124 - val_accuracy: 0.2905\n","Epoch 77/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5955 - accuracy: 0.3799 - val_loss: 1.8090 - val_accuracy: 0.2906\n","Epoch 78/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5922 - accuracy: 0.3833 - val_loss: 1.8136 - val_accuracy: 0.2900\n","Epoch 79/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5936 - accuracy: 0.3835 - val_loss: 1.8118 - val_accuracy: 0.2886\n","Epoch 80/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5946 - accuracy: 0.3850 - val_loss: 1.8097 - val_accuracy: 0.2923\n","Epoch 81/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5942 - accuracy: 0.3822 - val_loss: 1.8098 - val_accuracy: 0.2942\n","Epoch 82/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5926 - accuracy: 0.3827 - val_loss: 1.8091 - val_accuracy: 0.2931\n","Epoch 83/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5918 - accuracy: 0.3839 - val_loss: 1.8108 - val_accuracy: 0.2925\n","Epoch 84/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5892 - accuracy: 0.3843 - val_loss: 1.8104 - val_accuracy: 0.2973\n","Epoch 85/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5898 - accuracy: 0.3836 - val_loss: 1.8123 - val_accuracy: 0.2952\n","Epoch 86/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5906 - accuracy: 0.3842 - val_loss: 1.8104 - val_accuracy: 0.2945\n","Epoch 87/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5864 - accuracy: 0.3848 - val_loss: 1.8143 - val_accuracy: 0.2915\n","Epoch 88/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5880 - accuracy: 0.3845 - val_loss: 1.8098 - val_accuracy: 0.2939\n","Epoch 89/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5867 - accuracy: 0.3858 - val_loss: 1.8098 - val_accuracy: 0.2937\n","Epoch 90/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5860 - accuracy: 0.3877 - val_loss: 1.8137 - val_accuracy: 0.2933\n","Epoch 91/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5834 - accuracy: 0.3873 - val_loss: 1.8126 - val_accuracy: 0.2924\n","Epoch 92/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5826 - accuracy: 0.3877 - val_loss: 1.8118 - val_accuracy: 0.2949\n","Epoch 93/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5831 - accuracy: 0.3853 - val_loss: 1.8135 - val_accuracy: 0.2931\n","Epoch 94/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5869 - accuracy: 0.3859 - val_loss: 1.8138 - val_accuracy: 0.2921\n","Epoch 95/500\n","73923/73923 [==============================] - 8s 104us/step - loss: 1.5825 - accuracy: 0.3858 - val_loss: 1.8125 - val_accuracy: 0.2931\n","Epoch 96/500\n","73923/73923 [==============================] - 8s 106us/step - loss: 1.5821 - accuracy: 0.3864 - val_loss: 1.8127 - val_accuracy: 0.2922\n","Epoch 97/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5810 - accuracy: 0.3883 - val_loss: 1.8129 - val_accuracy: 0.2963\n","Epoch 98/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5789 - accuracy: 0.3879 - val_loss: 1.8131 - val_accuracy: 0.2968\n","Epoch 99/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5786 - accuracy: 0.3882 - val_loss: 1.8135 - val_accuracy: 0.2941\n","Epoch 100/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5806 - accuracy: 0.3902 - val_loss: 1.8104 - val_accuracy: 0.2959\n","Epoch 101/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5825 - accuracy: 0.3864 - val_loss: 1.8092 - val_accuracy: 0.2946\n","Epoch 102/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5791 - accuracy: 0.3890 - val_loss: 1.8120 - val_accuracy: 0.2958\n","Epoch 103/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5798 - accuracy: 0.3877 - val_loss: 1.8102 - val_accuracy: 0.2966\n","Epoch 104/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5791 - accuracy: 0.3881 - val_loss: 1.8099 - val_accuracy: 0.2970\n","Epoch 105/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5794 - accuracy: 0.3885 - val_loss: 1.8098 - val_accuracy: 0.2956\n","Epoch 106/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5768 - accuracy: 0.3902 - val_loss: 1.8119 - val_accuracy: 0.2957\n","Epoch 107/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5791 - accuracy: 0.3861 - val_loss: 1.8116 - val_accuracy: 0.2978\n","Epoch 108/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5760 - accuracy: 0.3895 - val_loss: 1.8120 - val_accuracy: 0.2951\n","Epoch 109/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5760 - accuracy: 0.3879 - val_loss: 1.8101 - val_accuracy: 0.2967\n","Epoch 110/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5771 - accuracy: 0.3896 - val_loss: 1.8118 - val_accuracy: 0.2946\n","Epoch 111/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5734 - accuracy: 0.3899 - val_loss: 1.8148 - val_accuracy: 0.2943\n","Epoch 112/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5752 - accuracy: 0.3891 - val_loss: 1.8158 - val_accuracy: 0.2953\n","Epoch 113/500\n","73923/73923 [==============================] - 8s 102us/step - loss: 1.5750 - accuracy: 0.3898 - val_loss: 1.8110 - val_accuracy: 0.2953\n","Epoch 114/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5708 - accuracy: 0.3918 - val_loss: 1.8147 - val_accuracy: 0.2963\n","Epoch 115/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5697 - accuracy: 0.3941 - val_loss: 1.8124 - val_accuracy: 0.2951\n","Epoch 116/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5711 - accuracy: 0.3897 - val_loss: 1.8113 - val_accuracy: 0.2958\n","Epoch 117/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5679 - accuracy: 0.3915 - val_loss: 1.8134 - val_accuracy: 0.2987\n","Epoch 118/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5733 - accuracy: 0.3898 - val_loss: 1.8104 - val_accuracy: 0.2949\n","Epoch 119/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5676 - accuracy: 0.3928 - val_loss: 1.8121 - val_accuracy: 0.2945\n","Epoch 120/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5749 - accuracy: 0.3895 - val_loss: 1.8094 - val_accuracy: 0.2946\n","Epoch 121/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5716 - accuracy: 0.3903 - val_loss: 1.8106 - val_accuracy: 0.2968\n","Epoch 122/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5688 - accuracy: 0.3929 - val_loss: 1.8117 - val_accuracy: 0.2971\n","Epoch 123/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5678 - accuracy: 0.3912 - val_loss: 1.8114 - val_accuracy: 0.2996\n","Epoch 124/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5702 - accuracy: 0.3942 - val_loss: 1.8117 - val_accuracy: 0.2974\n","Epoch 125/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5681 - accuracy: 0.3913 - val_loss: 1.8130 - val_accuracy: 0.2957\n","Epoch 126/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5670 - accuracy: 0.3940 - val_loss: 1.8102 - val_accuracy: 0.2968\n","Epoch 127/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5663 - accuracy: 0.3910 - val_loss: 1.8106 - val_accuracy: 0.2963\n","Epoch 128/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5659 - accuracy: 0.3940 - val_loss: 1.8134 - val_accuracy: 0.2974\n","Epoch 129/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5658 - accuracy: 0.3953 - val_loss: 1.8147 - val_accuracy: 0.2921\n","Epoch 130/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5679 - accuracy: 0.3923 - val_loss: 1.8093 - val_accuracy: 0.2977\n","Epoch 131/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5660 - accuracy: 0.3927 - val_loss: 1.8133 - val_accuracy: 0.2968\n","Epoch 132/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5663 - accuracy: 0.3922 - val_loss: 1.8119 - val_accuracy: 0.2989\n","Epoch 133/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5669 - accuracy: 0.3932 - val_loss: 1.8109 - val_accuracy: 0.3008\n","Epoch 134/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5624 - accuracy: 0.3947 - val_loss: 1.8126 - val_accuracy: 0.2975\n","Epoch 135/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5629 - accuracy: 0.3957 - val_loss: 1.8107 - val_accuracy: 0.2963\n","Epoch 136/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5643 - accuracy: 0.3946 - val_loss: 1.8127 - val_accuracy: 0.2949\n","Epoch 137/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5661 - accuracy: 0.3926 - val_loss: 1.8118 - val_accuracy: 0.2955\n","Epoch 138/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5639 - accuracy: 0.3949 - val_loss: 1.8117 - val_accuracy: 0.2973\n","Epoch 139/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5634 - accuracy: 0.3963 - val_loss: 1.8105 - val_accuracy: 0.2977\n","Epoch 140/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5623 - accuracy: 0.3949 - val_loss: 1.8127 - val_accuracy: 0.2953\n","Epoch 141/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5657 - accuracy: 0.3950 - val_loss: 1.8114 - val_accuracy: 0.2973\n","Epoch 142/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5624 - accuracy: 0.3943 - val_loss: 1.8103 - val_accuracy: 0.2983\n","Epoch 143/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5626 - accuracy: 0.3967 - val_loss: 1.8138 - val_accuracy: 0.2987\n","Epoch 144/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5634 - accuracy: 0.3934 - val_loss: 1.8117 - val_accuracy: 0.2954\n","Epoch 145/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5631 - accuracy: 0.3935 - val_loss: 1.8096 - val_accuracy: 0.2967\n","Epoch 146/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5604 - accuracy: 0.3955 - val_loss: 1.8110 - val_accuracy: 0.2980\n","Epoch 147/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5630 - accuracy: 0.3960 - val_loss: 1.8096 - val_accuracy: 0.2994\n","Epoch 148/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5574 - accuracy: 0.3980 - val_loss: 1.8123 - val_accuracy: 0.2939\n","Epoch 149/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5600 - accuracy: 0.3972 - val_loss: 1.8143 - val_accuracy: 0.2972\n","Epoch 150/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5588 - accuracy: 0.3967 - val_loss: 1.8102 - val_accuracy: 0.2972\n","Epoch 151/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5618 - accuracy: 0.3936 - val_loss: 1.8123 - val_accuracy: 0.2952\n","Epoch 152/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5612 - accuracy: 0.3940 - val_loss: 1.8103 - val_accuracy: 0.2960\n","Epoch 153/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5569 - accuracy: 0.3967 - val_loss: 1.8137 - val_accuracy: 0.2990\n","Epoch 154/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5593 - accuracy: 0.3965 - val_loss: 1.8111 - val_accuracy: 0.2945\n","Epoch 155/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5614 - accuracy: 0.3936 - val_loss: 1.8094 - val_accuracy: 0.2984\n","Epoch 156/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5563 - accuracy: 0.3968 - val_loss: 1.8122 - val_accuracy: 0.2997\n","Epoch 157/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5585 - accuracy: 0.3959 - val_loss: 1.8136 - val_accuracy: 0.2997\n","Epoch 158/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5564 - accuracy: 0.3948 - val_loss: 1.8116 - val_accuracy: 0.2982\n","Epoch 159/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5548 - accuracy: 0.3968 - val_loss: 1.8126 - val_accuracy: 0.3001\n","Epoch 160/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5567 - accuracy: 0.3980 - val_loss: 1.8109 - val_accuracy: 0.2968\n","Epoch 161/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5563 - accuracy: 0.3955 - val_loss: 1.8115 - val_accuracy: 0.2988\n","Epoch 162/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5560 - accuracy: 0.3974 - val_loss: 1.8132 - val_accuracy: 0.2972\n","Epoch 163/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5524 - accuracy: 0.3977 - val_loss: 1.8148 - val_accuracy: 0.2958\n","Epoch 164/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5559 - accuracy: 0.3990 - val_loss: 1.8100 - val_accuracy: 0.2990\n","Epoch 165/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5555 - accuracy: 0.3986 - val_loss: 1.8083 - val_accuracy: 0.2997\n","Epoch 166/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5531 - accuracy: 0.3995 - val_loss: 1.8136 - val_accuracy: 0.2999\n","Epoch 167/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5561 - accuracy: 0.3979 - val_loss: 1.8127 - val_accuracy: 0.2960\n","Epoch 168/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5558 - accuracy: 0.3986 - val_loss: 1.8121 - val_accuracy: 0.3019\n","Epoch 169/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5555 - accuracy: 0.3997 - val_loss: 1.8115 - val_accuracy: 0.2998\n","Epoch 170/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5533 - accuracy: 0.3962 - val_loss: 1.8105 - val_accuracy: 0.2981\n","Epoch 171/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5497 - accuracy: 0.3976 - val_loss: 1.8123 - val_accuracy: 0.3001\n","Epoch 172/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5530 - accuracy: 0.3982 - val_loss: 1.8095 - val_accuracy: 0.3000\n","Epoch 173/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5535 - accuracy: 0.4010 - val_loss: 1.8091 - val_accuracy: 0.2978\n","Epoch 174/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5531 - accuracy: 0.3976 - val_loss: 1.8128 - val_accuracy: 0.2985\n","Epoch 175/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5533 - accuracy: 0.3971 - val_loss: 1.8132 - val_accuracy: 0.2987\n","Epoch 176/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5497 - accuracy: 0.3991 - val_loss: 1.8146 - val_accuracy: 0.2981\n","Epoch 177/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5537 - accuracy: 0.3991 - val_loss: 1.8118 - val_accuracy: 0.2999\n","Epoch 178/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5518 - accuracy: 0.3993 - val_loss: 1.8116 - val_accuracy: 0.2995\n","Epoch 179/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5493 - accuracy: 0.4018 - val_loss: 1.8132 - val_accuracy: 0.2991\n","Epoch 180/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5508 - accuracy: 0.4011 - val_loss: 1.8135 - val_accuracy: 0.3011\n","Epoch 181/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5472 - accuracy: 0.4020 - val_loss: 1.8145 - val_accuracy: 0.2981\n","Epoch 182/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5513 - accuracy: 0.3988 - val_loss: 1.8155 - val_accuracy: 0.2988\n","Epoch 183/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5496 - accuracy: 0.4002 - val_loss: 1.8136 - val_accuracy: 0.3003\n","Epoch 184/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5513 - accuracy: 0.3992 - val_loss: 1.8127 - val_accuracy: 0.2996\n","Epoch 185/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5513 - accuracy: 0.4004 - val_loss: 1.8140 - val_accuracy: 0.2979\n","Epoch 186/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5509 - accuracy: 0.3990 - val_loss: 1.8104 - val_accuracy: 0.2989\n","Epoch 187/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5496 - accuracy: 0.3985 - val_loss: 1.8113 - val_accuracy: 0.2973\n","Epoch 188/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5481 - accuracy: 0.3980 - val_loss: 1.8141 - val_accuracy: 0.2969\n","Epoch 189/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5473 - accuracy: 0.3998 - val_loss: 1.8130 - val_accuracy: 0.2999\n","Epoch 190/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5487 - accuracy: 0.4007 - val_loss: 1.8133 - val_accuracy: 0.2986\n","Epoch 191/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5462 - accuracy: 0.4019 - val_loss: 1.8129 - val_accuracy: 0.2982\n","Epoch 192/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5491 - accuracy: 0.4002 - val_loss: 1.8125 - val_accuracy: 0.2996\n","Epoch 193/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5463 - accuracy: 0.4023 - val_loss: 1.8174 - val_accuracy: 0.2951\n","Epoch 194/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5470 - accuracy: 0.3990 - val_loss: 1.8134 - val_accuracy: 0.2975\n","Epoch 195/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5489 - accuracy: 0.4005 - val_loss: 1.8116 - val_accuracy: 0.2998\n","Epoch 196/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5481 - accuracy: 0.4007 - val_loss: 1.8137 - val_accuracy: 0.2980\n","Epoch 197/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5458 - accuracy: 0.4005 - val_loss: 1.8133 - val_accuracy: 0.3001\n","Epoch 198/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5468 - accuracy: 0.4007 - val_loss: 1.8132 - val_accuracy: 0.2990\n","Epoch 199/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5472 - accuracy: 0.4006 - val_loss: 1.8108 - val_accuracy: 0.2994\n","Epoch 200/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5444 - accuracy: 0.3986 - val_loss: 1.8128 - val_accuracy: 0.2977\n","Epoch 201/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5474 - accuracy: 0.3982 - val_loss: 1.8135 - val_accuracy: 0.2996\n","Epoch 202/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5467 - accuracy: 0.3995 - val_loss: 1.8137 - val_accuracy: 0.2998\n","Epoch 203/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5438 - accuracy: 0.3991 - val_loss: 1.8127 - val_accuracy: 0.2993\n","Epoch 204/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5475 - accuracy: 0.4009 - val_loss: 1.8100 - val_accuracy: 0.2995\n","Epoch 205/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5450 - accuracy: 0.4013 - val_loss: 1.8123 - val_accuracy: 0.2982\n","Epoch 206/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5462 - accuracy: 0.4016 - val_loss: 1.8127 - val_accuracy: 0.2966\n","Epoch 207/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5463 - accuracy: 0.4013 - val_loss: 1.8122 - val_accuracy: 0.2940\n","Epoch 208/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5397 - accuracy: 0.4040 - val_loss: 1.8137 - val_accuracy: 0.2968\n","Epoch 209/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5429 - accuracy: 0.4030 - val_loss: 1.8128 - val_accuracy: 0.2994\n","Epoch 210/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5445 - accuracy: 0.4010 - val_loss: 1.8131 - val_accuracy: 0.2994\n","Epoch 211/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5435 - accuracy: 0.4004 - val_loss: 1.8116 - val_accuracy: 0.3003\n","Epoch 212/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5441 - accuracy: 0.4009 - val_loss: 1.8128 - val_accuracy: 0.2968\n","Epoch 213/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5390 - accuracy: 0.4042 - val_loss: 1.8140 - val_accuracy: 0.2984\n","Epoch 214/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5412 - accuracy: 0.4036 - val_loss: 1.8105 - val_accuracy: 0.3003\n","Epoch 215/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5423 - accuracy: 0.4034 - val_loss: 1.8109 - val_accuracy: 0.3007\n","Epoch 216/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5428 - accuracy: 0.4028 - val_loss: 1.8113 - val_accuracy: 0.2987\n","Epoch 217/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5448 - accuracy: 0.4018 - val_loss: 1.8120 - val_accuracy: 0.2964\n","Epoch 218/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5411 - accuracy: 0.4006 - val_loss: 1.8133 - val_accuracy: 0.3006\n","Epoch 219/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5408 - accuracy: 0.4045 - val_loss: 1.8127 - val_accuracy: 0.2990\n","Epoch 220/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5410 - accuracy: 0.4025 - val_loss: 1.8127 - val_accuracy: 0.2978\n","Epoch 221/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5398 - accuracy: 0.4023 - val_loss: 1.8139 - val_accuracy: 0.2985\n","Epoch 222/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5409 - accuracy: 0.4059 - val_loss: 1.8111 - val_accuracy: 0.2946\n","Epoch 223/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5395 - accuracy: 0.4022 - val_loss: 1.8151 - val_accuracy: 0.2994\n","Epoch 224/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5424 - accuracy: 0.4013 - val_loss: 1.8137 - val_accuracy: 0.3004\n","Epoch 225/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5402 - accuracy: 0.4022 - val_loss: 1.8134 - val_accuracy: 0.2981\n","Epoch 226/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5396 - accuracy: 0.4047 - val_loss: 1.8115 - val_accuracy: 0.2994\n","Epoch 227/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5414 - accuracy: 0.4020 - val_loss: 1.8094 - val_accuracy: 0.3017\n","Epoch 228/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5397 - accuracy: 0.4066 - val_loss: 1.8131 - val_accuracy: 0.3004\n","Epoch 229/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5391 - accuracy: 0.4037 - val_loss: 1.8135 - val_accuracy: 0.2980\n","Epoch 230/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5397 - accuracy: 0.4031 - val_loss: 1.8142 - val_accuracy: 0.3000\n","Epoch 231/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5382 - accuracy: 0.4029 - val_loss: 1.8119 - val_accuracy: 0.2978\n","Epoch 232/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5409 - accuracy: 0.4026 - val_loss: 1.8132 - val_accuracy: 0.2982\n","Epoch 233/500\n","73923/73923 [==============================] - 7s 91us/step - loss: 1.5397 - accuracy: 0.4022 - val_loss: 1.8089 - val_accuracy: 0.3001\n","Epoch 234/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5382 - accuracy: 0.4019 - val_loss: 1.8105 - val_accuracy: 0.3006\n","Epoch 235/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5388 - accuracy: 0.4024 - val_loss: 1.8137 - val_accuracy: 0.2994\n","Epoch 236/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5390 - accuracy: 0.4025 - val_loss: 1.8122 - val_accuracy: 0.3006\n","Epoch 237/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5399 - accuracy: 0.4039 - val_loss: 1.8101 - val_accuracy: 0.2980\n","Epoch 238/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5352 - accuracy: 0.4050 - val_loss: 1.8121 - val_accuracy: 0.2998\n","Epoch 239/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5354 - accuracy: 0.4048 - val_loss: 1.8142 - val_accuracy: 0.3006\n","Epoch 240/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5384 - accuracy: 0.4035 - val_loss: 1.8133 - val_accuracy: 0.2994\n","Epoch 241/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5361 - accuracy: 0.4070 - val_loss: 1.8143 - val_accuracy: 0.2993\n","Epoch 242/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5350 - accuracy: 0.4058 - val_loss: 1.8145 - val_accuracy: 0.2997\n","Epoch 243/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5405 - accuracy: 0.4038 - val_loss: 1.8123 - val_accuracy: 0.2970\n","Epoch 244/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5386 - accuracy: 0.4013 - val_loss: 1.8161 - val_accuracy: 0.2959\n","Epoch 245/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5389 - accuracy: 0.4034 - val_loss: 1.8129 - val_accuracy: 0.2985\n","Epoch 246/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5386 - accuracy: 0.4043 - val_loss: 1.8147 - val_accuracy: 0.2957\n","Epoch 247/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5395 - accuracy: 0.4023 - val_loss: 1.8113 - val_accuracy: 0.3006\n","Epoch 248/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5378 - accuracy: 0.4042 - val_loss: 1.8146 - val_accuracy: 0.2984\n","Epoch 249/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5358 - accuracy: 0.4047 - val_loss: 1.8165 - val_accuracy: 0.2990\n","Epoch 250/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5377 - accuracy: 0.4053 - val_loss: 1.8104 - val_accuracy: 0.2972\n","Epoch 251/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5330 - accuracy: 0.4076 - val_loss: 1.8142 - val_accuracy: 0.2973\n","Epoch 252/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5355 - accuracy: 0.4041 - val_loss: 1.8142 - val_accuracy: 0.2989\n","Epoch 253/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5362 - accuracy: 0.4030 - val_loss: 1.8130 - val_accuracy: 0.2997\n","Epoch 254/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5316 - accuracy: 0.4047 - val_loss: 1.8144 - val_accuracy: 0.3002\n","Epoch 255/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5367 - accuracy: 0.4039 - val_loss: 1.8112 - val_accuracy: 0.2989\n","Epoch 256/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5336 - accuracy: 0.4042 - val_loss: 1.8147 - val_accuracy: 0.2998\n","Epoch 257/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5349 - accuracy: 0.4075 - val_loss: 1.8128 - val_accuracy: 0.2990\n","Epoch 258/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5351 - accuracy: 0.4054 - val_loss: 1.8113 - val_accuracy: 0.2984\n","Epoch 259/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5360 - accuracy: 0.4050 - val_loss: 1.8120 - val_accuracy: 0.3004\n","Epoch 260/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5321 - accuracy: 0.4069 - val_loss: 1.8142 - val_accuracy: 0.2994\n","Epoch 261/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5344 - accuracy: 0.4066 - val_loss: 1.8107 - val_accuracy: 0.3009\n","Epoch 262/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5304 - accuracy: 0.4069 - val_loss: 1.8148 - val_accuracy: 0.3020\n","Epoch 263/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5297 - accuracy: 0.4077 - val_loss: 1.8154 - val_accuracy: 0.3007\n","Epoch 264/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5329 - accuracy: 0.4041 - val_loss: 1.8151 - val_accuracy: 0.2988\n","Epoch 265/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5314 - accuracy: 0.4075 - val_loss: 1.8144 - val_accuracy: 0.2990\n","Epoch 266/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5349 - accuracy: 0.4068 - val_loss: 1.8142 - val_accuracy: 0.3007\n","Epoch 267/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5342 - accuracy: 0.4050 - val_loss: 1.8107 - val_accuracy: 0.2992\n","Epoch 268/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5312 - accuracy: 0.4070 - val_loss: 1.8094 - val_accuracy: 0.2994\n","Epoch 269/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5307 - accuracy: 0.4081 - val_loss: 1.8114 - val_accuracy: 0.2969\n","Epoch 270/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5344 - accuracy: 0.4074 - val_loss: 1.8122 - val_accuracy: 0.2969\n","Epoch 271/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5329 - accuracy: 0.4062 - val_loss: 1.8102 - val_accuracy: 0.2967\n","Epoch 272/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5323 - accuracy: 0.4043 - val_loss: 1.8112 - val_accuracy: 0.2976\n","Epoch 273/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5308 - accuracy: 0.4076 - val_loss: 1.8133 - val_accuracy: 0.2984\n","Epoch 274/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5317 - accuracy: 0.4082 - val_loss: 1.8141 - val_accuracy: 0.2983\n","Epoch 275/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5308 - accuracy: 0.4079 - val_loss: 1.8129 - val_accuracy: 0.2992\n","Epoch 276/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5315 - accuracy: 0.4070 - val_loss: 1.8132 - val_accuracy: 0.2986\n","Epoch 277/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5307 - accuracy: 0.4057 - val_loss: 1.8109 - val_accuracy: 0.3018\n","Epoch 278/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5322 - accuracy: 0.4036 - val_loss: 1.8133 - val_accuracy: 0.3000\n","Epoch 279/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5346 - accuracy: 0.4064 - val_loss: 1.8135 - val_accuracy: 0.3027\n","Epoch 280/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5310 - accuracy: 0.4070 - val_loss: 1.8107 - val_accuracy: 0.2996\n","Epoch 281/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5340 - accuracy: 0.4082 - val_loss: 1.8097 - val_accuracy: 0.3010\n","Epoch 282/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5322 - accuracy: 0.4041 - val_loss: 1.8103 - val_accuracy: 0.3007\n","Epoch 283/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5307 - accuracy: 0.4068 - val_loss: 1.8118 - val_accuracy: 0.3003\n","Epoch 284/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5290 - accuracy: 0.4097 - val_loss: 1.8140 - val_accuracy: 0.2995\n","Epoch 285/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5304 - accuracy: 0.4071 - val_loss: 1.8130 - val_accuracy: 0.2994\n","Epoch 286/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5312 - accuracy: 0.4063 - val_loss: 1.8111 - val_accuracy: 0.3010\n","Epoch 287/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5268 - accuracy: 0.4104 - val_loss: 1.8119 - val_accuracy: 0.3017\n","Epoch 288/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5321 - accuracy: 0.4061 - val_loss: 1.8119 - val_accuracy: 0.3005\n","Epoch 289/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5306 - accuracy: 0.4084 - val_loss: 1.8121 - val_accuracy: 0.3003\n","Epoch 290/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5315 - accuracy: 0.4065 - val_loss: 1.8112 - val_accuracy: 0.2993\n","Epoch 291/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5324 - accuracy: 0.4062 - val_loss: 1.8185 - val_accuracy: 0.2996\n","Epoch 292/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5313 - accuracy: 0.4052 - val_loss: 1.8134 - val_accuracy: 0.2994\n","Epoch 293/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5309 - accuracy: 0.4060 - val_loss: 1.8119 - val_accuracy: 0.3016\n","Epoch 294/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5299 - accuracy: 0.4074 - val_loss: 1.8131 - val_accuracy: 0.3001\n","Epoch 295/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5309 - accuracy: 0.4067 - val_loss: 1.8123 - val_accuracy: 0.3014\n","Epoch 296/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5292 - accuracy: 0.4053 - val_loss: 1.8132 - val_accuracy: 0.2997\n","Epoch 297/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5293 - accuracy: 0.4085 - val_loss: 1.8135 - val_accuracy: 0.3006\n","Epoch 298/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5323 - accuracy: 0.4061 - val_loss: 1.8124 - val_accuracy: 0.3008\n","Epoch 299/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5264 - accuracy: 0.4091 - val_loss: 1.8166 - val_accuracy: 0.2994\n","Epoch 300/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5281 - accuracy: 0.4072 - val_loss: 1.8142 - val_accuracy: 0.3011\n","Epoch 301/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5287 - accuracy: 0.4069 - val_loss: 1.8117 - val_accuracy: 0.3016\n","Epoch 302/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5272 - accuracy: 0.4086 - val_loss: 1.8146 - val_accuracy: 0.3024\n","Epoch 303/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5307 - accuracy: 0.4067 - val_loss: 1.8110 - val_accuracy: 0.2985\n","Epoch 304/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5287 - accuracy: 0.4089 - val_loss: 1.8127 - val_accuracy: 0.3021\n","Epoch 305/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5278 - accuracy: 0.4078 - val_loss: 1.8120 - val_accuracy: 0.3012\n","Epoch 306/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5271 - accuracy: 0.4094 - val_loss: 1.8193 - val_accuracy: 0.2981\n","Epoch 307/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5279 - accuracy: 0.4080 - val_loss: 1.8172 - val_accuracy: 0.2989\n","Epoch 308/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5282 - accuracy: 0.4071 - val_loss: 1.8140 - val_accuracy: 0.3013\n","Epoch 309/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5302 - accuracy: 0.4067 - val_loss: 1.8137 - val_accuracy: 0.3016\n","Epoch 310/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5275 - accuracy: 0.4065 - val_loss: 1.8152 - val_accuracy: 0.2992\n","Epoch 311/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5241 - accuracy: 0.4087 - val_loss: 1.8151 - val_accuracy: 0.3005\n","Epoch 312/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5255 - accuracy: 0.4079 - val_loss: 1.8138 - val_accuracy: 0.2999\n","Epoch 313/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5257 - accuracy: 0.4075 - val_loss: 1.8156 - val_accuracy: 0.2972\n","Epoch 314/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5275 - accuracy: 0.4089 - val_loss: 1.8132 - val_accuracy: 0.3007\n","Epoch 315/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5264 - accuracy: 0.4080 - val_loss: 1.8142 - val_accuracy: 0.2993\n","Epoch 316/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5246 - accuracy: 0.4091 - val_loss: 1.8146 - val_accuracy: 0.3004\n","Epoch 317/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5249 - accuracy: 0.4097 - val_loss: 1.8149 - val_accuracy: 0.2999\n","Epoch 318/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5214 - accuracy: 0.4122 - val_loss: 1.8167 - val_accuracy: 0.3006\n","Epoch 319/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5270 - accuracy: 0.4075 - val_loss: 1.8152 - val_accuracy: 0.2988\n","Epoch 320/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5277 - accuracy: 0.4060 - val_loss: 1.8128 - val_accuracy: 0.2984\n","Epoch 321/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5248 - accuracy: 0.4086 - val_loss: 1.8157 - val_accuracy: 0.2999\n","Epoch 322/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5263 - accuracy: 0.4086 - val_loss: 1.8133 - val_accuracy: 0.3013\n","Epoch 323/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5230 - accuracy: 0.4087 - val_loss: 1.8164 - val_accuracy: 0.3023\n","Epoch 324/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5259 - accuracy: 0.4082 - val_loss: 1.8137 - val_accuracy: 0.3011\n","Epoch 325/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5241 - accuracy: 0.4073 - val_loss: 1.8131 - val_accuracy: 0.2996\n","Epoch 326/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5243 - accuracy: 0.4087 - val_loss: 1.8151 - val_accuracy: 0.3003\n","Epoch 327/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5272 - accuracy: 0.4084 - val_loss: 1.8110 - val_accuracy: 0.3011\n","Epoch 328/500\n","73923/73923 [==============================] - 7s 91us/step - loss: 1.5237 - accuracy: 0.4111 - val_loss: 1.8156 - val_accuracy: 0.3015\n","Epoch 329/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5241 - accuracy: 0.4098 - val_loss: 1.8143 - val_accuracy: 0.3036\n","Epoch 330/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5233 - accuracy: 0.4108 - val_loss: 1.8138 - val_accuracy: 0.3016\n","Epoch 331/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5262 - accuracy: 0.4084 - val_loss: 1.8120 - val_accuracy: 0.3021\n","Epoch 332/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5233 - accuracy: 0.4073 - val_loss: 1.8139 - val_accuracy: 0.3004\n","Epoch 333/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5235 - accuracy: 0.4097 - val_loss: 1.8147 - val_accuracy: 0.3017\n","Epoch 334/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5231 - accuracy: 0.4079 - val_loss: 1.8156 - val_accuracy: 0.3005\n","Epoch 335/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5244 - accuracy: 0.4097 - val_loss: 1.8157 - val_accuracy: 0.3010\n","Epoch 336/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5243 - accuracy: 0.4081 - val_loss: 1.8147 - val_accuracy: 0.2987\n","Epoch 337/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5211 - accuracy: 0.4118 - val_loss: 1.8171 - val_accuracy: 0.3005\n","Epoch 338/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5225 - accuracy: 0.4122 - val_loss: 1.8159 - val_accuracy: 0.3011\n","Epoch 339/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5231 - accuracy: 0.4095 - val_loss: 1.8164 - val_accuracy: 0.3012\n","Epoch 340/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5203 - accuracy: 0.4124 - val_loss: 1.8138 - val_accuracy: 0.3039\n","Epoch 341/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5264 - accuracy: 0.4090 - val_loss: 1.8097 - val_accuracy: 0.3000\n","Epoch 342/500\n","73923/73923 [==============================] - 7s 91us/step - loss: 1.5241 - accuracy: 0.4093 - val_loss: 1.8106 - val_accuracy: 0.3023\n","Epoch 343/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5207 - accuracy: 0.4098 - val_loss: 1.8168 - val_accuracy: 0.3033\n","Epoch 344/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5215 - accuracy: 0.4118 - val_loss: 1.8115 - val_accuracy: 0.3031\n","Epoch 345/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5250 - accuracy: 0.4085 - val_loss: 1.8109 - val_accuracy: 0.3039\n","Epoch 346/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5254 - accuracy: 0.4080 - val_loss: 1.8127 - val_accuracy: 0.3027\n","Epoch 347/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5217 - accuracy: 0.4101 - val_loss: 1.8139 - val_accuracy: 0.3002\n","Epoch 348/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5201 - accuracy: 0.4090 - val_loss: 1.8143 - val_accuracy: 0.3019\n","Epoch 349/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5224 - accuracy: 0.4090 - val_loss: 1.8143 - val_accuracy: 0.3034\n","Epoch 350/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5196 - accuracy: 0.4127 - val_loss: 1.8138 - val_accuracy: 0.3023\n","Epoch 351/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5232 - accuracy: 0.4093 - val_loss: 1.8162 - val_accuracy: 0.3004\n","Epoch 352/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5215 - accuracy: 0.4103 - val_loss: 1.8136 - val_accuracy: 0.3023\n","Epoch 353/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5236 - accuracy: 0.4092 - val_loss: 1.8134 - val_accuracy: 0.3028\n","Epoch 354/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5205 - accuracy: 0.4100 - val_loss: 1.8188 - val_accuracy: 0.3010\n","Epoch 355/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5222 - accuracy: 0.4090 - val_loss: 1.8119 - val_accuracy: 0.3043\n","Epoch 356/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5223 - accuracy: 0.4091 - val_loss: 1.8153 - val_accuracy: 0.3020\n","Epoch 357/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5212 - accuracy: 0.4089 - val_loss: 1.8144 - val_accuracy: 0.3033\n","Epoch 358/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5221 - accuracy: 0.4090 - val_loss: 1.8123 - val_accuracy: 0.3030\n","Epoch 359/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5233 - accuracy: 0.4105 - val_loss: 1.8103 - val_accuracy: 0.3024\n","Epoch 360/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5208 - accuracy: 0.4120 - val_loss: 1.8165 - val_accuracy: 0.3037\n","Epoch 361/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5243 - accuracy: 0.4073 - val_loss: 1.8093 - val_accuracy: 0.3010\n","Epoch 362/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5214 - accuracy: 0.4099 - val_loss: 1.8123 - val_accuracy: 0.3032\n","Epoch 363/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5212 - accuracy: 0.4111 - val_loss: 1.8167 - val_accuracy: 0.3017\n","Epoch 364/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5249 - accuracy: 0.4083 - val_loss: 1.8107 - val_accuracy: 0.3012\n","Epoch 365/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5205 - accuracy: 0.4106 - val_loss: 1.8150 - val_accuracy: 0.3012\n","Epoch 366/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5202 - accuracy: 0.4112 - val_loss: 1.8112 - val_accuracy: 0.3002\n","Epoch 367/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5212 - accuracy: 0.4088 - val_loss: 1.8096 - val_accuracy: 0.3018\n","Epoch 368/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5193 - accuracy: 0.4111 - val_loss: 1.8112 - val_accuracy: 0.3029\n","Epoch 369/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5186 - accuracy: 0.4107 - val_loss: 1.8130 - val_accuracy: 0.3050\n","Epoch 370/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5189 - accuracy: 0.4089 - val_loss: 1.8135 - val_accuracy: 0.3019\n","Epoch 371/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5205 - accuracy: 0.4110 - val_loss: 1.8121 - val_accuracy: 0.3008\n","Epoch 372/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5170 - accuracy: 0.4125 - val_loss: 1.8158 - val_accuracy: 0.3037\n","Epoch 373/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5222 - accuracy: 0.4095 - val_loss: 1.8106 - val_accuracy: 0.3020\n","Epoch 374/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5180 - accuracy: 0.4120 - val_loss: 1.8135 - val_accuracy: 0.3031\n","Epoch 375/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5216 - accuracy: 0.4085 - val_loss: 1.8131 - val_accuracy: 0.3011\n","Epoch 376/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5207 - accuracy: 0.4099 - val_loss: 1.8143 - val_accuracy: 0.3032\n","Epoch 377/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5178 - accuracy: 0.4092 - val_loss: 1.8171 - val_accuracy: 0.3004\n","Epoch 378/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5182 - accuracy: 0.4113 - val_loss: 1.8139 - val_accuracy: 0.3010\n","Epoch 379/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5159 - accuracy: 0.4126 - val_loss: 1.8152 - val_accuracy: 0.3025\n","Epoch 380/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5192 - accuracy: 0.4092 - val_loss: 1.8143 - val_accuracy: 0.3025\n","Epoch 381/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5187 - accuracy: 0.4098 - val_loss: 1.8164 - val_accuracy: 0.3037\n","Epoch 382/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5205 - accuracy: 0.4100 - val_loss: 1.8138 - val_accuracy: 0.3038\n","Epoch 383/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5123 - accuracy: 0.4121 - val_loss: 1.8144 - val_accuracy: 0.2991\n","Epoch 384/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5186 - accuracy: 0.4117 - val_loss: 1.8112 - val_accuracy: 0.3024\n","Epoch 385/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5201 - accuracy: 0.4091 - val_loss: 1.8101 - val_accuracy: 0.3033\n","Epoch 386/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5157 - accuracy: 0.4101 - val_loss: 1.8111 - val_accuracy: 0.3056\n","Epoch 387/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5152 - accuracy: 0.4113 - val_loss: 1.8126 - val_accuracy: 0.3025\n","Epoch 388/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5179 - accuracy: 0.4093 - val_loss: 1.8116 - val_accuracy: 0.3024\n","Epoch 389/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5168 - accuracy: 0.4100 - val_loss: 1.8119 - val_accuracy: 0.3043\n","Epoch 390/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5189 - accuracy: 0.4113 - val_loss: 1.8124 - val_accuracy: 0.3033\n","Epoch 391/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5176 - accuracy: 0.4126 - val_loss: 1.8160 - val_accuracy: 0.3037\n","Epoch 392/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5186 - accuracy: 0.4116 - val_loss: 1.8110 - val_accuracy: 0.3038\n","Epoch 393/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5145 - accuracy: 0.4130 - val_loss: 1.8154 - val_accuracy: 0.3025\n","Epoch 394/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5193 - accuracy: 0.4129 - val_loss: 1.8154 - val_accuracy: 0.3025\n","Epoch 395/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5145 - accuracy: 0.4130 - val_loss: 1.8156 - val_accuracy: 0.2993\n","Epoch 396/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5174 - accuracy: 0.4125 - val_loss: 1.8135 - val_accuracy: 0.3016\n","Epoch 397/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5183 - accuracy: 0.4143 - val_loss: 1.8154 - val_accuracy: 0.3030\n","Epoch 398/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5203 - accuracy: 0.4097 - val_loss: 1.8141 - val_accuracy: 0.3016\n","Epoch 399/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5175 - accuracy: 0.4126 - val_loss: 1.8146 - val_accuracy: 0.3021\n","Epoch 400/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5212 - accuracy: 0.4086 - val_loss: 1.8090 - val_accuracy: 0.3017\n","Epoch 401/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5174 - accuracy: 0.4110 - val_loss: 1.8153 - val_accuracy: 0.3018\n","Epoch 402/500\n","73923/73923 [==============================] - 8s 115us/step - loss: 1.5179 - accuracy: 0.4115 - val_loss: 1.8106 - val_accuracy: 0.3043\n","Epoch 403/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5165 - accuracy: 0.4112 - val_loss: 1.8154 - val_accuracy: 0.3018\n","Epoch 404/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5172 - accuracy: 0.4101 - val_loss: 1.8145 - val_accuracy: 0.3010\n","Epoch 405/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5151 - accuracy: 0.4130 - val_loss: 1.8148 - val_accuracy: 0.3029\n","Epoch 406/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5169 - accuracy: 0.4116 - val_loss: 1.8121 - val_accuracy: 0.3016\n","Epoch 407/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5139 - accuracy: 0.4121 - val_loss: 1.8159 - val_accuracy: 0.3031\n","Epoch 408/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5170 - accuracy: 0.4108 - val_loss: 1.8159 - val_accuracy: 0.3045\n","Epoch 409/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5171 - accuracy: 0.4128 - val_loss: 1.8145 - val_accuracy: 0.3018\n","Epoch 410/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5171 - accuracy: 0.4109 - val_loss: 1.8133 - val_accuracy: 0.3018\n","Epoch 411/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5176 - accuracy: 0.4111 - val_loss: 1.8134 - val_accuracy: 0.3038\n","Epoch 412/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5166 - accuracy: 0.4120 - val_loss: 1.8157 - val_accuracy: 0.3014\n","Epoch 413/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5175 - accuracy: 0.4124 - val_loss: 1.8141 - val_accuracy: 0.3015\n","Epoch 414/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5150 - accuracy: 0.4107 - val_loss: 1.8135 - val_accuracy: 0.3029\n","Epoch 415/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5195 - accuracy: 0.4085 - val_loss: 1.8127 - val_accuracy: 0.3039\n","Epoch 416/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5183 - accuracy: 0.4098 - val_loss: 1.8151 - val_accuracy: 0.3020\n","Epoch 417/500\n","73923/73923 [==============================] - 7s 92us/step - loss: 1.5170 - accuracy: 0.4115 - val_loss: 1.8104 - val_accuracy: 0.3025\n","Epoch 418/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5150 - accuracy: 0.4101 - val_loss: 1.8141 - val_accuracy: 0.3037\n","Epoch 419/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5120 - accuracy: 0.4128 - val_loss: 1.8136 - val_accuracy: 0.3010\n","Epoch 420/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5144 - accuracy: 0.4128 - val_loss: 1.8146 - val_accuracy: 0.3016\n","Epoch 421/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5161 - accuracy: 0.4111 - val_loss: 1.8148 - val_accuracy: 0.2997\n","Epoch 422/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5137 - accuracy: 0.4136 - val_loss: 1.8162 - val_accuracy: 0.3029\n","Epoch 423/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5147 - accuracy: 0.4116 - val_loss: 1.8183 - val_accuracy: 0.3016\n","Epoch 424/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5143 - accuracy: 0.4116 - val_loss: 1.8137 - val_accuracy: 0.3025\n","Epoch 425/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5110 - accuracy: 0.4151 - val_loss: 1.8158 - val_accuracy: 0.3019\n","Epoch 426/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5118 - accuracy: 0.4116 - val_loss: 1.8151 - val_accuracy: 0.3028\n","Epoch 427/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5169 - accuracy: 0.4122 - val_loss: 1.8130 - val_accuracy: 0.3023\n","Epoch 428/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5144 - accuracy: 0.4132 - val_loss: 1.8164 - val_accuracy: 0.3000\n","Epoch 429/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5171 - accuracy: 0.4105 - val_loss: 1.8138 - val_accuracy: 0.3016\n","Epoch 430/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5159 - accuracy: 0.4131 - val_loss: 1.8137 - val_accuracy: 0.3018\n","Epoch 431/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5171 - accuracy: 0.4121 - val_loss: 1.8134 - val_accuracy: 0.3038\n","Epoch 432/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5128 - accuracy: 0.4133 - val_loss: 1.8200 - val_accuracy: 0.3004\n","Epoch 433/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5130 - accuracy: 0.4125 - val_loss: 1.8173 - val_accuracy: 0.3013\n","Epoch 434/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5174 - accuracy: 0.4124 - val_loss: 1.8141 - val_accuracy: 0.3008\n","Epoch 435/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5141 - accuracy: 0.4139 - val_loss: 1.8178 - val_accuracy: 0.3007\n","Epoch 436/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5148 - accuracy: 0.4120 - val_loss: 1.8155 - val_accuracy: 0.3035\n","Epoch 437/500\n","73923/73923 [==============================] - 8s 102us/step - loss: 1.5177 - accuracy: 0.4101 - val_loss: 1.8142 - val_accuracy: 0.3029\n","Epoch 438/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5137 - accuracy: 0.4135 - val_loss: 1.8175 - val_accuracy: 0.3014\n","Epoch 439/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5129 - accuracy: 0.4141 - val_loss: 1.8148 - val_accuracy: 0.3024\n","Epoch 440/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5151 - accuracy: 0.4131 - val_loss: 1.8160 - val_accuracy: 0.3033\n","Epoch 441/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5141 - accuracy: 0.4131 - val_loss: 1.8171 - val_accuracy: 0.3020\n","Epoch 442/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5117 - accuracy: 0.4163 - val_loss: 1.8177 - val_accuracy: 0.3042\n","Epoch 443/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5147 - accuracy: 0.4145 - val_loss: 1.8134 - val_accuracy: 0.3045\n","Epoch 444/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5109 - accuracy: 0.4153 - val_loss: 1.8186 - val_accuracy: 0.3053\n","Epoch 445/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5106 - accuracy: 0.4140 - val_loss: 1.8148 - val_accuracy: 0.3033\n","Epoch 446/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5142 - accuracy: 0.4118 - val_loss: 1.8154 - val_accuracy: 0.3030\n","Epoch 447/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5124 - accuracy: 0.4133 - val_loss: 1.8146 - val_accuracy: 0.3049\n","Epoch 448/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5099 - accuracy: 0.4135 - val_loss: 1.8196 - val_accuracy: 0.3027\n","Epoch 449/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5137 - accuracy: 0.4141 - val_loss: 1.8161 - val_accuracy: 0.3040\n","Epoch 450/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5129 - accuracy: 0.4115 - val_loss: 1.8191 - val_accuracy: 0.3029\n","Epoch 451/500\n","73923/73923 [==============================] - 8s 102us/step - loss: 1.5149 - accuracy: 0.4135 - val_loss: 1.8145 - val_accuracy: 0.3034\n","Epoch 452/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5118 - accuracy: 0.4127 - val_loss: 1.8156 - val_accuracy: 0.3029\n","Epoch 453/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5139 - accuracy: 0.4134 - val_loss: 1.8168 - val_accuracy: 0.3010\n","Epoch 454/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5154 - accuracy: 0.4130 - val_loss: 1.8162 - val_accuracy: 0.3018\n","Epoch 455/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5093 - accuracy: 0.4126 - val_loss: 1.8134 - val_accuracy: 0.3038\n","Epoch 456/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5101 - accuracy: 0.4141 - val_loss: 1.8170 - val_accuracy: 0.3016\n","Epoch 457/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5136 - accuracy: 0.4118 - val_loss: 1.8146 - val_accuracy: 0.3026\n","Epoch 458/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5138 - accuracy: 0.4131 - val_loss: 1.8126 - val_accuracy: 0.3059\n","Epoch 459/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5127 - accuracy: 0.4141 - val_loss: 1.8148 - val_accuracy: 0.3043\n","Epoch 460/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5109 - accuracy: 0.4156 - val_loss: 1.8161 - val_accuracy: 0.3003\n","Epoch 461/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5128 - accuracy: 0.4132 - val_loss: 1.8143 - val_accuracy: 0.3010\n","Epoch 462/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5130 - accuracy: 0.4124 - val_loss: 1.8131 - val_accuracy: 0.3008\n","Epoch 463/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5132 - accuracy: 0.4121 - val_loss: 1.8160 - val_accuracy: 0.3006\n","Epoch 464/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5120 - accuracy: 0.4122 - val_loss: 1.8144 - val_accuracy: 0.3015\n","Epoch 465/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5128 - accuracy: 0.4127 - val_loss: 1.8147 - val_accuracy: 0.3018\n","Epoch 466/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5116 - accuracy: 0.4147 - val_loss: 1.8149 - val_accuracy: 0.3029\n","Epoch 467/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5113 - accuracy: 0.4138 - val_loss: 1.8154 - val_accuracy: 0.3012\n","Epoch 468/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5126 - accuracy: 0.4136 - val_loss: 1.8173 - val_accuracy: 0.3026\n","Epoch 469/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5095 - accuracy: 0.4132 - val_loss: 1.8170 - val_accuracy: 0.3013\n","Epoch 470/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5125 - accuracy: 0.4146 - val_loss: 1.8170 - val_accuracy: 0.3020\n","Epoch 471/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5108 - accuracy: 0.4144 - val_loss: 1.8176 - val_accuracy: 0.3029\n","Epoch 472/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5112 - accuracy: 0.4145 - val_loss: 1.8209 - val_accuracy: 0.2993\n","Epoch 473/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5117 - accuracy: 0.4136 - val_loss: 1.8186 - val_accuracy: 0.3021\n","Epoch 474/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5102 - accuracy: 0.4138 - val_loss: 1.8206 - val_accuracy: 0.3014\n","Epoch 475/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5085 - accuracy: 0.4154 - val_loss: 1.8157 - val_accuracy: 0.3035\n","Epoch 476/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5114 - accuracy: 0.4138 - val_loss: 1.8170 - val_accuracy: 0.3023\n","Epoch 477/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5114 - accuracy: 0.4135 - val_loss: 1.8164 - val_accuracy: 0.3042\n","Epoch 478/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5092 - accuracy: 0.4157 - val_loss: 1.8177 - val_accuracy: 0.2995\n","Epoch 479/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5089 - accuracy: 0.4129 - val_loss: 1.8219 - val_accuracy: 0.2998\n","Epoch 480/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5107 - accuracy: 0.4133 - val_loss: 1.8191 - val_accuracy: 0.3033\n","Epoch 481/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5124 - accuracy: 0.4141 - val_loss: 1.8146 - val_accuracy: 0.3016\n","Epoch 482/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5112 - accuracy: 0.4138 - val_loss: 1.8168 - val_accuracy: 0.3024\n","Epoch 483/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5124 - accuracy: 0.4135 - val_loss: 1.8180 - val_accuracy: 0.3007\n","Epoch 484/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5095 - accuracy: 0.4145 - val_loss: 1.8156 - val_accuracy: 0.3028\n","Epoch 485/500\n","73923/73923 [==============================] - 7s 95us/step - loss: 1.5118 - accuracy: 0.4150 - val_loss: 1.8164 - val_accuracy: 0.3020\n","Epoch 486/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5109 - accuracy: 0.4145 - val_loss: 1.8179 - val_accuracy: 0.3012\n","Epoch 487/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5108 - accuracy: 0.4142 - val_loss: 1.8156 - val_accuracy: 0.3018\n","Epoch 488/500\n","73923/73923 [==============================] - 8s 112us/step - loss: 1.5082 - accuracy: 0.4145 - val_loss: 1.8197 - val_accuracy: 0.3010\n","Epoch 489/500\n","73923/73923 [==============================] - 7s 93us/step - loss: 1.5102 - accuracy: 0.4124 - val_loss: 1.8161 - val_accuracy: 0.3009\n","Epoch 490/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5110 - accuracy: 0.4138 - val_loss: 1.8174 - val_accuracy: 0.3029\n","Epoch 491/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5090 - accuracy: 0.4156 - val_loss: 1.8159 - val_accuracy: 0.3008\n","Epoch 492/500\n","73923/73923 [==============================] - 7s 97us/step - loss: 1.5060 - accuracy: 0.4168 - val_loss: 1.8188 - val_accuracy: 0.3027\n","Epoch 493/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5102 - accuracy: 0.4136 - val_loss: 1.8146 - val_accuracy: 0.3029\n","Epoch 494/500\n","73923/73923 [==============================] - 7s 101us/step - loss: 1.5080 - accuracy: 0.4114 - val_loss: 1.8162 - val_accuracy: 0.3042\n","Epoch 495/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5066 - accuracy: 0.4159 - val_loss: 1.8201 - val_accuracy: 0.3022\n","Epoch 496/500\n","73923/73923 [==============================] - 7s 98us/step - loss: 1.5088 - accuracy: 0.4150 - val_loss: 1.8176 - val_accuracy: 0.3012\n","Epoch 497/500\n","73923/73923 [==============================] - 7s 99us/step - loss: 1.5104 - accuracy: 0.4141 - val_loss: 1.8172 - val_accuracy: 0.3023\n","Epoch 498/500\n","73923/73923 [==============================] - 7s 94us/step - loss: 1.5091 - accuracy: 0.4168 - val_loss: 1.8171 - val_accuracy: 0.3049\n","Epoch 499/500\n","73923/73923 [==============================] - 7s 96us/step - loss: 1.5150 - accuracy: 0.4135 - val_loss: 1.8150 - val_accuracy: 0.3024\n","Epoch 500/500\n","73923/73923 [==============================] - 7s 100us/step - loss: 1.5090 - accuracy: 0.4157 - val_loss: 1.8195 - val_accuracy: 0.3007\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f3849822630>"]},"metadata":{"tags":[]},"execution_count":197}]},{"cell_type":"code","metadata":{"id":"tdWLxTs1tvu3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593474495978,"user_tz":180,"elapsed":6140287,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"b5e25936-1cf0-42da-de73-a2a88db873fb"},"source":["acur_test = regressor.evaluate(X_test, y_test, verbose=0)\n","accuracy_modelo5 = acur_test[1]\n","print(accuracy_modelo5)"],"execution_count":198,"outputs":[{"output_type":"stream","text":["0.30068719387054443\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xK0lCAkrc4ub","colab_type":"text"},"source":["MATRIZ DE CONFUSÃO"]},{"cell_type":"code","metadata":{"id":"Ykdfimtic2hd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593474497005,"user_tz":180,"elapsed":6141307,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["y_predicted_lstm = regressor.predict_classes(X_test)\n","lstm_results = pd.DataFrame(list(zip(y_predicted_lstm, y_test)), columns =['predito', 'real'])\n","df_confusion = pd.crosstab(lstm_results.real, lstm_results.predito)\n","\n","export_path = workdir_path + '/matrizConfusaoLSTM2.csv'\n","df_confusion.to_csv (export_path, index = True, header=True)"],"execution_count":199,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Up8gfYgiaQHE","colab_type":"text"},"source":["CRIANDO A REDE COM 3 CAMADAS"]},{"cell_type":"code","metadata":{"id":"_258fj8-xOCF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"ok","timestamp":1593474497385,"user_tz":180,"elapsed":6141657,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"0900968a-0d94-4c26-fdf1-fdca789510e9"},"source":["# Initicializar a RNN\n","regressor = Sequential()\n"," \n","# Adicionar a primeira camada LSTM e Dropout \n","regressor.add(LSTM(units = primeiro_neuronio_lstm, return_sequences = True, input_shape=(1, x_train_prepared.shape[1])))\n","regressor.add(Dropout(0.2))\n"," \n","# Adicionar a segunda camada LSTM e Dropout\n","regressor.add(LSTM(units = segundo_neuronio_lstm, return_sequences = True))\n","regressor.add(Dropout(0.2))\n"," \n","# Adicionar a terceira camada LSTM e Dropout\n","regressor.add(LSTM(units = terceiro_neuronio_lstm))\n","regressor.add(Dropout(0.2))\n"," \n","# camada de saída\n","regressor.add(Dense(units = camadas_saida, activation='softmax')) #para classificação dar como entrada as classes com função de ativação softmax\n","\n","# Compilar a rede\n","regressor.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Visualizar a rede\n","regressor.summary()"],"execution_count":200,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_12 (LSTM)               (None, 1, 64)             38144     \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 1, 64)             0         \n","_________________________________________________________________\n","lstm_13 (LSTM)               (None, 1, 32)             12416     \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 1, 32)             0         \n","_________________________________________________________________\n","lstm_14 (LSTM)               (None, 16)                3136      \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 16)                0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 7)                 119       \n","=================================================================\n","Total params: 53,815\n","Trainable params: 53,815\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dl5ZqFT8yTnB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593478980601,"user_tz":180,"elapsed":10624848,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"4e3438ea-c767-4cb2-ca10-49f4e1232339"},"source":["#fitting\n","regressor.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = epocas, batch_size = 32 )"],"execution_count":201,"outputs":[{"output_type":"stream","text":["Train on 73923 samples, validate on 18481 samples\n","Epoch 1/500\n","73923/73923 [==============================] - 11s 146us/step - loss: 1.8990 - accuracy: 0.2087 - val_loss: 1.8939 - val_accuracy: 0.2154\n","Epoch 2/500\n","73923/73923 [==============================] - 10s 132us/step - loss: 1.8801 - accuracy: 0.2297 - val_loss: 1.8802 - val_accuracy: 0.2300\n","Epoch 3/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.8599 - accuracy: 0.2464 - val_loss: 1.8711 - val_accuracy: 0.2367\n","Epoch 4/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.8423 - accuracy: 0.2576 - val_loss: 1.8643 - val_accuracy: 0.2421\n","Epoch 5/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.8274 - accuracy: 0.2704 - val_loss: 1.8601 - val_accuracy: 0.2491\n","Epoch 6/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.8169 - accuracy: 0.2758 - val_loss: 1.8548 - val_accuracy: 0.2501\n","Epoch 7/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.8052 - accuracy: 0.2831 - val_loss: 1.8529 - val_accuracy: 0.2542\n","Epoch 8/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.7956 - accuracy: 0.2904 - val_loss: 1.8509 - val_accuracy: 0.2580\n","Epoch 9/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.7868 - accuracy: 0.2939 - val_loss: 1.8478 - val_accuracy: 0.2642\n","Epoch 10/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.7791 - accuracy: 0.3007 - val_loss: 1.8500 - val_accuracy: 0.2625\n","Epoch 11/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.7759 - accuracy: 0.3038 - val_loss: 1.8441 - val_accuracy: 0.2667\n","Epoch 12/500\n","73923/73923 [==============================] - 10s 129us/step - loss: 1.7668 - accuracy: 0.3108 - val_loss: 1.8442 - val_accuracy: 0.2654\n","Epoch 13/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.7611 - accuracy: 0.3132 - val_loss: 1.8431 - val_accuracy: 0.2680\n","Epoch 14/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.7570 - accuracy: 0.3155 - val_loss: 1.8435 - val_accuracy: 0.2684\n","Epoch 15/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.7488 - accuracy: 0.3172 - val_loss: 1.8415 - val_accuracy: 0.2720\n","Epoch 16/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.7468 - accuracy: 0.3204 - val_loss: 1.8424 - val_accuracy: 0.2721\n","Epoch 17/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.7421 - accuracy: 0.3233 - val_loss: 1.8368 - val_accuracy: 0.2757\n","Epoch 18/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.7395 - accuracy: 0.3236 - val_loss: 1.8367 - val_accuracy: 0.2738\n","Epoch 19/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.7341 - accuracy: 0.3275 - val_loss: 1.8389 - val_accuracy: 0.2737\n","Epoch 20/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.7310 - accuracy: 0.3300 - val_loss: 1.8361 - val_accuracy: 0.2775\n","Epoch 21/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.7271 - accuracy: 0.3326 - val_loss: 1.8339 - val_accuracy: 0.2735\n","Epoch 22/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.7233 - accuracy: 0.3341 - val_loss: 1.8329 - val_accuracy: 0.2795\n","Epoch 23/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.7197 - accuracy: 0.3356 - val_loss: 1.8351 - val_accuracy: 0.2799\n","Epoch 24/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.7173 - accuracy: 0.3365 - val_loss: 1.8312 - val_accuracy: 0.2795\n","Epoch 25/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.7129 - accuracy: 0.3391 - val_loss: 1.8318 - val_accuracy: 0.2802\n","Epoch 26/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.7099 - accuracy: 0.3388 - val_loss: 1.8330 - val_accuracy: 0.2807\n","Epoch 27/500\n","73923/73923 [==============================] - 10s 129us/step - loss: 1.7072 - accuracy: 0.3423 - val_loss: 1.8294 - val_accuracy: 0.2796\n","Epoch 28/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.7054 - accuracy: 0.3435 - val_loss: 1.8292 - val_accuracy: 0.2805\n","Epoch 29/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.7016 - accuracy: 0.3443 - val_loss: 1.8263 - val_accuracy: 0.2777\n","Epoch 30/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.7023 - accuracy: 0.3443 - val_loss: 1.8276 - val_accuracy: 0.2801\n","Epoch 31/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6992 - accuracy: 0.3459 - val_loss: 1.8274 - val_accuracy: 0.2789\n","Epoch 32/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6986 - accuracy: 0.3459 - val_loss: 1.8263 - val_accuracy: 0.2805\n","Epoch 33/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6920 - accuracy: 0.3484 - val_loss: 1.8273 - val_accuracy: 0.2786\n","Epoch 34/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6903 - accuracy: 0.3501 - val_loss: 1.8268 - val_accuracy: 0.2833\n","Epoch 35/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6913 - accuracy: 0.3515 - val_loss: 1.8271 - val_accuracy: 0.2810\n","Epoch 36/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6892 - accuracy: 0.3522 - val_loss: 1.8250 - val_accuracy: 0.2833\n","Epoch 37/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6892 - accuracy: 0.3502 - val_loss: 1.8258 - val_accuracy: 0.2823\n","Epoch 38/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6854 - accuracy: 0.3507 - val_loss: 1.8244 - val_accuracy: 0.2817\n","Epoch 39/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6815 - accuracy: 0.3539 - val_loss: 1.8244 - val_accuracy: 0.2852\n","Epoch 40/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6809 - accuracy: 0.3533 - val_loss: 1.8254 - val_accuracy: 0.2853\n","Epoch 41/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6810 - accuracy: 0.3566 - val_loss: 1.8227 - val_accuracy: 0.2840\n","Epoch 42/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6778 - accuracy: 0.3552 - val_loss: 1.8225 - val_accuracy: 0.2858\n","Epoch 43/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6798 - accuracy: 0.3552 - val_loss: 1.8215 - val_accuracy: 0.2872\n","Epoch 44/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6747 - accuracy: 0.3581 - val_loss: 1.8267 - val_accuracy: 0.2891\n","Epoch 45/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6735 - accuracy: 0.3575 - val_loss: 1.8235 - val_accuracy: 0.2878\n","Epoch 46/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6711 - accuracy: 0.3617 - val_loss: 1.8231 - val_accuracy: 0.2885\n","Epoch 47/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6732 - accuracy: 0.3583 - val_loss: 1.8236 - val_accuracy: 0.2898\n","Epoch 48/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6699 - accuracy: 0.3591 - val_loss: 1.8213 - val_accuracy: 0.2901\n","Epoch 49/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6680 - accuracy: 0.3613 - val_loss: 1.8244 - val_accuracy: 0.2901\n","Epoch 50/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6672 - accuracy: 0.3608 - val_loss: 1.8210 - val_accuracy: 0.2876\n","Epoch 51/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6664 - accuracy: 0.3613 - val_loss: 1.8215 - val_accuracy: 0.2872\n","Epoch 52/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6657 - accuracy: 0.3615 - val_loss: 1.8207 - val_accuracy: 0.2883\n","Epoch 53/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6624 - accuracy: 0.3635 - val_loss: 1.8242 - val_accuracy: 0.2884\n","Epoch 54/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6602 - accuracy: 0.3674 - val_loss: 1.8210 - val_accuracy: 0.2867\n","Epoch 55/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6624 - accuracy: 0.3644 - val_loss: 1.8190 - val_accuracy: 0.2911\n","Epoch 56/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6586 - accuracy: 0.3644 - val_loss: 1.8205 - val_accuracy: 0.2879\n","Epoch 57/500\n","73923/73923 [==============================] - 11s 144us/step - loss: 1.6607 - accuracy: 0.3641 - val_loss: 1.8191 - val_accuracy: 0.2897\n","Epoch 58/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6582 - accuracy: 0.3632 - val_loss: 1.8226 - val_accuracy: 0.2921\n","Epoch 59/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6538 - accuracy: 0.3669 - val_loss: 1.8237 - val_accuracy: 0.2899\n","Epoch 60/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6540 - accuracy: 0.3670 - val_loss: 1.8195 - val_accuracy: 0.2938\n","Epoch 61/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6560 - accuracy: 0.3673 - val_loss: 1.8204 - val_accuracy: 0.2872\n","Epoch 62/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6498 - accuracy: 0.3704 - val_loss: 1.8184 - val_accuracy: 0.2902\n","Epoch 63/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6528 - accuracy: 0.3665 - val_loss: 1.8197 - val_accuracy: 0.2915\n","Epoch 64/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6505 - accuracy: 0.3706 - val_loss: 1.8201 - val_accuracy: 0.2886\n","Epoch 65/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6492 - accuracy: 0.3696 - val_loss: 1.8181 - val_accuracy: 0.2915\n","Epoch 66/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6512 - accuracy: 0.3693 - val_loss: 1.8167 - val_accuracy: 0.2907\n","Epoch 67/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6459 - accuracy: 0.3701 - val_loss: 1.8168 - val_accuracy: 0.2907\n","Epoch 68/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6485 - accuracy: 0.3692 - val_loss: 1.8154 - val_accuracy: 0.2921\n","Epoch 69/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6443 - accuracy: 0.3708 - val_loss: 1.8179 - val_accuracy: 0.2925\n","Epoch 70/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6431 - accuracy: 0.3708 - val_loss: 1.8172 - val_accuracy: 0.2891\n","Epoch 71/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6424 - accuracy: 0.3748 - val_loss: 1.8198 - val_accuracy: 0.2952\n","Epoch 72/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6433 - accuracy: 0.3711 - val_loss: 1.8150 - val_accuracy: 0.2891\n","Epoch 73/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6426 - accuracy: 0.3728 - val_loss: 1.8201 - val_accuracy: 0.2901\n","Epoch 74/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6429 - accuracy: 0.3736 - val_loss: 1.8195 - val_accuracy: 0.2934\n","Epoch 75/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6403 - accuracy: 0.3745 - val_loss: 1.8178 - val_accuracy: 0.2916\n","Epoch 76/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6394 - accuracy: 0.3728 - val_loss: 1.8140 - val_accuracy: 0.2929\n","Epoch 77/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6405 - accuracy: 0.3732 - val_loss: 1.8183 - val_accuracy: 0.2879\n","Epoch 78/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.6387 - accuracy: 0.3728 - val_loss: 1.8171 - val_accuracy: 0.2937\n","Epoch 79/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6378 - accuracy: 0.3740 - val_loss: 1.8129 - val_accuracy: 0.2934\n","Epoch 80/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6386 - accuracy: 0.3719 - val_loss: 1.8176 - val_accuracy: 0.2921\n","Epoch 81/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6378 - accuracy: 0.3745 - val_loss: 1.8158 - val_accuracy: 0.2911\n","Epoch 82/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6339 - accuracy: 0.3751 - val_loss: 1.8175 - val_accuracy: 0.2916\n","Epoch 83/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6321 - accuracy: 0.3747 - val_loss: 1.8166 - val_accuracy: 0.2965\n","Epoch 84/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6340 - accuracy: 0.3750 - val_loss: 1.8178 - val_accuracy: 0.2933\n","Epoch 85/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6320 - accuracy: 0.3751 - val_loss: 1.8183 - val_accuracy: 0.2920\n","Epoch 86/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6339 - accuracy: 0.3775 - val_loss: 1.8179 - val_accuracy: 0.2935\n","Epoch 87/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6335 - accuracy: 0.3743 - val_loss: 1.8170 - val_accuracy: 0.2915\n","Epoch 88/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6333 - accuracy: 0.3765 - val_loss: 1.8124 - val_accuracy: 0.2933\n","Epoch 89/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6287 - accuracy: 0.3766 - val_loss: 1.8153 - val_accuracy: 0.2955\n","Epoch 90/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.6305 - accuracy: 0.3759 - val_loss: 1.8128 - val_accuracy: 0.2944\n","Epoch 91/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6289 - accuracy: 0.3792 - val_loss: 1.8142 - val_accuracy: 0.2950\n","Epoch 92/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6317 - accuracy: 0.3753 - val_loss: 1.8139 - val_accuracy: 0.2937\n","Epoch 93/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6273 - accuracy: 0.3787 - val_loss: 1.8191 - val_accuracy: 0.2939\n","Epoch 94/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6266 - accuracy: 0.3783 - val_loss: 1.8140 - val_accuracy: 0.2928\n","Epoch 95/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6266 - accuracy: 0.3783 - val_loss: 1.8138 - val_accuracy: 0.2924\n","Epoch 96/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6259 - accuracy: 0.3817 - val_loss: 1.8201 - val_accuracy: 0.2916\n","Epoch 97/500\n","73923/73923 [==============================] - 10s 129us/step - loss: 1.6269 - accuracy: 0.3786 - val_loss: 1.8129 - val_accuracy: 0.2916\n","Epoch 98/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6263 - accuracy: 0.3784 - val_loss: 1.8146 - val_accuracy: 0.2928\n","Epoch 99/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6269 - accuracy: 0.3766 - val_loss: 1.8128 - val_accuracy: 0.2942\n","Epoch 100/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6232 - accuracy: 0.3795 - val_loss: 1.8186 - val_accuracy: 0.2924\n","Epoch 101/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6205 - accuracy: 0.3829 - val_loss: 1.8162 - val_accuracy: 0.2915\n","Epoch 102/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6246 - accuracy: 0.3791 - val_loss: 1.8135 - val_accuracy: 0.2962\n","Epoch 103/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6237 - accuracy: 0.3822 - val_loss: 1.8156 - val_accuracy: 0.2937\n","Epoch 104/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6204 - accuracy: 0.3827 - val_loss: 1.8162 - val_accuracy: 0.2926\n","Epoch 105/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6189 - accuracy: 0.3802 - val_loss: 1.8156 - val_accuracy: 0.2935\n","Epoch 106/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.6206 - accuracy: 0.3829 - val_loss: 1.8110 - val_accuracy: 0.2931\n","Epoch 107/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6198 - accuracy: 0.3817 - val_loss: 1.8171 - val_accuracy: 0.2929\n","Epoch 108/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6200 - accuracy: 0.3816 - val_loss: 1.8147 - val_accuracy: 0.2937\n","Epoch 109/500\n","73923/73923 [==============================] - 10s 132us/step - loss: 1.6184 - accuracy: 0.3818 - val_loss: 1.8123 - val_accuracy: 0.2937\n","Epoch 110/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6192 - accuracy: 0.3807 - val_loss: 1.8174 - val_accuracy: 0.2934\n","Epoch 111/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6149 - accuracy: 0.3841 - val_loss: 1.8125 - val_accuracy: 0.2972\n","Epoch 112/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6158 - accuracy: 0.3818 - val_loss: 1.8192 - val_accuracy: 0.2953\n","Epoch 113/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6169 - accuracy: 0.3843 - val_loss: 1.8147 - val_accuracy: 0.2927\n","Epoch 114/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6182 - accuracy: 0.3811 - val_loss: 1.8160 - val_accuracy: 0.2941\n","Epoch 115/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6161 - accuracy: 0.3825 - val_loss: 1.8156 - val_accuracy: 0.2936\n","Epoch 116/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6180 - accuracy: 0.3823 - val_loss: 1.8147 - val_accuracy: 0.2934\n","Epoch 117/500\n","73923/73923 [==============================] - 10s 129us/step - loss: 1.6160 - accuracy: 0.3861 - val_loss: 1.8135 - val_accuracy: 0.2942\n","Epoch 118/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6152 - accuracy: 0.3850 - val_loss: 1.8143 - val_accuracy: 0.2959\n","Epoch 119/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.6170 - accuracy: 0.3823 - val_loss: 1.8125 - val_accuracy: 0.2971\n","Epoch 120/500\n","73923/73923 [==============================] - 10s 133us/step - loss: 1.6128 - accuracy: 0.3859 - val_loss: 1.8141 - val_accuracy: 0.2961\n","Epoch 121/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6134 - accuracy: 0.3856 - val_loss: 1.8132 - val_accuracy: 0.2945\n","Epoch 122/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6152 - accuracy: 0.3841 - val_loss: 1.8120 - val_accuracy: 0.2946\n","Epoch 123/500\n","73923/73923 [==============================] - 11s 142us/step - loss: 1.6118 - accuracy: 0.3853 - val_loss: 1.8183 - val_accuracy: 0.2969\n","Epoch 124/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6123 - accuracy: 0.3869 - val_loss: 1.8139 - val_accuracy: 0.2959\n","Epoch 125/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6123 - accuracy: 0.3838 - val_loss: 1.8156 - val_accuracy: 0.2957\n","Epoch 126/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6112 - accuracy: 0.3845 - val_loss: 1.8156 - val_accuracy: 0.2971\n","Epoch 127/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6096 - accuracy: 0.3849 - val_loss: 1.8154 - val_accuracy: 0.2954\n","Epoch 128/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6109 - accuracy: 0.3861 - val_loss: 1.8137 - val_accuracy: 0.2968\n","Epoch 129/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6105 - accuracy: 0.3856 - val_loss: 1.8142 - val_accuracy: 0.2980\n","Epoch 130/500\n","73923/73923 [==============================] - 10s 133us/step - loss: 1.6082 - accuracy: 0.3879 - val_loss: 1.8141 - val_accuracy: 0.2968\n","Epoch 131/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.6077 - accuracy: 0.3875 - val_loss: 1.8121 - val_accuracy: 0.2966\n","Epoch 132/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6086 - accuracy: 0.3868 - val_loss: 1.8136 - val_accuracy: 0.2972\n","Epoch 133/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6112 - accuracy: 0.3865 - val_loss: 1.8095 - val_accuracy: 0.2967\n","Epoch 134/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.6053 - accuracy: 0.3863 - val_loss: 1.8147 - val_accuracy: 0.2982\n","Epoch 135/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6051 - accuracy: 0.3879 - val_loss: 1.8128 - val_accuracy: 0.2996\n","Epoch 136/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6064 - accuracy: 0.3868 - val_loss: 1.8146 - val_accuracy: 0.2952\n","Epoch 137/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6068 - accuracy: 0.3869 - val_loss: 1.8137 - val_accuracy: 0.2957\n","Epoch 138/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6082 - accuracy: 0.3865 - val_loss: 1.8108 - val_accuracy: 0.2990\n","Epoch 139/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6076 - accuracy: 0.3864 - val_loss: 1.8122 - val_accuracy: 0.2971\n","Epoch 140/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6075 - accuracy: 0.3867 - val_loss: 1.8107 - val_accuracy: 0.2990\n","Epoch 141/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6067 - accuracy: 0.3880 - val_loss: 1.8099 - val_accuracy: 0.2965\n","Epoch 142/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6052 - accuracy: 0.3865 - val_loss: 1.8154 - val_accuracy: 0.2972\n","Epoch 143/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.6060 - accuracy: 0.3878 - val_loss: 1.8158 - val_accuracy: 0.2979\n","Epoch 144/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.6036 - accuracy: 0.3880 - val_loss: 1.8090 - val_accuracy: 0.2984\n","Epoch 145/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6011 - accuracy: 0.3917 - val_loss: 1.8144 - val_accuracy: 0.2987\n","Epoch 146/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.6054 - accuracy: 0.3885 - val_loss: 1.8127 - val_accuracy: 0.2990\n","Epoch 147/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6049 - accuracy: 0.3874 - val_loss: 1.8121 - val_accuracy: 0.2977\n","Epoch 148/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6046 - accuracy: 0.3892 - val_loss: 1.8137 - val_accuracy: 0.2993\n","Epoch 149/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6040 - accuracy: 0.3893 - val_loss: 1.8108 - val_accuracy: 0.2992\n","Epoch 150/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6064 - accuracy: 0.3855 - val_loss: 1.8121 - val_accuracy: 0.2987\n","Epoch 151/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.6007 - accuracy: 0.3911 - val_loss: 1.8149 - val_accuracy: 0.2981\n","Epoch 152/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6026 - accuracy: 0.3876 - val_loss: 1.8126 - val_accuracy: 0.2982\n","Epoch 153/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.6037 - accuracy: 0.3907 - val_loss: 1.8135 - val_accuracy: 0.2978\n","Epoch 154/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.6033 - accuracy: 0.3889 - val_loss: 1.8076 - val_accuracy: 0.3001\n","Epoch 155/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6023 - accuracy: 0.3878 - val_loss: 1.8138 - val_accuracy: 0.2996\n","Epoch 156/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.6007 - accuracy: 0.3901 - val_loss: 1.8133 - val_accuracy: 0.2990\n","Epoch 157/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.6004 - accuracy: 0.3893 - val_loss: 1.8137 - val_accuracy: 0.2995\n","Epoch 158/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5983 - accuracy: 0.3923 - val_loss: 1.8146 - val_accuracy: 0.2960\n","Epoch 159/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.6028 - accuracy: 0.3885 - val_loss: 1.8109 - val_accuracy: 0.3003\n","Epoch 160/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5990 - accuracy: 0.3912 - val_loss: 1.8144 - val_accuracy: 0.2950\n","Epoch 161/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5978 - accuracy: 0.3897 - val_loss: 1.8085 - val_accuracy: 0.2980\n","Epoch 162/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5969 - accuracy: 0.3910 - val_loss: 1.8142 - val_accuracy: 0.2957\n","Epoch 163/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5994 - accuracy: 0.3906 - val_loss: 1.8142 - val_accuracy: 0.2965\n","Epoch 164/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.6005 - accuracy: 0.3889 - val_loss: 1.8125 - val_accuracy: 0.2962\n","Epoch 165/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5992 - accuracy: 0.3899 - val_loss: 1.8135 - val_accuracy: 0.2995\n","Epoch 166/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5971 - accuracy: 0.3897 - val_loss: 1.8136 - val_accuracy: 0.2983\n","Epoch 167/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5979 - accuracy: 0.3921 - val_loss: 1.8134 - val_accuracy: 0.2992\n","Epoch 168/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5965 - accuracy: 0.3916 - val_loss: 1.8163 - val_accuracy: 0.3007\n","Epoch 169/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5974 - accuracy: 0.3919 - val_loss: 1.8108 - val_accuracy: 0.2988\n","Epoch 170/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5946 - accuracy: 0.3935 - val_loss: 1.8160 - val_accuracy: 0.2966\n","Epoch 171/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5948 - accuracy: 0.3925 - val_loss: 1.8145 - val_accuracy: 0.2981\n","Epoch 172/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5954 - accuracy: 0.3908 - val_loss: 1.8121 - val_accuracy: 0.2960\n","Epoch 173/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5970 - accuracy: 0.3906 - val_loss: 1.8134 - val_accuracy: 0.2964\n","Epoch 174/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5932 - accuracy: 0.3924 - val_loss: 1.8143 - val_accuracy: 0.2979\n","Epoch 175/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5986 - accuracy: 0.3904 - val_loss: 1.8129 - val_accuracy: 0.2979\n","Epoch 176/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5980 - accuracy: 0.3917 - val_loss: 1.8120 - val_accuracy: 0.2957\n","Epoch 177/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5936 - accuracy: 0.3922 - val_loss: 1.8115 - val_accuracy: 0.2967\n","Epoch 178/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5934 - accuracy: 0.3927 - val_loss: 1.8140 - val_accuracy: 0.3010\n","Epoch 179/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5945 - accuracy: 0.3915 - val_loss: 1.8123 - val_accuracy: 0.3012\n","Epoch 180/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5942 - accuracy: 0.3917 - val_loss: 1.8114 - val_accuracy: 0.2971\n","Epoch 181/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5954 - accuracy: 0.3931 - val_loss: 1.8089 - val_accuracy: 0.3010\n","Epoch 182/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5947 - accuracy: 0.3938 - val_loss: 1.8120 - val_accuracy: 0.2958\n","Epoch 183/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5936 - accuracy: 0.3924 - val_loss: 1.8127 - val_accuracy: 0.2973\n","Epoch 184/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5943 - accuracy: 0.3919 - val_loss: 1.8107 - val_accuracy: 0.2987\n","Epoch 185/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5931 - accuracy: 0.3925 - val_loss: 1.8125 - val_accuracy: 0.3001\n","Epoch 186/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5978 - accuracy: 0.3919 - val_loss: 1.8114 - val_accuracy: 0.2999\n","Epoch 187/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5914 - accuracy: 0.3919 - val_loss: 1.8130 - val_accuracy: 0.2987\n","Epoch 188/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5920 - accuracy: 0.3925 - val_loss: 1.8145 - val_accuracy: 0.2984\n","Epoch 189/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5918 - accuracy: 0.3932 - val_loss: 1.8103 - val_accuracy: 0.2991\n","Epoch 190/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5948 - accuracy: 0.3918 - val_loss: 1.8139 - val_accuracy: 0.3002\n","Epoch 191/500\n","73923/73923 [==============================] - 10s 137us/step - loss: 1.5939 - accuracy: 0.3924 - val_loss: 1.8147 - val_accuracy: 0.2972\n","Epoch 192/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5935 - accuracy: 0.3923 - val_loss: 1.8138 - val_accuracy: 0.3001\n","Epoch 193/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5895 - accuracy: 0.3950 - val_loss: 1.8121 - val_accuracy: 0.2997\n","Epoch 194/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5888 - accuracy: 0.3950 - val_loss: 1.8119 - val_accuracy: 0.3006\n","Epoch 195/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5887 - accuracy: 0.3950 - val_loss: 1.8105 - val_accuracy: 0.2996\n","Epoch 196/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5897 - accuracy: 0.3925 - val_loss: 1.8077 - val_accuracy: 0.2987\n","Epoch 197/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5908 - accuracy: 0.3949 - val_loss: 1.8120 - val_accuracy: 0.2989\n","Epoch 198/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.5942 - accuracy: 0.3925 - val_loss: 1.8093 - val_accuracy: 0.2988\n","Epoch 199/500\n","73923/73923 [==============================] - 9s 127us/step - loss: 1.5924 - accuracy: 0.3942 - val_loss: 1.8126 - val_accuracy: 0.2994\n","Epoch 200/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5905 - accuracy: 0.3944 - val_loss: 1.8129 - val_accuracy: 0.2972\n","Epoch 201/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5898 - accuracy: 0.3935 - val_loss: 1.8108 - val_accuracy: 0.2986\n","Epoch 202/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5892 - accuracy: 0.3937 - val_loss: 1.8103 - val_accuracy: 0.2997\n","Epoch 203/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5893 - accuracy: 0.3908 - val_loss: 1.8132 - val_accuracy: 0.2983\n","Epoch 204/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5879 - accuracy: 0.3926 - val_loss: 1.8153 - val_accuracy: 0.2985\n","Epoch 205/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5882 - accuracy: 0.3956 - val_loss: 1.8131 - val_accuracy: 0.3006\n","Epoch 206/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5859 - accuracy: 0.3946 - val_loss: 1.8119 - val_accuracy: 0.2977\n","Epoch 207/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5903 - accuracy: 0.3934 - val_loss: 1.8146 - val_accuracy: 0.3004\n","Epoch 208/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5847 - accuracy: 0.3953 - val_loss: 1.8125 - val_accuracy: 0.2969\n","Epoch 209/500\n","73923/73923 [==============================] - 10s 129us/step - loss: 1.5883 - accuracy: 0.3930 - val_loss: 1.8113 - val_accuracy: 0.2981\n","Epoch 210/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5862 - accuracy: 0.3961 - val_loss: 1.8130 - val_accuracy: 0.2980\n","Epoch 211/500\n","73923/73923 [==============================] - 9s 115us/step - loss: 1.5863 - accuracy: 0.3952 - val_loss: 1.8147 - val_accuracy: 0.3012\n","Epoch 212/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5887 - accuracy: 0.3949 - val_loss: 1.8151 - val_accuracy: 0.2976\n","Epoch 213/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5894 - accuracy: 0.3927 - val_loss: 1.8128 - val_accuracy: 0.2994\n","Epoch 214/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5872 - accuracy: 0.3947 - val_loss: 1.8168 - val_accuracy: 0.2990\n","Epoch 215/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5867 - accuracy: 0.3964 - val_loss: 1.8140 - val_accuracy: 0.2987\n","Epoch 216/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5885 - accuracy: 0.3935 - val_loss: 1.8135 - val_accuracy: 0.2984\n","Epoch 217/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5845 - accuracy: 0.3977 - val_loss: 1.8115 - val_accuracy: 0.2996\n","Epoch 218/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5867 - accuracy: 0.3952 - val_loss: 1.8135 - val_accuracy: 0.2988\n","Epoch 219/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5865 - accuracy: 0.3964 - val_loss: 1.8107 - val_accuracy: 0.2985\n","Epoch 220/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5855 - accuracy: 0.3961 - val_loss: 1.8151 - val_accuracy: 0.3003\n","Epoch 221/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5870 - accuracy: 0.3946 - val_loss: 1.8123 - val_accuracy: 0.2992\n","Epoch 222/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5812 - accuracy: 0.3982 - val_loss: 1.8155 - val_accuracy: 0.2994\n","Epoch 223/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5845 - accuracy: 0.3965 - val_loss: 1.8134 - val_accuracy: 0.2960\n","Epoch 224/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5861 - accuracy: 0.3948 - val_loss: 1.8083 - val_accuracy: 0.3008\n","Epoch 225/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5832 - accuracy: 0.3970 - val_loss: 1.8093 - val_accuracy: 0.2994\n","Epoch 226/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5839 - accuracy: 0.3963 - val_loss: 1.8112 - val_accuracy: 0.2977\n","Epoch 227/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5846 - accuracy: 0.3951 - val_loss: 1.8086 - val_accuracy: 0.3008\n","Epoch 228/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5840 - accuracy: 0.3964 - val_loss: 1.8180 - val_accuracy: 0.2988\n","Epoch 229/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5800 - accuracy: 0.3960 - val_loss: 1.8172 - val_accuracy: 0.3013\n","Epoch 230/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5873 - accuracy: 0.3945 - val_loss: 1.8155 - val_accuracy: 0.2996\n","Epoch 231/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5830 - accuracy: 0.3963 - val_loss: 1.8115 - val_accuracy: 0.2996\n","Epoch 232/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5841 - accuracy: 0.3954 - val_loss: 1.8115 - val_accuracy: 0.3004\n","Epoch 233/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5873 - accuracy: 0.3935 - val_loss: 1.8094 - val_accuracy: 0.2975\n","Epoch 234/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5813 - accuracy: 0.3980 - val_loss: 1.8094 - val_accuracy: 0.2985\n","Epoch 235/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5801 - accuracy: 0.3958 - val_loss: 1.8125 - val_accuracy: 0.2973\n","Epoch 236/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5808 - accuracy: 0.3957 - val_loss: 1.8107 - val_accuracy: 0.2970\n","Epoch 237/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5802 - accuracy: 0.3968 - val_loss: 1.8170 - val_accuracy: 0.3003\n","Epoch 238/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5833 - accuracy: 0.3957 - val_loss: 1.8129 - val_accuracy: 0.3018\n","Epoch 239/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5800 - accuracy: 0.3981 - val_loss: 1.8163 - val_accuracy: 0.2994\n","Epoch 240/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5851 - accuracy: 0.3942 - val_loss: 1.8061 - val_accuracy: 0.3002\n","Epoch 241/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5826 - accuracy: 0.3953 - val_loss: 1.8126 - val_accuracy: 0.2980\n","Epoch 242/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5822 - accuracy: 0.3962 - val_loss: 1.8130 - val_accuracy: 0.2993\n","Epoch 243/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5812 - accuracy: 0.3998 - val_loss: 1.8134 - val_accuracy: 0.2983\n","Epoch 244/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5830 - accuracy: 0.3962 - val_loss: 1.8147 - val_accuracy: 0.2974\n","Epoch 245/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5821 - accuracy: 0.3961 - val_loss: 1.8135 - val_accuracy: 0.2984\n","Epoch 246/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5795 - accuracy: 0.3968 - val_loss: 1.8144 - val_accuracy: 0.2981\n","Epoch 247/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5791 - accuracy: 0.3986 - val_loss: 1.8158 - val_accuracy: 0.2987\n","Epoch 248/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5811 - accuracy: 0.3975 - val_loss: 1.8123 - val_accuracy: 0.3021\n","Epoch 249/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5847 - accuracy: 0.3951 - val_loss: 1.8109 - val_accuracy: 0.2991\n","Epoch 250/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5809 - accuracy: 0.3978 - val_loss: 1.8111 - val_accuracy: 0.2980\n","Epoch 251/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5826 - accuracy: 0.3955 - val_loss: 1.8100 - val_accuracy: 0.2985\n","Epoch 252/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.5817 - accuracy: 0.3964 - val_loss: 1.8171 - val_accuracy: 0.2981\n","Epoch 253/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5798 - accuracy: 0.3962 - val_loss: 1.8141 - val_accuracy: 0.2979\n","Epoch 254/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5762 - accuracy: 0.3984 - val_loss: 1.8165 - val_accuracy: 0.2993\n","Epoch 255/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5833 - accuracy: 0.3962 - val_loss: 1.8126 - val_accuracy: 0.3002\n","Epoch 256/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5786 - accuracy: 0.3991 - val_loss: 1.8140 - val_accuracy: 0.2987\n","Epoch 257/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5781 - accuracy: 0.3972 - val_loss: 1.8117 - val_accuracy: 0.3024\n","Epoch 258/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5799 - accuracy: 0.3983 - val_loss: 1.8104 - val_accuracy: 0.3010\n","Epoch 259/500\n","73923/73923 [==============================] - 10s 141us/step - loss: 1.5789 - accuracy: 0.3980 - val_loss: 1.8148 - val_accuracy: 0.3000\n","Epoch 260/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5769 - accuracy: 0.3978 - val_loss: 1.8133 - val_accuracy: 0.2996\n","Epoch 261/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5783 - accuracy: 0.3984 - val_loss: 1.8142 - val_accuracy: 0.3023\n","Epoch 262/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5761 - accuracy: 0.3986 - val_loss: 1.8125 - val_accuracy: 0.2995\n","Epoch 263/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5791 - accuracy: 0.3962 - val_loss: 1.8129 - val_accuracy: 0.2973\n","Epoch 264/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5761 - accuracy: 0.3985 - val_loss: 1.8127 - val_accuracy: 0.3002\n","Epoch 265/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5777 - accuracy: 0.3971 - val_loss: 1.8154 - val_accuracy: 0.3003\n","Epoch 266/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5774 - accuracy: 0.3994 - val_loss: 1.8097 - val_accuracy: 0.2979\n","Epoch 267/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5774 - accuracy: 0.3976 - val_loss: 1.8103 - val_accuracy: 0.2974\n","Epoch 268/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5783 - accuracy: 0.4003 - val_loss: 1.8127 - val_accuracy: 0.2993\n","Epoch 269/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.5786 - accuracy: 0.3981 - val_loss: 1.8151 - val_accuracy: 0.3007\n","Epoch 270/500\n","73923/73923 [==============================] - 9s 128us/step - loss: 1.5755 - accuracy: 0.3988 - val_loss: 1.8112 - val_accuracy: 0.2974\n","Epoch 271/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5808 - accuracy: 0.3999 - val_loss: 1.8114 - val_accuracy: 0.2977\n","Epoch 272/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5776 - accuracy: 0.4004 - val_loss: 1.8080 - val_accuracy: 0.2994\n","Epoch 273/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5740 - accuracy: 0.3998 - val_loss: 1.8149 - val_accuracy: 0.2996\n","Epoch 274/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5781 - accuracy: 0.3974 - val_loss: 1.8126 - val_accuracy: 0.3006\n","Epoch 275/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5757 - accuracy: 0.3975 - val_loss: 1.8155 - val_accuracy: 0.2996\n","Epoch 276/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.5736 - accuracy: 0.3996 - val_loss: 1.8151 - val_accuracy: 0.2986\n","Epoch 277/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5761 - accuracy: 0.3997 - val_loss: 1.8145 - val_accuracy: 0.2992\n","Epoch 278/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5782 - accuracy: 0.3993 - val_loss: 1.8151 - val_accuracy: 0.2979\n","Epoch 279/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5786 - accuracy: 0.3983 - val_loss: 1.8136 - val_accuracy: 0.2986\n","Epoch 280/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5740 - accuracy: 0.4008 - val_loss: 1.8142 - val_accuracy: 0.2993\n","Epoch 281/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5791 - accuracy: 0.3983 - val_loss: 1.8123 - val_accuracy: 0.2998\n","Epoch 282/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5758 - accuracy: 0.4001 - val_loss: 1.8148 - val_accuracy: 0.3012\n","Epoch 283/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5746 - accuracy: 0.3997 - val_loss: 1.8124 - val_accuracy: 0.3005\n","Epoch 284/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5779 - accuracy: 0.3960 - val_loss: 1.8153 - val_accuracy: 0.2987\n","Epoch 285/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5771 - accuracy: 0.3976 - val_loss: 1.8148 - val_accuracy: 0.3005\n","Epoch 286/500\n","73923/73923 [==============================] - 9s 115us/step - loss: 1.5776 - accuracy: 0.3985 - val_loss: 1.8165 - val_accuracy: 0.2974\n","Epoch 287/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5717 - accuracy: 0.4002 - val_loss: 1.8148 - val_accuracy: 0.2982\n","Epoch 288/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5767 - accuracy: 0.3995 - val_loss: 1.8098 - val_accuracy: 0.2974\n","Epoch 289/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5739 - accuracy: 0.3995 - val_loss: 1.8119 - val_accuracy: 0.2994\n","Epoch 290/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5739 - accuracy: 0.4004 - val_loss: 1.8189 - val_accuracy: 0.3012\n","Epoch 291/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5732 - accuracy: 0.4001 - val_loss: 1.8163 - val_accuracy: 0.2984\n","Epoch 292/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5746 - accuracy: 0.3983 - val_loss: 1.8148 - val_accuracy: 0.2988\n","Epoch 293/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5761 - accuracy: 0.4001 - val_loss: 1.8132 - val_accuracy: 0.3013\n","Epoch 294/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5740 - accuracy: 0.3988 - val_loss: 1.8152 - val_accuracy: 0.3014\n","Epoch 295/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5753 - accuracy: 0.4002 - val_loss: 1.8132 - val_accuracy: 0.3018\n","Epoch 296/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5746 - accuracy: 0.4006 - val_loss: 1.8166 - val_accuracy: 0.3008\n","Epoch 297/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5760 - accuracy: 0.3996 - val_loss: 1.8145 - val_accuracy: 0.2972\n","Epoch 298/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5745 - accuracy: 0.4013 - val_loss: 1.8095 - val_accuracy: 0.2997\n","Epoch 299/500\n","73923/73923 [==============================] - 8s 114us/step - loss: 1.5745 - accuracy: 0.3963 - val_loss: 1.8131 - val_accuracy: 0.2986\n","Epoch 300/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5744 - accuracy: 0.3992 - val_loss: 1.8146 - val_accuracy: 0.2999\n","Epoch 301/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5753 - accuracy: 0.3996 - val_loss: 1.8134 - val_accuracy: 0.3017\n","Epoch 302/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5757 - accuracy: 0.4015 - val_loss: 1.8153 - val_accuracy: 0.3004\n","Epoch 303/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5753 - accuracy: 0.4007 - val_loss: 1.8126 - val_accuracy: 0.2992\n","Epoch 304/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5728 - accuracy: 0.4007 - val_loss: 1.8118 - val_accuracy: 0.2992\n","Epoch 305/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5728 - accuracy: 0.4017 - val_loss: 1.8083 - val_accuracy: 0.3017\n","Epoch 306/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5749 - accuracy: 0.3995 - val_loss: 1.8121 - val_accuracy: 0.3018\n","Epoch 307/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5738 - accuracy: 0.3980 - val_loss: 1.8145 - val_accuracy: 0.3003\n","Epoch 308/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5705 - accuracy: 0.3986 - val_loss: 1.8118 - val_accuracy: 0.3016\n","Epoch 309/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5712 - accuracy: 0.4011 - val_loss: 1.8118 - val_accuracy: 0.3027\n","Epoch 310/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5705 - accuracy: 0.4018 - val_loss: 1.8117 - val_accuracy: 0.3030\n","Epoch 311/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5732 - accuracy: 0.3989 - val_loss: 1.8128 - val_accuracy: 0.3034\n","Epoch 312/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5721 - accuracy: 0.4001 - val_loss: 1.8101 - val_accuracy: 0.3016\n","Epoch 313/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5732 - accuracy: 0.4006 - val_loss: 1.8119 - val_accuracy: 0.3004\n","Epoch 314/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5706 - accuracy: 0.4035 - val_loss: 1.8111 - val_accuracy: 0.3005\n","Epoch 315/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5713 - accuracy: 0.4014 - val_loss: 1.8127 - val_accuracy: 0.3049\n","Epoch 316/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5702 - accuracy: 0.4012 - val_loss: 1.8151 - val_accuracy: 0.3007\n","Epoch 317/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5699 - accuracy: 0.4018 - val_loss: 1.8154 - val_accuracy: 0.3013\n","Epoch 318/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5697 - accuracy: 0.4000 - val_loss: 1.8151 - val_accuracy: 0.3018\n","Epoch 319/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5675 - accuracy: 0.4031 - val_loss: 1.8178 - val_accuracy: 0.3001\n","Epoch 320/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5710 - accuracy: 0.3987 - val_loss: 1.8130 - val_accuracy: 0.2998\n","Epoch 321/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5710 - accuracy: 0.4011 - val_loss: 1.8145 - val_accuracy: 0.3005\n","Epoch 322/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5698 - accuracy: 0.4028 - val_loss: 1.8146 - val_accuracy: 0.3023\n","Epoch 323/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5719 - accuracy: 0.4001 - val_loss: 1.8161 - val_accuracy: 0.2998\n","Epoch 324/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5683 - accuracy: 0.4022 - val_loss: 1.8171 - val_accuracy: 0.2999\n","Epoch 325/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5678 - accuracy: 0.4025 - val_loss: 1.8110 - val_accuracy: 0.3011\n","Epoch 326/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5697 - accuracy: 0.4031 - val_loss: 1.8113 - val_accuracy: 0.2991\n","Epoch 327/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5709 - accuracy: 0.4010 - val_loss: 1.8133 - val_accuracy: 0.2993\n","Epoch 328/500\n","73923/73923 [==============================] - 10s 131us/step - loss: 1.5670 - accuracy: 0.4044 - val_loss: 1.8184 - val_accuracy: 0.3007\n","Epoch 329/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5707 - accuracy: 0.4006 - val_loss: 1.8145 - val_accuracy: 0.2991\n","Epoch 330/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5692 - accuracy: 0.4012 - val_loss: 1.8124 - val_accuracy: 0.2993\n","Epoch 331/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5721 - accuracy: 0.3986 - val_loss: 1.8172 - val_accuracy: 0.2996\n","Epoch 332/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5683 - accuracy: 0.4004 - val_loss: 1.8162 - val_accuracy: 0.2996\n","Epoch 333/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5704 - accuracy: 0.4019 - val_loss: 1.8147 - val_accuracy: 0.3004\n","Epoch 334/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5674 - accuracy: 0.4009 - val_loss: 1.8104 - val_accuracy: 0.3032\n","Epoch 335/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5684 - accuracy: 0.4021 - val_loss: 1.8201 - val_accuracy: 0.3011\n","Epoch 336/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5688 - accuracy: 0.4029 - val_loss: 1.8114 - val_accuracy: 0.3037\n","Epoch 337/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5688 - accuracy: 0.4019 - val_loss: 1.8168 - val_accuracy: 0.3014\n","Epoch 338/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5701 - accuracy: 0.4010 - val_loss: 1.8180 - val_accuracy: 0.3002\n","Epoch 339/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5708 - accuracy: 0.3988 - val_loss: 1.8126 - val_accuracy: 0.3018\n","Epoch 340/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5681 - accuracy: 0.4030 - val_loss: 1.8203 - val_accuracy: 0.3023\n","Epoch 341/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5731 - accuracy: 0.3994 - val_loss: 1.8171 - val_accuracy: 0.3020\n","Epoch 342/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5697 - accuracy: 0.4013 - val_loss: 1.8143 - val_accuracy: 0.3039\n","Epoch 343/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5682 - accuracy: 0.4032 - val_loss: 1.8141 - val_accuracy: 0.3021\n","Epoch 344/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5676 - accuracy: 0.4035 - val_loss: 1.8153 - val_accuracy: 0.3014\n","Epoch 345/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5666 - accuracy: 0.4020 - val_loss: 1.8131 - val_accuracy: 0.3012\n","Epoch 346/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5691 - accuracy: 0.4030 - val_loss: 1.8180 - val_accuracy: 0.2996\n","Epoch 347/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5707 - accuracy: 0.4012 - val_loss: 1.8158 - val_accuracy: 0.3027\n","Epoch 348/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5699 - accuracy: 0.4027 - val_loss: 1.8170 - val_accuracy: 0.3015\n","Epoch 349/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5645 - accuracy: 0.4053 - val_loss: 1.8154 - val_accuracy: 0.3003\n","Epoch 350/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5676 - accuracy: 0.4052 - val_loss: 1.8127 - val_accuracy: 0.3027\n","Epoch 351/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5661 - accuracy: 0.4031 - val_loss: 1.8166 - val_accuracy: 0.2988\n","Epoch 352/500\n","73923/73923 [==============================] - 8s 115us/step - loss: 1.5662 - accuracy: 0.4029 - val_loss: 1.8174 - val_accuracy: 0.3019\n","Epoch 353/500\n","73923/73923 [==============================] - 9s 115us/step - loss: 1.5685 - accuracy: 0.4020 - val_loss: 1.8187 - val_accuracy: 0.3010\n","Epoch 354/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5673 - accuracy: 0.4025 - val_loss: 1.8163 - val_accuracy: 0.2985\n","Epoch 355/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5679 - accuracy: 0.4007 - val_loss: 1.8186 - val_accuracy: 0.3009\n","Epoch 356/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5671 - accuracy: 0.4031 - val_loss: 1.8193 - val_accuracy: 0.2993\n","Epoch 357/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5659 - accuracy: 0.4044 - val_loss: 1.8197 - val_accuracy: 0.2994\n","Epoch 358/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5698 - accuracy: 0.4035 - val_loss: 1.8137 - val_accuracy: 0.3006\n","Epoch 359/500\n","73923/73923 [==============================] - 9s 115us/step - loss: 1.5695 - accuracy: 0.4038 - val_loss: 1.8139 - val_accuracy: 0.2998\n","Epoch 360/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5653 - accuracy: 0.4040 - val_loss: 1.8156 - val_accuracy: 0.3016\n","Epoch 361/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5659 - accuracy: 0.4025 - val_loss: 1.8162 - val_accuracy: 0.3012\n","Epoch 362/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5661 - accuracy: 0.4028 - val_loss: 1.8143 - val_accuracy: 0.3040\n","Epoch 363/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5666 - accuracy: 0.4025 - val_loss: 1.8153 - val_accuracy: 0.3011\n","Epoch 364/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5681 - accuracy: 0.4019 - val_loss: 1.8108 - val_accuracy: 0.3007\n","Epoch 365/500\n","73923/73923 [==============================] - 8s 115us/step - loss: 1.5638 - accuracy: 0.4047 - val_loss: 1.8155 - val_accuracy: 0.3014\n","Epoch 366/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5692 - accuracy: 0.4004 - val_loss: 1.8125 - val_accuracy: 0.3000\n","Epoch 367/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5658 - accuracy: 0.4022 - val_loss: 1.8135 - val_accuracy: 0.3003\n","Epoch 368/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5665 - accuracy: 0.4022 - val_loss: 1.8122 - val_accuracy: 0.3014\n","Epoch 369/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5664 - accuracy: 0.4027 - val_loss: 1.8164 - val_accuracy: 0.3016\n","Epoch 370/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5677 - accuracy: 0.4032 - val_loss: 1.8101 - val_accuracy: 0.3019\n","Epoch 371/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5637 - accuracy: 0.4022 - val_loss: 1.8158 - val_accuracy: 0.3015\n","Epoch 372/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5643 - accuracy: 0.4039 - val_loss: 1.8129 - val_accuracy: 0.2993\n","Epoch 373/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5612 - accuracy: 0.4059 - val_loss: 1.8182 - val_accuracy: 0.3026\n","Epoch 374/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5665 - accuracy: 0.4041 - val_loss: 1.8186 - val_accuracy: 0.3016\n","Epoch 375/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5615 - accuracy: 0.4050 - val_loss: 1.8124 - val_accuracy: 0.3017\n","Epoch 376/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5642 - accuracy: 0.4043 - val_loss: 1.8154 - val_accuracy: 0.3024\n","Epoch 377/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5634 - accuracy: 0.4036 - val_loss: 1.8103 - val_accuracy: 0.3017\n","Epoch 378/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5656 - accuracy: 0.4014 - val_loss: 1.8167 - val_accuracy: 0.3029\n","Epoch 379/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5671 - accuracy: 0.4044 - val_loss: 1.8094 - val_accuracy: 0.3021\n","Epoch 380/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5629 - accuracy: 0.4055 - val_loss: 1.8150 - val_accuracy: 0.3030\n","Epoch 381/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5640 - accuracy: 0.4034 - val_loss: 1.8135 - val_accuracy: 0.3017\n","Epoch 382/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5629 - accuracy: 0.4041 - val_loss: 1.8157 - val_accuracy: 0.3032\n","Epoch 383/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5629 - accuracy: 0.4049 - val_loss: 1.8162 - val_accuracy: 0.3018\n","Epoch 384/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5663 - accuracy: 0.4041 - val_loss: 1.8137 - val_accuracy: 0.3038\n","Epoch 385/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5638 - accuracy: 0.4047 - val_loss: 1.8128 - val_accuracy: 0.3008\n","Epoch 386/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5642 - accuracy: 0.4065 - val_loss: 1.8098 - val_accuracy: 0.3016\n","Epoch 387/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5678 - accuracy: 0.4018 - val_loss: 1.8159 - val_accuracy: 0.3001\n","Epoch 388/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5654 - accuracy: 0.4031 - val_loss: 1.8163 - val_accuracy: 0.3019\n","Epoch 389/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5634 - accuracy: 0.4026 - val_loss: 1.8161 - val_accuracy: 0.3006\n","Epoch 390/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5666 - accuracy: 0.4024 - val_loss: 1.8155 - val_accuracy: 0.3011\n","Epoch 391/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5656 - accuracy: 0.4011 - val_loss: 1.8127 - val_accuracy: 0.3016\n","Epoch 392/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5613 - accuracy: 0.4048 - val_loss: 1.8154 - val_accuracy: 0.3019\n","Epoch 393/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5647 - accuracy: 0.4053 - val_loss: 1.8110 - val_accuracy: 0.3027\n","Epoch 394/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5631 - accuracy: 0.4022 - val_loss: 1.8130 - val_accuracy: 0.3009\n","Epoch 395/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5614 - accuracy: 0.4034 - val_loss: 1.8107 - val_accuracy: 0.3026\n","Epoch 396/500\n","73923/73923 [==============================] - 8s 115us/step - loss: 1.5618 - accuracy: 0.4058 - val_loss: 1.8147 - val_accuracy: 0.3028\n","Epoch 397/500\n","73923/73923 [==============================] - 10s 138us/step - loss: 1.5640 - accuracy: 0.4049 - val_loss: 1.8131 - val_accuracy: 0.3017\n","Epoch 398/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5620 - accuracy: 0.4079 - val_loss: 1.8130 - val_accuracy: 0.3037\n","Epoch 399/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5599 - accuracy: 0.4053 - val_loss: 1.8168 - val_accuracy: 0.3014\n","Epoch 400/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5644 - accuracy: 0.4038 - val_loss: 1.8178 - val_accuracy: 0.3015\n","Epoch 401/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5623 - accuracy: 0.4025 - val_loss: 1.8148 - val_accuracy: 0.3032\n","Epoch 402/500\n","73923/73923 [==============================] - 9s 115us/step - loss: 1.5643 - accuracy: 0.4037 - val_loss: 1.8132 - val_accuracy: 0.3028\n","Epoch 403/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5631 - accuracy: 0.4048 - val_loss: 1.8123 - val_accuracy: 0.3021\n","Epoch 404/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5611 - accuracy: 0.4052 - val_loss: 1.8154 - val_accuracy: 0.3032\n","Epoch 405/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5631 - accuracy: 0.4025 - val_loss: 1.8145 - val_accuracy: 0.3012\n","Epoch 406/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5614 - accuracy: 0.4030 - val_loss: 1.8164 - val_accuracy: 0.3018\n","Epoch 407/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5673 - accuracy: 0.4037 - val_loss: 1.8138 - val_accuracy: 0.2993\n","Epoch 408/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5624 - accuracy: 0.4034 - val_loss: 1.8202 - val_accuracy: 0.3008\n","Epoch 409/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5607 - accuracy: 0.4070 - val_loss: 1.8176 - val_accuracy: 0.3017\n","Epoch 410/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5628 - accuracy: 0.4042 - val_loss: 1.8126 - val_accuracy: 0.3044\n","Epoch 411/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5597 - accuracy: 0.4047 - val_loss: 1.8177 - val_accuracy: 0.3012\n","Epoch 412/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5604 - accuracy: 0.4058 - val_loss: 1.8132 - val_accuracy: 0.3014\n","Epoch 413/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5597 - accuracy: 0.4047 - val_loss: 1.8157 - val_accuracy: 0.3018\n","Epoch 414/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5627 - accuracy: 0.4035 - val_loss: 1.8121 - val_accuracy: 0.3012\n","Epoch 415/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5595 - accuracy: 0.4075 - val_loss: 1.8154 - val_accuracy: 0.3042\n","Epoch 416/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5603 - accuracy: 0.4063 - val_loss: 1.8170 - val_accuracy: 0.3038\n","Epoch 417/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5619 - accuracy: 0.4062 - val_loss: 1.8158 - val_accuracy: 0.3028\n","Epoch 418/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5611 - accuracy: 0.4042 - val_loss: 1.8152 - val_accuracy: 0.3025\n","Epoch 419/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5652 - accuracy: 0.4011 - val_loss: 1.8138 - val_accuracy: 0.3031\n","Epoch 420/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5615 - accuracy: 0.4052 - val_loss: 1.8158 - val_accuracy: 0.3022\n","Epoch 421/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5613 - accuracy: 0.4026 - val_loss: 1.8148 - val_accuracy: 0.3006\n","Epoch 422/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5616 - accuracy: 0.4034 - val_loss: 1.8159 - val_accuracy: 0.3044\n","Epoch 423/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5610 - accuracy: 0.4052 - val_loss: 1.8121 - val_accuracy: 0.3033\n","Epoch 424/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5608 - accuracy: 0.4048 - val_loss: 1.8153 - val_accuracy: 0.3017\n","Epoch 425/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5611 - accuracy: 0.4041 - val_loss: 1.8140 - val_accuracy: 0.3002\n","Epoch 426/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5623 - accuracy: 0.4029 - val_loss: 1.8146 - val_accuracy: 0.3025\n","Epoch 427/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5605 - accuracy: 0.4064 - val_loss: 1.8191 - val_accuracy: 0.3023\n","Epoch 428/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5598 - accuracy: 0.4055 - val_loss: 1.8154 - val_accuracy: 0.3034\n","Epoch 429/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5618 - accuracy: 0.4042 - val_loss: 1.8177 - val_accuracy: 0.3034\n","Epoch 430/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5609 - accuracy: 0.4047 - val_loss: 1.8161 - val_accuracy: 0.3027\n","Epoch 431/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5609 - accuracy: 0.4046 - val_loss: 1.8184 - val_accuracy: 0.3030\n","Epoch 432/500\n","73923/73923 [==============================] - 9s 124us/step - loss: 1.5590 - accuracy: 0.4076 - val_loss: 1.8147 - val_accuracy: 0.3037\n","Epoch 433/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5606 - accuracy: 0.4046 - val_loss: 1.8121 - val_accuracy: 0.3015\n","Epoch 434/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5600 - accuracy: 0.4041 - val_loss: 1.8153 - val_accuracy: 0.3013\n","Epoch 435/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5595 - accuracy: 0.4055 - val_loss: 1.8149 - val_accuracy: 0.3027\n","Epoch 436/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5611 - accuracy: 0.4030 - val_loss: 1.8147 - val_accuracy: 0.3033\n","Epoch 437/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5547 - accuracy: 0.4075 - val_loss: 1.8199 - val_accuracy: 0.3019\n","Epoch 438/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5610 - accuracy: 0.4049 - val_loss: 1.8144 - val_accuracy: 0.3033\n","Epoch 439/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5575 - accuracy: 0.4071 - val_loss: 1.8131 - val_accuracy: 0.3030\n","Epoch 440/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5589 - accuracy: 0.4054 - val_loss: 1.8125 - val_accuracy: 0.3037\n","Epoch 441/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5606 - accuracy: 0.4048 - val_loss: 1.8123 - val_accuracy: 0.3040\n","Epoch 442/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5573 - accuracy: 0.4050 - val_loss: 1.8145 - val_accuracy: 0.3018\n","Epoch 443/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5585 - accuracy: 0.4087 - val_loss: 1.8171 - val_accuracy: 0.3017\n","Epoch 444/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5583 - accuracy: 0.4074 - val_loss: 1.8158 - val_accuracy: 0.3034\n","Epoch 445/500\n","73923/73923 [==============================] - 9s 125us/step - loss: 1.5612 - accuracy: 0.4044 - val_loss: 1.8095 - val_accuracy: 0.3057\n","Epoch 446/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5584 - accuracy: 0.4068 - val_loss: 1.8139 - val_accuracy: 0.3021\n","Epoch 447/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5590 - accuracy: 0.4064 - val_loss: 1.8149 - val_accuracy: 0.3029\n","Epoch 448/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5582 - accuracy: 0.4085 - val_loss: 1.8141 - val_accuracy: 0.3044\n","Epoch 449/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5586 - accuracy: 0.4065 - val_loss: 1.8157 - val_accuracy: 0.3021\n","Epoch 450/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5587 - accuracy: 0.4052 - val_loss: 1.8161 - val_accuracy: 0.3016\n","Epoch 451/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5582 - accuracy: 0.4054 - val_loss: 1.8111 - val_accuracy: 0.3012\n","Epoch 452/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5559 - accuracy: 0.4055 - val_loss: 1.8137 - val_accuracy: 0.3042\n","Epoch 453/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5575 - accuracy: 0.4057 - val_loss: 1.8150 - val_accuracy: 0.2997\n","Epoch 454/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5620 - accuracy: 0.4049 - val_loss: 1.8134 - val_accuracy: 0.3029\n","Epoch 455/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5591 - accuracy: 0.4068 - val_loss: 1.8162 - val_accuracy: 0.3030\n","Epoch 456/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5595 - accuracy: 0.4047 - val_loss: 1.8164 - val_accuracy: 0.3033\n","Epoch 457/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5566 - accuracy: 0.4052 - val_loss: 1.8167 - val_accuracy: 0.3047\n","Epoch 458/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5594 - accuracy: 0.4043 - val_loss: 1.8182 - val_accuracy: 0.3027\n","Epoch 459/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5591 - accuracy: 0.4038 - val_loss: 1.8141 - val_accuracy: 0.3028\n","Epoch 460/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5565 - accuracy: 0.4043 - val_loss: 1.8140 - val_accuracy: 0.3014\n","Epoch 461/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5577 - accuracy: 0.4063 - val_loss: 1.8169 - val_accuracy: 0.3010\n","Epoch 462/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5576 - accuracy: 0.4050 - val_loss: 1.8150 - val_accuracy: 0.3012\n","Epoch 463/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5584 - accuracy: 0.4058 - val_loss: 1.8097 - val_accuracy: 0.3019\n","Epoch 464/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5538 - accuracy: 0.4075 - val_loss: 1.8161 - val_accuracy: 0.3032\n","Epoch 465/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5564 - accuracy: 0.4079 - val_loss: 1.8146 - val_accuracy: 0.3017\n","Epoch 466/500\n","73923/73923 [==============================] - 10s 135us/step - loss: 1.5566 - accuracy: 0.4063 - val_loss: 1.8154 - val_accuracy: 0.3020\n","Epoch 467/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5573 - accuracy: 0.4058 - val_loss: 1.8153 - val_accuracy: 0.3042\n","Epoch 468/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5588 - accuracy: 0.4042 - val_loss: 1.8159 - val_accuracy: 0.3033\n","Epoch 469/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5574 - accuracy: 0.4034 - val_loss: 1.8156 - val_accuracy: 0.3051\n","Epoch 470/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5570 - accuracy: 0.4049 - val_loss: 1.8140 - val_accuracy: 0.3034\n","Epoch 471/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5571 - accuracy: 0.4034 - val_loss: 1.8156 - val_accuracy: 0.3034\n","Epoch 472/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5551 - accuracy: 0.4077 - val_loss: 1.8165 - val_accuracy: 0.3031\n","Epoch 473/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5565 - accuracy: 0.4057 - val_loss: 1.8167 - val_accuracy: 0.3042\n","Epoch 474/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5548 - accuracy: 0.4070 - val_loss: 1.8156 - val_accuracy: 0.3027\n","Epoch 475/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5546 - accuracy: 0.4061 - val_loss: 1.8162 - val_accuracy: 0.3023\n","Epoch 476/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5535 - accuracy: 0.4083 - val_loss: 1.8218 - val_accuracy: 0.2997\n","Epoch 477/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5585 - accuracy: 0.4062 - val_loss: 1.8114 - val_accuracy: 0.3039\n","Epoch 478/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5565 - accuracy: 0.4035 - val_loss: 1.8192 - val_accuracy: 0.3037\n","Epoch 479/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5581 - accuracy: 0.4066 - val_loss: 1.8169 - val_accuracy: 0.3029\n","Epoch 480/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5542 - accuracy: 0.4047 - val_loss: 1.8166 - val_accuracy: 0.3013\n","Epoch 481/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5549 - accuracy: 0.4062 - val_loss: 1.8171 - val_accuracy: 0.3034\n","Epoch 482/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5589 - accuracy: 0.4044 - val_loss: 1.8150 - val_accuracy: 0.3023\n","Epoch 483/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5546 - accuracy: 0.4071 - val_loss: 1.8174 - val_accuracy: 0.3025\n","Epoch 484/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5593 - accuracy: 0.4058 - val_loss: 1.8156 - val_accuracy: 0.3028\n","Epoch 485/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5548 - accuracy: 0.4044 - val_loss: 1.8153 - val_accuracy: 0.3010\n","Epoch 486/500\n","73923/73923 [==============================] - 9s 126us/step - loss: 1.5515 - accuracy: 0.4073 - val_loss: 1.8193 - val_accuracy: 0.3026\n","Epoch 487/500\n","73923/73923 [==============================] - 9s 123us/step - loss: 1.5568 - accuracy: 0.4089 - val_loss: 1.8159 - val_accuracy: 0.3020\n","Epoch 488/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5593 - accuracy: 0.4051 - val_loss: 1.8114 - val_accuracy: 0.3024\n","Epoch 489/500\n","73923/73923 [==============================] - 8s 115us/step - loss: 1.5562 - accuracy: 0.4038 - val_loss: 1.8114 - val_accuracy: 0.3008\n","Epoch 490/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5564 - accuracy: 0.4058 - val_loss: 1.8181 - val_accuracy: 0.3001\n","Epoch 491/500\n","73923/73923 [==============================] - 9s 117us/step - loss: 1.5570 - accuracy: 0.4055 - val_loss: 1.8141 - val_accuracy: 0.3012\n","Epoch 492/500\n","73923/73923 [==============================] - 8s 114us/step - loss: 1.5540 - accuracy: 0.4082 - val_loss: 1.8167 - val_accuracy: 0.3024\n","Epoch 493/500\n","73923/73923 [==============================] - 9s 119us/step - loss: 1.5576 - accuracy: 0.4046 - val_loss: 1.8134 - val_accuracy: 0.3020\n","Epoch 494/500\n","73923/73923 [==============================] - 9s 116us/step - loss: 1.5536 - accuracy: 0.4098 - val_loss: 1.8120 - val_accuracy: 0.3007\n","Epoch 495/500\n","73923/73923 [==============================] - 9s 120us/step - loss: 1.5561 - accuracy: 0.4080 - val_loss: 1.8154 - val_accuracy: 0.3029\n","Epoch 496/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5545 - accuracy: 0.4058 - val_loss: 1.8123 - val_accuracy: 0.3009\n","Epoch 497/500\n","73923/73923 [==============================] - 9s 118us/step - loss: 1.5575 - accuracy: 0.4070 - val_loss: 1.8150 - val_accuracy: 0.3010\n","Epoch 498/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5571 - accuracy: 0.4075 - val_loss: 1.8139 - val_accuracy: 0.3015\n","Epoch 499/500\n","73923/73923 [==============================] - 9s 122us/step - loss: 1.5540 - accuracy: 0.4070 - val_loss: 1.8183 - val_accuracy: 0.3003\n","Epoch 500/500\n","73923/73923 [==============================] - 9s 121us/step - loss: 1.5575 - accuracy: 0.4048 - val_loss: 1.8115 - val_accuracy: 0.3012\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f37fb7d6208>"]},"metadata":{"tags":[]},"execution_count":201}]},{"cell_type":"code","metadata":{"id":"IUMiXAC1ucSk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593478980976,"user_tz":180,"elapsed":10625201,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}},"outputId":"8e9ddbcb-61f3-4832-a5d7-4bcc268f5515"},"source":["acur_test = regressor.evaluate(X_test, y_test, verbose=0)\n","accuracy_modelo6 = acur_test[1]\n","print(accuracy_modelo6)"],"execution_count":202,"outputs":[{"output_type":"stream","text":["0.30122828483581543\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g3hxNC_wbMUT","colab_type":"text"},"source":["MATRIZ DE CONFUSÃO"]},{"cell_type":"code","metadata":{"id":"GkOxCynU976r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593478982105,"user_tz":180,"elapsed":10626321,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["y_predicted_lstm = regressor.predict_classes(X_test)\n","lstm_results = pd.DataFrame(list(zip(y_predicted_lstm, y_test)), columns =['predito', 'real'])\n","df_confusion = pd.crosstab(lstm_results.real, lstm_results.predito)\n","\n","export_path = workdir_path + '/matrizConfusaoLSTM3.csv'\n","df_confusion.to_csv (export_path, index = True, header=True)"],"execution_count":203,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtZmH3KSxdYu","colab_type":"text"},"source":["EXPORTANDO RESULTADOS DE ACURACIA"]},{"cell_type":"code","metadata":{"id":"QxdoQ-Q7upMI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593478982107,"user_tz":180,"elapsed":10626311,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["descricoes_modelos = [modelo1, modelo2, modelo3, modelo4, modelo5, modelo6]\n","acuracias = [accuracy_modelo1, accuracy_modelo2, accuracy_modelo3, accuracy_modelo4, accuracy_modelo5, accuracy_modelo6]\n"],"execution_count":204,"outputs":[]},{"cell_type":"code","metadata":{"id":"feLXXzKSf07H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593478982108,"user_tz":180,"elapsed":10626308,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":["\n","acuracias_df = pd.DataFrame(list(zip(descricoes_modelos, acuracias)), \n","               columns =['modelo', 'acuracia']) \n","\n","export_path = workdir_path + '/acuracias.csv'\n","acuracias_df.to_csv (export_path, index = True, header=True)"],"execution_count":205,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmqEl564gB0A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593478982109,"user_tz":180,"elapsed":10626303,"user":{"displayName":"Flávia Rodrigues Costa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhloiPVsAlM7hGPOHLQWxmYUo7eLd1RxHPRjkXscVk=s64","userId":"02075572627500231098"}}},"source":[""],"execution_count":205,"outputs":[]}]}